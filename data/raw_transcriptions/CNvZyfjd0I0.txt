('<center> <iframe width="500" height="320" src="https://www.youtube.com/embed/CNvZyfjd0I0"> </iframe> </center>', " Ja, hallo zusammen. Es freut mich sehr, dass wir heute als letzten Speaker bei unserer Konferenz Joscha Bach hier haben. Ich verfolge den Werdegang von Joscha jetzt schon ungefähr seit 17 Jahren. Wir haben uns damals in einem Internetforum kennengelernt und ich weiß noch, ich war sofort fasziniert von seiner Gabe, mit allen möglichen Leuten sehr empathisch ins Gespräch zu kommen und über alles Mögliche zu reden, um dann im nächsten Schritt völlig abzuspacen in höchste, wie soll man sagen, in höchste Gefilde, in höchste intellektuelle Gefilde. Inzwischen hat man das auch in den USA festgestellt, wo der Joscha seit einiger Zeit lebt und arbeitet. Ich glaube, rund eine halbe Million Menschen haben zuletzt sein Video mit Lex Friedman gesehen, der KI-Forscher ist und YouTuber. Und ich glaube, ich habe noch nie so viele frenetische Kommentare unter einem YouTube-Video dieser Couleur gesehen. Einen habe ich mir gemerkt, da hat ein User geschrieben, ich möchte, dass die URL dieses YouTube-Videos irgendwann auf meinem Grabstein steht. Insofern freue ich mich heute sehr, Joshua hier zu haben, mal wieder in Deutschland sprechen zu sehen und erst recht natürlich als letzten Speak auf unsere 1&9-Konferenz. Ich bin gespannt, was er sagt. Ihr könnt jetzt schon Fragen stellen, Anmerkungen in den Chat schreiben. Und genau, und dann werden wir weitersehen. Auf jeden Fall, ich übergebe jetzt an Joscha live aus dem Silicon Valley. Dein Wort. Hallo, einen wunderschönen guten Abend. Hier im Silicon Valley ist es Mittag, wunderbarer Frühling wie immer in der South Bay. Ich vermisse die Heimat dennoch ab und zu, aber ich bin sehr glücklich, ich arbeite bei einem künstlichen Intelligenz-Startup in der Forschung. Das Startup heißt AI Foundation und was mich am meisten interessiert, ist der Weg zu Systemen, die sich so ähnlich verhalten wie wir, damit wir lernen, wer wir sind und wie unser Verhältnis zur Realität aussieht. Vielen Dank, Christian, für die Einladung. Ich habe überlegt, worüber ich heute erzählen sollte und am liebsten würde ich über eine Entwicklung in der KI berichten, die mich im letzten Jahr sehr fasziniert hat. Und ich hole gleich ein kleines bisschen weiter aus. Es gibt in der künstlichen Intelligenz einen philosophischen Konflikt, der meiner Ansicht nach underreported ist, der zu wenig Aufmerksamkeit gefunden hat. Und dieser Konflikt handelt von den Platonisten und den Verkörperungsleuten, könnte man sagen. Es gab auf der einen Seite Leute wie Marvy Minsky, die, wenn sie sich mit dem Problem des Geistes und der Interaktion mit der Realität beschäftigt haben, überlegt haben, wie gehen wir damit um, wie bauen wir Systeme, die das können. Wir bilden Ideen von der Realität, wir machen einen Plan, wie wir mit diesen Ideen umgehen und dann setzen wir uns mit unserer Umgebung in Bezug und tun irgendwas in dieser Umgebung und dann wiederholen wir diesen gesamten Prozess. Und das steht im Gegensatz zu den Embedded Systems Leuten. Also die Idee, wir bauen ein System, das mit der Realität direkt enttangelt ist und in irgendeiner Weise mit ihm verwoben ist und mit der ständig in Bezug steht und die ganze Zeit Bedeutung aus dieser Realität extrahieren muss, indem es mit der Realität umgeht, direkt. Und zu diesen Leuten gehören zum Beispiel Menschen wie Rodney Brooks. Und diese beiden Gruppen haben einen erstaunlich tiefen und energischen Konflikt miteinander gehabt, das heißt, die Platonisten, die sozusagen mathematische Konzepte der Realität und des Umgehens mit der Realität entwickelt haben, haben diese radikal verkörperten, eingebetteten Systeme abgelehnt, einfach deswegen, weil die meisten verkörperten Systeme, die wir sehen, sind nicht besonders intelligent, also jedenfalls nicht im menschlichen Sinne und sind nicht in der Lage, Probleme in der gleichen abstrakten Weise wie wir zu lösen. Und umgekehrt ist es so, dass die Leute, die sich mit den verkörperten Systemen beschäftigt haben, meinten, dass die Ideen, die wir haben, um mit der Realität umzugehen, also die Abstraktionen, die wir haben, völlig unzureichend sind, um die wahre Tiefe und Struktur und Komplexität der Realität zu erfassen und mit ihr umzugehen. Das heißt, unsere Mathematik ist eigentlich noch viel zu unfertig und wird es vielleicht auch immer sein, um mit der Realität richtig umzugehen. Und wie das so ist, beide Gruppen hatten recht. Das heißt, die symbolischen KI hat sich entwickelt aus diesen platonischen Konzepten und hat letzten Endes bis heute nicht es geschafft, Systeme zu bauen, die mit der Realität in der ähnlichen Weise umgehen wie wir Menschen. Und die Robotikleute, so wie Wodny Brooks, das ist im Prinzip im Rumba kulminiert. Und diese beiden Richtungen haben sich bis heute nicht komplett getroffen. Das heißt, wir haben keine Systeme, die in der Lage sind, in Echtzeit mit der Realität umzugehen, komplett mit ihr eingebettet zu sein, online zu lernen und in einer ähnlichen Weise Bedeutung extrahieren, wie Menschen das tun. Aber wir haben Systeme, die das isoliert voneinander relativ gut können. Also das heißt, wir haben Systeme, die in Echtzeit schneller reagieren als Menschen und wir haben Systeme, die mehr Struktur aus der Realität extrahieren können, in einer gewissen Weise als Menschen, auch wenn sie nicht die Bedeutung der Realität erfassen. Und diese beiden Richtungen reflektieren zwei Fähigkeiten, die unser eigener Geist hat, die, glaube ich, getrennte Modi sind, in einer gewissen Weise. Und zwar, würde ich sagen, ein geometrischer Modus und ein symbolischer Modus. Es korrespondiert zu dieser Trennung, die Descartes gemacht hat zwischen Res Extensa und Res Cogitans, dem ausgedehnten Bereich und dem Bereich der mentalen Konzepte. Und also Extensa ist praktisch die Dinge im Raum. Und die Welt, wie wir heute wissen in der Physik, besteht nicht wirklich aus Dingen im Raum, sondern der Raum emergiert über einer darunterliegenden Struktur, über die wir uns noch nicht so ganz einig sind. Das ist irgendein verrückter Quantengraf. Und der Raum, mit dem wir umgehen, das ist ein Konzept, den unser Geist konstruiert. Der bringt diese Muster, mit denen wir verbunden sind, in eine Ordnung, die es uns erlaubt, die Welt vorhersehbar und interagierbar zu machen. Im Prinzip ist diese Vorstellung von Dingen im Raum so eine Art Karte, eine mentale Map, die wir bauen. Die erste Karte, die unser Körper baut, also unser Geist baut, ist die Körperkarte. Symmetrische sind so Symmetrische Vortex, die wird gebildet, bereits bevor wir geboren sind. Und wie kann man so eine Karte des Körpers machen? Das ist erstaunlich einfach. Man muss einfach nur zählen, welche Reize gleichzeitig auftreten. Wenn zwei Reize immer gleichzeitig auftreten, dann korrespondieren sie zu dem gleichen Nerv, zum Beispiel auf der Körperoberfläche oder auf der Retina. Wenn zwei Reize, die im Neokortex ankommen, fast immer gleich sind, aber nicht immer gleich sind, dann sind sie wahrscheinlich benachbart. Wenn ich meine Körperoberfläche berühre, dann ist es so, dass ich benachbarte Nerven berühre. Dadurch, dass ich Statistiken mache, über welche Nerven gleichzeitig Signale senden, kriege ich die Nachbarschaft raus und kann praktisch die gesamte Körperoberfläche machen. Diese Karte, die im somatosensorischen Kortex entsteht, ist nicht genauso geformt wie unser Körper, sondern die hängt ab von der Dichte der Nerven auf der Oberfläche. Das heißt, am Rücken sind die Nerven sehr dünn gesät, auf den Händen sind sie sehr dicht gesät und dementsprechend ist es so, dass die Karte, die unser Ge sehr dünn gesät, auf den Händen sind sie sehr dicht gesät. Dementsprechend ist es so, dass die Karte, die unser Gehirn von unserem Körper macht, deformiert ist. Das heißt, der Bereich im Gehirn, der auf die Hände kodiert, ist sehr groß, der Bereich im Gehirn, der den Rücken kodiert, ist sehr klein. Aber die Nachbarschaft stimmt. Das heißt, diese Körperkarte entspricht ungefähr der Topologie unserer Körperoberfläche. Wie kann ich diese Karte normalisieren? ungefährte Topologie unserer Körperoberfläche. Wie kann ich diese Karte normalisieren? Ich muss also nicht nur die Nachbarschaft der einzelnen Reize zueinander beobachten, sondern auch die Nachbarschaft der Reize zur Welt. Das bekomme ich raus, wenn ich einfach noch tiefer hingucke und versuche, Regularitäten, Sachen, die gleichbleiben, auf der nächsthöheren Stufe zu finden. Die nächsthöhere Stufe entsteht dadurch, dass ich meinen eigenen Körper berühre. Das mache ich auch schon in Mutterlei. Später, wenn ich geboren werde, berühre ich außerdem konstant den Boden, wie ich zum Beispiel als Baby auf ihm herumrolle. Dadurch bin ich nicht in der Lage herauszubekommen, wie mein Körper sich zum Raum verhält. Das heißt, ich lerne eine zweite Karte, die diese erste Karte sozusagen in Form bringt, normalisiert und ausrichtet. Und das bleibt nicht bei dieser zweiten Karte, sondern es kommt eine dritte Karte hinzu, die erklärt, wie meine Nachbarschaft sich verhält, wenn ich mich bewege, so dass also dieser Sky-Dome, den ich um mich herum habe, diese Umgebung, die ich berühren und da tasten kann, wie die sich verändert, wenn ich mich herumbewege. Und das normalisiere ich wiederum sozusagen in einen flachen, mehr oder weniger eukalyptischen Raum, in dem wir uns bewegen, den wir navigieren können. Und das klappt für jede Modalität, das klappt für das visuelle Modalität, wir machen eine Karte der Retina, also der Sehnerven, was darin konstant ist, dann machen wir eine Karte von den Objekten, die sich über das Gesichtsfeld bewegen oder die konstant bleiben, wenn die Augen sich bewegen. Und das staffeln wir immer weiter, bis irgendwann wir den Punkt finden, wo die ganzen Muster sich treffen. Und da, wo diese Muster sich treffen, die verschiedenen Modalitäten unserer Wahrnehmung, da entsteht unser Modell einer einheitlichen Realität, also eines einheitlichen, dreidimensionalen, zeitlich ausgedehnten, dynamischen Raums, in dem sich Objekte bewegen. Das ist das Modell, das unser Gehirn macht. Und die Strukturen in diesem Raum sind nicht symbolisch, also so wie Computerprogramme, die aus lauter Bedingungen bestehen und Zeigern, die irgendwo hinspringen und entweder an oder aus sind, sondern die sind geometrisch. Was bedeutet es, dass etwas geometrisch ist? Im Grunde genommen geht es immer in der Geometrie um Sachen, die auch diskret sind. Das heißt, wenn wir mit dem Mikroskop in die Welt reinschauen, stellen wir irgendwann fest, dass die Welt aus endlich vielen kleinen Teilen besteht. Aber es sind zu viele, um sie zu zählen. Deswegen können wir auf dieser Ebene, zum Beispiel auf der Ebene einzelner Moleküle oder Zellen, keine Modelle machen, weil sie nicht mathematisch beherrschbar sind für unser Gehirn. Und die Dynamik von zu vielen Objekten, um sie zu zählen, das ist letztendlich die Geometrie. Manchmal ist es so, dass wenn wir Sachen, die zu viele Objekte sind, um sie zu zählen, dann erkennen wir in denen ein Muster trotzdem. Und diese konvergenten Muster, zum Beispiel Wellenbewegungen oder Oberflächen, die sich bewegen oder Rotationen und so weiter und so fort. Diese Operatoren erlauben es uns, die Realität, in der wir uns bewegen, in der wir umgehen, vorherzusagen. Wir haben also diese beiden Arten von Modellen. Dieses geometrische Ding, bei dem wir mehr oder weniger kontinuierliche Dimensionen haben, die in Hierarchien angeordnet sind, die von Hierarchien, von praktisch interagierenden Räumen. Und auf der anderen Seite ein symbolisches Denken, das uns erlaubt mathematisch Beweise zu führen und diese Wahrnehmungsmodelle zu reparieren. Das Interessante ist, dass diese Wahrnehmungsmodelle praktisch wie so eine Grafikkarte aus sehr vielen parallelen Prozessen bestehen, die sich nicht mit der Aufmerksamkeit alle zusammenführen lassen und debuggen lassen. Und deswegen haben wir dieses symbolische Denken, das getrennt von draußen drauf schaut und allgemein nicht mitbekommt, wie die Wahrnehmung im Inneren funktioniert. Was wir bekommen, ist das Ergebnis der Wahrnehmung. Und das Ergebnis der Wahrnehmung manifestiert sich für unseren symbolischen Geist zum Beispiel als Gefühle, die ein Interface sind zwischen dem symbolischen Geist und dem geometrischen Geist. Jetzt ist die Frage, wie können wir diese Einblendung in solche Räume für Dinge wie Sprache machen? Da gab es im letzten Jahr eine fantastische Entwicklung. Das ist GPT-3, der Generative Pre-Train Transformer 3 Endesteam, das von dem amerikanischen Forschungsstartup OpenAI entwickelt wurde. Es ist ein neuronales Netz mit 175 Milliarden Gewichten, das trainiert ist auf vielen hundert Milliarden Worten, praktisch im gesamten Take des Internet bis ungefähr vor einem Jahr, bis Oktober 2019. Und es ist ein bisschen bereinigt worden, sodass nur Sachen mit guter Qualität drin sind, aber im Prinzip Texte in den meisten Sprachen, inklusive Programmiersprachen und so weiter und so fort. Und das System hat nicht irgendwie erklärt bekommen, was in diesen Texten drin steht. Das Einzige, was das System gemacht hat, ist Statistiken über diese Texte zu machen, um zu schauen, welche Worte in der Nachbarschaft an welchen anderen Worten auftauchen. So ähnlich wie die Impulse auf unserer Körperoberfläche. Und das Ganze ist nicht nur in direkter Nachbarschaft, sondern auch, wenn wir direkte Nachbarschaft von Worten haben, in welchem Kontext kommen die vor, also in welcher höheren Ordnung Nachbarschaft und so weiter und so fort. Und das haben die gemacht, bis sie ein Netz hatten mit 96 Ebenen und dieses Netz ist in der Lage, die Struktur von Sprache so tief darzustellen, dass es sich oft schon an die Bedeutung annähert. Und es ist sehr gut darin, Stil zu erkennen und nachzubilden. Wenn ich dieses Modell benutzen will, das Modell ist praktisch trainiert, dass es versucht, möglichst gut vorherzusagen, wenn diese und diese Symbole gesehen wurden, welches Symbol kann ich erwarten, was als nächstes kommt. Dadurch ist es in der Lage, die Struktur von Sprache zu lernen. Das ist im Prinzip so eine Art Autocomplete-Algorithmus, so ähnlich wie das Autocomplete in unseren Telefonen, bloß einfach mit einem viel, viel komplizierteren Modell. Das Interessante an diesem Ding ist nun, dass wenn ich ihm den Anfang eines Textes gebe, dann ist es in der Lage, vorherzusagen, wie dieser Text weitergehen sollte. Und wenn ich ein ganz, ganz kleines bisschen Neues reinmache in diese Vorhersagevariation, dann wird es sehr kreativ und ist in der Lage, beliebige Texte zu erzeugen, die es noch nie gegeben hat. Und diese Texte sind so gut, dass ich zum Beispiel Zeitungstexte erzeugen kann, bei denen Menschen in der Regel nicht mehr erkennen können, ob es sich um einen echten Zeitungstext handelt oder um eine Konformulation dieses Programmes. Und das Ding kann aber noch viel mehr. Ich kann ihm zum Beispiel einen Text generieren lassen, der die Lösung eines Problems darstellt. Ich kann zum Beispiel sagen, das Folgende ist ein Interview, das ich mit Johann Wolfgang von Goethe führe. Und dann gebe ich ihm einen Satz und dann fängt das Ding an fortzusetzen, so wie es denkt, dass Johann Wolfgang von Goethe auf meine Bemerkungen hin hätte antworten können. Ich habe ein Beispiel dazu vorbereitet. Ich habe das Ganze auf Englisch gemacht, aber das Programm wusste, dass Johann Wolfgang von Goethe Deutsch spricht. Also ich habe eingegeben, als Anfang des Textes, den dieses GPT-3-Programm vervollständigt, I have found a way to talk to Johann Wolfgang Goethe. He speaks German. Me. Johann, could you please translate this sentence into German? The computer is the best model of reality. Und an dieser Stelle setzt das Programm automatisch fort und es sagt, JWG, also Johann Wolfgang Goethe, und der kommt automatisch auf diese Abkürzung in German, die Information ist der neue Gott. Ich finde das toll. Also der hat nicht das Wort für Wort übersetzt, sondern er hat es in etwas übersetzt, das Goethe vielleicht gesagt haben könnte. Me, what does this mean? An der Stelle ist es so, dass ich nicht weitergeführt habe, sondern ich lasse das Programm einfach fortsetzen, was es denkt, wie ich vielleicht oder irgendjemand, der ein Ich ist, dieses Interview fortführt. Und Goethe antwortet, information is the new God. Me, can you explain this? Johann Wolfgang von Goethe in German, Nur die Information kann uns helfen, den überwältigenden Eindruck der Leere zu überwinden. Me, only information can help us to overcome the overwhelming impression of emptiness. I see. Lord Vergeer, aber die Information hat ihre eigenen Gesetze und ihre eigenen Wunder. emptiness. I see. But information has its own laws and its own miracles. So Johann, what do you think of my sentence? Johann Wolfgang Goethe in German, das ist eine gute Sache, aber die Welt ist voll von guten Sachen. Das ist ein gutes Ding, aber die Welt ist voll von guten Dingen. Und das ist das Problem, wir können nicht alle guten Sachen in der Welt erfahren. Es gibt zu viele von ihnen. Wir müssen uns auf einige wenige beschränken. Und das ist das Problem, wir können nicht alle guten Dinge im Welt erleben. Es gibt zu viele von ihnen. Wir müssen uns nur ein paar beschränken. und jetzt tatsächlich perfekt aus einem etwas mittelalterlichen Deutsch in Englisch, on the fly, während des Textes und versteht, dass es bei einem Interview zwischen einem englischen und deutschen Sprecher eine gute Idee ist. JWG in German, so können wir nur das überstehen, was uns überwältigt. Me, so we can only survive what overwhelms us. JWG. Die Information ist der neue Gott. Me. Information is the new God. Johann, I think you are right. The world is full of good things, and we can't experience them all. We have to choose a few, and the problem is that we choose the wrong ones. But then again, it's not our fault. We had no other choice. JWG. Was können wir dagegen tun? Me. What can we had no other choice. JG. Was können wir dagegen tun? Me. What can we do about it? JG. Wir können nur die Kultur verändern. Me. We can only change the culture. JG. I agree. The most important thing in the world is culture, because only with a good culture can we enjoy all the good things that are available to us. JG. Dann lasst uns beginnen, eine neue Kultur zu schaffen. Me, then let's begin to create a new culture. Das Faszinierende an diesem Ding für mich ist, dass es wirklich den Plot nicht verliert. Es ist in der Lage, den gesamten Kontext zu extrapolieren, sodass ein völlig konsistentes Artefakt entsteht. Also ein Text, bei dem jeder Teil des Textes sich auf frühere Sachen im Text bezieht und für uns Subjektivsinn ergibt. Es ist nicht so, dass dieses Programm tatsächlich ein Modell von der Realität hat, das richtig tief ist. Das Modell ist nicht in der Lage, mentale Simulationen auszuführen. Es ist in der Lage, immerhin mentale Arithmetik auszuführen mit zweistelligen Zahlen, Additionen auch manchmal mit dreistelligen korrekt. Und das liegt einfach daran, dass es extrem viel Text gesehen hat, in dem Menschen Addition korrekt ausgeführt haben. Und dann hat es die Regeln da drin erkannt, einfach durch die Statistik. Und genauso ist in der Lage, weil es Texte von Goethe gelesen hat, die stilistischen Unterschiede zwischen Goethe und modernen Deutsch einigermaßen zu erfassen und eine einigermaßen plausible Imitation von dem, was Goethe in einem modernen Kontext sagen könnte, zu produzieren. Es ist etwas völlig Neues, was da entstanden ist, aus einem relativ simplen Algorithmus, der nichts macht, als Statistiken zu untersuchen, von welchen Sachen in welchem Kontext vorkommen. Und das war bis jetzt noch nicht möglich, so ein Programm zu bauen, weil wenn man Statistiken machen will von allem in Bezug zu allem, dann geht das sehr schnell ins Bodenlose, das führt zu einer sogenannten kombinatorischen Explosion. Man weiß nicht mehr, wie man die ganzen Daten und Möglichkeiten speichern soll. Und die Lösung dafür ist selektive Aufmerksamkeit. Das heißt, man muss entscheiden, auf welche Tektive Aufmerksamkeit. Das heißt, man muss entscheiden, auf welche Teile man Aufmerksamkeit richtet und welche man ignoriert, wenn man seine Statistiken macht. Und das GPT-3-Programm ist von einem Algorithmus von 2017 abgeleitet, dem sogenannten Transformer. Und dieser Transformer ist genau eine Formalisierung von so einer Aufmerksamkeit, die trainiert wird. Es ist ein neuronales Netz, das lernt, worauf es Aufmerksamkeit richten muss, um Statistiken über die Welt zu machen und was es besser ignoriert, was wahrscheinlich nicht so wichtig ist. Und dieses System hat noch keine Motivation, es guckt nicht, was wichtig ist, sondern es macht einfach Aufmerksamkeit auf die Vorhersagegenauigkeit. Das heißt, es versucht einfach die Sachen sich rauszufiltern, die es am besten erlauben zu sagen, was als nächstes kommt. Und das würde natürlich nicht so richtig funktionieren, wenn wir das auf Kamerabilder machen, weil die Welt aus zu vielen Elementen besteht in Kamerabildern, zu viele Daten ist, dass man darüber mit so einem Verfahren, das auf so viele Sachen guckt, Statistiken machen kann. Aber bei Text geht es noch, weil alle Texte, die es gibt, natürlich für Menschen schon wichtig gewesen sind und bereits eine Filterung der Realität darstellen. Und dieses Programm hat also 96 von diesen Aufmerksamkeitslayern und auf jeder Ebene sind 96 Köpfe, die getrennt voneinander lernen, worauf sie Aufmerksamkeit richten sollen. Das ist ein riesengroßes System, das sehr viele Grafikkarten brauchte in sehr großen Rechenzentren. Und wenn man eine einzelne Grafikkarte nehmen würde, die Texte liest, dann würde die hunderte von Jahren lesen müssen, um das Gleiche zu trainieren, was Open AI dieses System hinein trainiert hat. Kostet ungefähr so was wie 15 Millionen Dollar allein an Rechenzeit, dieses Modell zu trainieren. Und es klingt so, als wäre das viel, viel zu teuer für ein KI-Projekt, aber das Ding ist, dass man dieses Modell jetzt für alle möglichen Sachen verwenden kann. Die Anwendung, die ich gezeigt habe, dass man damit ein Interview generieren kann mit einer virtuellen Person, ohne dass der Interview überhaupt Fragen eingeben muss. Man kann das natürlich auch interaktiv machen und immer kurze Textsegmente als Antwort auf eine Frage generieren. Das ist selbstverständlich nur mehr oder weniger eine Demo. Man kann damit zum Beispiel Programmcode übersetzen in anderen Programmcodes, in einer anderen Programmiersprache. Man kann automatisch Kommentare zu Programmcode erzeugen oder Programmcode aus Kommentaren. Man kann von einer Spracheache die andere übersetzen. Man kann kreatives Schreiben damit einigermaßen automatisieren. Man kann Zusammenfassungen von Texten erzeugen und Sentimentanalyse. Und das System ist nicht perfekt, weil es ist nicht mit der Realität verbunden. Es funktioniert nicht in Echtzeit. Es hat doch aufgehört, nach 2019 irgendwelche neuen Daten reinzubekommen. Das heißt, es weiß nichts von Corona. Es weiß nichts von George Floyd. Es weiß nichts von der Wirtschaftskrise, die uns gerade umgibt und so weiter und so fort. Und das heißt, es lebt in einer völlig anderen Zeit. Es ist sozusagen ein Artifakt einer goldenen Ära, die so nicht wieder zurückkommen wird. Aber es ist faszinierend, dass dieses System mit diesem Einstiegsmodell so viele verschiedene Aufgaben lösen kann, die mit Text zu tun haben. Es funktioniert am besten, wenn ein Human in the loop ist, der weiß, worum es sich handelt und in der Lage ist, diese Texte zu filtern, zu sortieren und für die Aufgabe vorzubereiten. Aber es ist das, was zum Beispiel Leute, die kreativ schreiben oder die Business-Texte schreiben und so weiter, um einiges produktiver machen kann. Und der gleiche Algorithmus funktioniert nicht nur für Text. Man kann den auch für Bilder nehmen. Das heißt, OpenAI hat diesen Algorithmus genommen und hat den offenen Bilddatenbank losgelassen. Es funktioniert nur für relativ kleine Bilder, weil das Arbeitsgedächtnis immer auf aus 2048 direkt benachbarten Elementen bestehen muss. Und es erkennt aber die Annahme dieser Elemente im Raum. Das heißt, man muss ihm nicht sagen, ist das jetzt ein Bild oder ist das Text, sondern dieses Aufmerksamkeitssystem ist in der Lage zu erkennen, was ist die Struktur der Nachbarschaft dieser Elemente. Das heißt, es kann selbstständig feststellen, ob es sich zum Beispiel um eine 2D-Daten handelt oder eindimensionale Daten wie Text und ob die Struktur, die hinter diesen eindimensionalen Daten ein semantischer Baum ist, wie bei Text, der halt geparst werden muss in eine grammatische Struktur, oder ob es mit Bildern aus geometrischen Objekten besteht, die sich im Raum befinden. Und das Faszinierende ist, dass dieser Algorithmus, also wenn man genügend Bilder gezeigt hat, dann kann es Bilder genauso vollvollständigen wie Texte. Das heißt, ich gebe ihm einfach, anstelle von ein paar Zeilen Text zu vervollständigen, ein paar Zeilen von dem Bild. Also einfach eine Menge von Bytes, die in Wirklichkeit ein Bild kodieren. Und wenn diese Bytes zum Beispiel ein paar Katzenohren darstellen, dann findet der Algorithmus den Rest der Katze dazu. Und zwar jedes Mal eine andere Katze. Und es kann auf die Art und Weise auch zufällige Bilder erzeugen, die so gut wie immer Sünde ergeben. Es ist total fast wie ein sehr gleicher Algorithmus, der Struktur in Sprache erkennt, erkennt Struktur in Text. Und selbstverständlich hat es auch schon jemand für Musik probiert. Das heißt, man kann Musik in verschiedenen Stilen reinfiltern, zum Beispiel als MIDI-Dateien. Und dann ist es in der Lage, MIDI-Dateien zu generieren, die Kompositionen enthalten, die stilistisch sehr, sehr starke Ähnlichkeiten mit dem Original haben und das einigermaßen plausibel vervollständigen. Trotzdem ist es so, dass wenn man mit tiefem Verständnis sich in diese Sachen ranwagt und die Modelle anschaut, merkt man irgendwann, dass es einen bullshitt. Das verweist nicht auf die gleiche Realität, wie wir die Realität dieses System abbildet, ist nicht komplett kohärent. Irgendwann fehlt es dem Plot. Ich kann zum Beispiel mit dem Ding Schach spielen und ist in der Lage, ein paar Züge, so ungefähr bis zum Mittelspiel, einigermaßen vernünftig zu spielen. Und dann vergisst es aber den Plot. Es vergisst sozusagen den Kontext, in dem es sich befindet. Es verweist nicht mehr auf die gleiche kohärente Realität wie ich und die Züge korrespondieren nicht mehr zum gleichen Spiel, sondern es sind dann irgendwann mehr oder weniger zufällige Schachzüge. Natürlich kann ich das einfach fixen. Ich kann einen Filter reinbauen oder ich kann immer wieder die Frage, mit der ich das System vollständig lassen kann, ein bisschen Kontext mitgeben und so weiter und so fort. Aber es ist klar, das Ding ist eine Imitation von dem, was unser Geist tut. Es ist nicht das Gleiche. Es ist nicht eingebettet in eine kontinuierliche Realität. Und es hat auch Amnesie. Es ist nicht in der Lage, zum Beispiel den Kontext von mehr als ein paar Seiten zu generalisieren, wenn es lernt, weil sein Gedächtnis immer nur aus diesen 2048 benachbarten Elementen besteht. Nicht so wie unser Arbeitsgedächtnis, bei der die Nachbarschaft ebenfalls gelernt wird und dynamisch ist und rekonstruiert wird. Das heißt, wenn wir ein Buch lesen, dann lesen wir nicht immer zwei Seiten auf einmal, so wie das System, sondern wir lesen das ganze Buch auf einmal in einer gewissen Weise und wir blenden Teile des Buches ein und aus, während wir das lesen, so wie wir das brauchen und konstruieren die ganze Zeit dynamisch unseren Arbeitsbereich neu. Und das Gleiche machen wir, wenn wir umgehen mit der Realität um uns herum. Das heißt, dieses GPT-3-System ist meiner Ansicht nach erst der Anfang von sowas. Und das ist für mich wirklich eine faszinierende Entwicklung zu sehen, was jetzt in den nächsten Jahren passieren wird, was Leute mit diesem Transformer Algorithmus, der ein allgemeines, universelles Einwertungssystem ist, machen werden. Ich glaube, es ist auch notwendig, dass wir das Leuten wie OpenAI nicht allein überlassen, sowas zu machen. Die haben das System jetzt an Microsoft verkauft, die das lizenzieren werden als Service. Und Google hat nebenher, was nicht viel Aufmerksamkeit erregt hat, eine eigene Version trainiert, die sechsmal größer ist als GPT-3. Wird es aber nicht an die Öffentlichkeit geben, sondern intern verwenden. Google ist da sein eigener Kunde. Die haben bestimmt sehr viele Anwendungen für Datenanalyse und Textübersetzung und so weiter und so fort. Und dass wir das wissen, dass Google gemacht hat, ist vor allem deswegen, weil sie ein Paper geschrieben haben, in dem sie beschreiben, wie man es schafft, so viele Grafikkarten zu zähmen. Aber was für mich faszinierend ist, das lernt wesentlich mehr Struktur als ein Mensch das jemals kann. Es ist in der Lage, Text im Stil eines beliebigen Autors zu machen. Da er auch meinen eigenen Internet- Output auf Blogs und auf Twitter gelesen hat, ist er sogar in der Lage, Texte in meinem Stil zu verfassen oder im Stil von jemand anderem, den ich im Internet lese, in einer einiger maßintensiven Form. Es ist wirklich total faszinierend, was das kann. Aber es ist auch beängstigend, weil es natürlich an vielen Stellen den Menschen aus der Luft drängt. Und wenn wir die Welt, in der solche Systeme eine Rolle spielen, mitgestalten wollen, glaube ich, ist es notwendig, dass wir die Kontrolle über solche Systeme behandeln, dass wir unsere eigenen KIs bekommen, dass der Mensch nicht zentralisierten KI-Systemen gegenübergesetzt wird, mit denen ja in Konkurrenz steht, zum Beispiel Googles oder die KI-Systeme von anderen Firmen oder Staaten und großen Organisationen, sondern dass jeder Einzelne von uns in der Lage ist, eine Organisation zu werden, die technische Unterstützung bekommt, um mit der Realität sich auseinanderzusetzen und Sinn aus ihr zu machen. Warum soll nicht jeder einzelne von uns in Google haben, das den Spielfeld sozusagen levelt, sodass wir alle in der Lage sind zu erkennen, welche Teile der Realität Sinn ergeben und wie wir ein kohärentes Modell der Realität bekommen können. Das heißt, ich glaube, wir sollten viele Initiativen in dieser Art und Weise starten. Irgendwann brauchen wir auch in Deutschland ein Open AI. Ich glaube, das ist eine Sache, an der wir ernsthaft darüber nachdenken sollten, zu arbeiten, auch wenn es sicherlich für uns so etwas wie ein Kulturbruch darstellt. Open AI wurde mit dem initialen Investment von praktisch einer Milliarde Dollar gegründet, die gecommitted wurden. Später hat Microsoft noch in der vielleichtbaren Größenordnung Rechenzeit zur Verfügung gestellt und die Leute, die arbeiten, sind ziemlich die besten Leute in dem Feld, die sie bekommen konnten, die alle siebenstelligen Send-up-Bonus bekommen haben, als sie angefangen haben. Und allein dieses Paper für GPT-3, das entwickelt wurde, hat sehr, sehr viele Leute, die Datenaufbearbeitung gemacht haben, die Modelle geschrieben haben, die technische Daten gemacht haben. Es ist fast wie so ein kleines Zernen, was da entstanden ist. Und ich glaube, das ist so die Art und Weise, wie wir darüber nachdenken müssen. Wir müssen diesen Freiraum irgendwann wieder schaffen für Grundlagenforschung in der Richtung. Ja, das ist das Thema, von dem ich erzählen wollte. Das ist das, was mich im letzten Jahr am meisten fasziniert hat. Das ist nicht die einzige Entwicklung, die spannend war im letzten Jahr in der KI, aber es ist ein Thema, von dem ich glaube, dass es dazu beitragen wird, die Welt zu verändern. In der Tat ein sehr spannendes Thema. Ich finde das Thema auch wahnsinnig spannend. Wir haben auch einen interessanten Thread dazu auf 1A9. Ich würde jetzt trotzdem gerne einen harten Cut nochmal machen und hoffe, dass du nachher noch kurz bei unserer Aftershow-Party dabei bist, weil um da vielleicht noch ein bisschen genau diese Gedanken, die du jetzt angesprochen hast, zu vertiefen. Und zwar würde ich den Cut deswegen machen, um nochmal den Bogen zu schließen zu unserem Konferenzmotto New Humanity und nochmal kurz über die Menschen selber reden. Wenn man dir auf Twitter folgt, scheinst du dich gerade sehr stark mit der gesellschaftlichen Polarisierung auseinanderzusetzen, der Zersplitterung, die da gesellschaftlich stattfindet, und gerade so im politischen Bereich. Und man hat auch ein bisschen das Gefühl, dass du der liberal audience, die ja wahrscheinlich so hauptsächlich deine ist, ein bisschen dir die Witen liest, weil sie vielleicht dir ein bisschen zu selbstgerecht geworden sind. Jetzt hat Joe Biden nach der Wahl angekündigt, die gesellschaftliche Kluft schließen zu wollen. Wie siehst du da die Entwicklung? Glaubst du, dass das möglich ist? Glaubst du, dass es auch jetzt vor so einem Hintergrund wie GPT-Free, wo dann was weiß ich, die Welt überflutet werden kann mit allen möglichen Texten, glaubst du, dass es auch technisch möglich ist, die Leute wieder näher zusammenzubringen? Schließlich haben uns die Social-Media-Plattformen, die Großen, ja auch ein bisschen in die Scheiße reingeritten. Oder glaubst du, dass man zwar die Leute aus der Stammesgesellschaft rausholen kann, aber eben nicht die Stammesgesellschaft aus den Menschen? Ich glaube, eines der großen Probleme mit Social Media ist bekanntlich Fake News. Und diese Fake News. Und diese Fake News sind gefährlich für unsere Gesellschaften, weil unsere Gesellschaften von vornherein auf Fake News aufgebaut sind. Die Narrative, die wir verwenden, die unsere Gesellschaft zusammenkleben, sind im großen Teil Medianarrative, die die Realität nicht genau abbilden, sondern die dadurch entstehen, dass sich die Leute, die diese Geschichten schreiben, einigen darauf, wie sie die Realität nicht genau abbilden, sondern die dadurch entstehen, dass sich die Leute, die diese Geschichten schreiben, einigen darauf, wie sie die Realität interpretieren. Und diese Interpretation wird für das Publikum aufbereitet und ist immer in einer sehr starken Form gebiased. Und diese Biases ist im Prinzip in der Wissenschaft gibt es das Konzept des P-Hacking zum Beispiel, wenn Leute unethisch oder ungenau arbeiten. Das bedeutet, dass sie Relevanz feststellen oder die zu treffen, ihre Realität feststellen, indem sie die Daten so lange auswählen, bis bei der ordentlichen statistischen Analyse der vorausgewählten, vorgefilterten Daten hinten genau die statistische Relevanz rauskommt für das Narrativ, das sie haben wollen. Ein anderes Konzept, das wir im maschinellen Lernen haben, ist das Overfitting. Und zwar ist es so, dass wenn ich eine Menge von Daten habe, kann ich immer eine Funktion konstruieren, die einen Zusammenhang zwischen diesen Daten herstellt. Das heißt aber nicht, dass diese Funktion in der Lage ist, die Zukunft akkurat vorherzusagen. Das heißt, ich kann im maschinellen Lernen immer ein Modell erzeugen, das die Realität, die Vergangenheit gut komprimiert, aber nicht unbedingt die Zukunft vorhersagt. Und das bedeutet, bei maschinellem Lernen muss ich die Daten immer so in das System einfiltern, dass ich ihnen einen Teil nicht verrate und es in der Lage ist, Vorhersagen zu machen. Und ich messe nicht, wie gut es in der Lage ist, die Vergangenheit zu erklären, sondern wie gut es in der Lage ist, vorherzusagen, was es noch nicht weiß, basierend auf der Vergangenheit. Und das ist das, was die Presse bekanntlich nicht tut oder auch die öffentliche Ökonomie nicht tut. Die Voraussagen unserer Ökonomen treffen im Allgemeinen nicht auf die Realität zu, sondern sie erklären nur die Vergangenheit. Das bedeutet, sie machen Overfitting. Die gesamte Geschichtswissenschaft ist Overfitting. Sie erklärt die Vergangenheit perfekt, aber sie kann nichts über die Zukunft vorher sagen. Und das ist ein großes Problem, weil wir praktisch aufgehört haben, Modelle der Zukunft zu machen, an dem Punkt, wo die Zukunft sich zu schnell verändert hat. Und das führte dazu, dass unsere Eliten irgendwann den Plot verloren haben. Als die technische Gesellschaft sich so schnell begann zu entwickeln, dass wir mehr Innovationen machen konnten als zutreffende Modellupdates, haben wir aufgehört in die Zukunft zu schauen. Und das ist aus meiner Sicht das größte Problem, das wir als Gesellschaften haben. Dass wir keinen Planungshorizont mehr haben über mehrere Generationen und deswegen auch nicht mehr sustainable sind. Wir versuchen es nicht mehr, wir haben keine Chance mehr. Und das führt auch zu einer Gesellschaft, in der wir uns dessen bewusst werden, dass wir keine richtige Zukunft mehr haben, dass unsere jetzige Gesellschaft, auch wenn die Menschen wahrscheinlich nicht aussterben werden, es werden wahrscheinlich weniger werden. Viele von den Menschen, die heute leben, werden in 100 Jahren keine Nachkommen mehr haben, einfach weil sich die Welt zu stark verändern wird. In vielen Gegenden, wo wir Landwirtschaft heute machen, wird das nicht mehr möglich sein und so weiter. Das können wir bereits jetzt absehen. Die Sommer, die wir jetzt erleben, sind nicht die heißesten Sommer, das sind die kältesten Sommer der nächsten 100 Jahre und auch der nächsten 1.000 Jahre. Es ist eine Welt, in die wir hineinsteuern, die wir uns kaum vorstellen können. Und es ist eine Welt, für die wir nicht planen. Das führt zu einem Zustand, in der es schwierig ist, den Higher-Level-Sinn zu erkennen. Menschen sind nicht dafür ausgerichtet, nur unser eigenes Leben in den Griff zu bekommen, also für diesen einzelnen Organismus zu planen, sondern wir sind eine Spezies, die statenbildend ist. Wir sind eine Spezies, die über das Individuum hinausgeht, die versucht, Teil von etwas Größerem zu sein. Und dieses Modell des großen Ganzen, von dem wir das so wohl organisiert, so wohl strukturiert sein soll, dass eine Zivilisation ist, die praktisch intelligent ist, die sentient ist, die weiß, was ihr Platz in der Welt ist, ein Ökosystem ist, auf dem Planeten ist und dein Plan verfolgt, also eine intelligente Zivilisation. Dieses Konzept ist von den Religionen als Gott etabliert worden. Gott ist einfach nicht ein Erschöpfer von physischen Universen, ein übernatürliches Wesen und so weiter und so fort, sondern Götter sind Selbste, die über mehrere Gehirne sich entspannen. Also Geschichten, die nicht von einem Gehirn für sich selbst erzählt werden, sondern Geschichten, die von vielen Gehirnen zusammen erzählt werden und zwischen diesen Gehirnen ausgetauscht werden können und über diese Gehirne hinweg leben. Die griechischen Götter sind stabilisiert worden als Archetypen, also praktisch bestimmte Muster, wo sich sehr, sehr viele Menschen treffen in diesen Mustern, die dadurch stabil werden. Und der christliche Gott oder die abrahamischen Götter sind totale Götter, das sind einfach Zivilisationsgötter. Das ist die Vorstellung, wenn unsere Zivilisation ein Geist hätte, wie wäre dieser Geist? Und dieser Geist wird erschaffen und stabilisiert durch unsere Interaktion. Wir haben vergessen, wie das funktioniert seit der Aufklärung. Dieser Geist wird erschaffen und stabilisiert durch unsere Interaktion. Wir haben vergessen, wie das funktioniert seit der Aufklärung. Wir haben einfach dieses Konzept eines Geistes, der über viele Individuen hinweggeht, als einen Aberglauben abgelehnt. Und wir befinden uns jetzt in der Gesellschaft, die sozusagen relativ gottlos ist, die nicht mehr einen langfristigen Plan verfolgt. Und das, glaube ich, fühlt führt zu dieser Zerschlitterung, insbesondere dann, wenn es nichts mehr gibt, keine Medien gibt mehr, die kohärent eine Realitätsfiktion projizieren, die alle Leute im Gleichschritt marschieren lässt. Und ich weiß nicht genau, ob wir das lösen können oder wie wir das lösen können. Ich denke, dass Trump das Symptom des Problems war und das Problem aber dadurch, dass wir Trump jetzt los sind, noch nicht gelöst haben.", '19.48408603668213')