('<center> <iframe width="500" height="320" src="https://www.youtube.com/embed/pgW59kIiqvo"> </iframe> </center>', " I'm very much interested in studying the human intellect and that's why I entered AI. But I'm also interested in the civilization intellect. If you see a civilization as a thing that makes sense of the universe, then it is quite similar to our own minds. Culture is basically the self of a civilization. Culture is who we think we are and what we want to be. And media is the consciousness of a civilization. It's basically the contents of our attention. That's where information gets shared and passed around. In the same way as consciousness is the contents of our attention, our own mind, and shares and passes information around. And the financial system is a very important part of civilization. It's the incentive regulation system. It's where rewards get allocated. It's a dopaminergic system. And it's very important that this thing works because intelligence is the ability to make models and rationality itself is not just intelligence. It's intelligence plus regulation. And you need to regulate in exactly the right way. A lot of people are very intelligent without having good regulation and they don't get good results. So if what happens if you automate the creation of models? That is what artificial intelligence is all about. AI today is mostly statistics. And that's correct because the mind is doing statistics of the world. AI is statistics on steroids. It's very experimental statistics. And it started about 1950, when Alan Turing realized that we are computational systems and that our minds are making models of the world and that we can start automating this. So we are now past this first age of AI. The first age of AI, people made the models by hand. Like, you make a model of how to play chess and implement it. And the second age of AI, this is what we are in right now, made the models by hand, like you make a model of how to play chess and implement it. And the second age of AI, that's what we are in right now, it's typically called deep learning, and what we do here is we no longer find a solution to the problem ourself, because that's very often too hard, like the game of Go is too hard to find a solution by hand. Instead we build a system that learns to find the solution. We build learning systems, and this is what deep learning is about. And it's tempting to think that the future of AI is going to be meta-learning. Because it's very hard to, by hand, make a system that learns a particular domain, to build a system that learns how to learn. And our own minds are meta-learning systems. We don't have one learning algorithm. We learn how to learn everything. The first generation AI had only very limited learning. The second generation AI can learn everything in a single problem domain if you find a learner for it. And what's going to happen in the future is that we can learn everything and integrate it into a single model. And this is what people do. We don't learn how to play Go and Chess and car driving in isolation. They are all parts of the same thing. They're part of a larger thing that we can learn and that is what we call the universe. That's basic function that we learn to describe reality. And this is the most important breakthrough problem in AI. The integration of all the models into a single one. If you have such a system that can build scalable models, this has huge consequences. And even learning build scalable models, it has huge consequences. And even learning AI, deep learning, has huge consequences for us. One example is trading. If you have a scalable model for trading and it plays the stock market, and it figures out that there's only 7.5 billion people and they only live for a few billion seconds, it's not so much, right? At some point you can model what's going on there and the system is going to game us in ways that we cannot help against. So imagine you have a trader that has an Ouroboros playbook. They basically eat everything that you make in order to extract reward. You're not into building anything, you're only into extracting reward. You game the reward infrastructure. And we have institutional players that do this a little bit but then it's interested in a longer game. Individual traders play a short game. So as an example the blockchain enabled the creation of new asset classes that outran regulators and still do. And then using the computational equivalent that's been driven by the energy supply of Denmark. That's serious oil being burned for attacks on the economic infrastructure. Now imagine you generalize this into a playbook to game the economic infrastructure. How can the economy defend against such a short player? Because in such a game, the defenders will always have way fewer resources than the attackers. The attackers are willing to reinvest everything. The economy is not going to reinvest everything that it makes into the defense against attacks, because it's meant to be an economy after all. Regulation is meant to be a small overhead. So using artificial intelligence technology for trading playbooks in my view is a very serious near-term danger of AI. Some people in AI are worried about the deployment of AI in weapons. This might kill a few million people. This has the potential of killing billions. If you basically bring down the dopaminergic system of society, it will stop to work. You can no longer buy pizza in such a world. And what can we do about this? It might require limiting the access of traders to the financial system. So only people without monetary interest or profit incentive, institutional players, can play this game. And our regulators are not incentivized to implement such regulations. So at some point, it's almost inevitable that we push humans out of the loop of this regulation. Whenever you have a competitive situation and you are versed with a human in the loop, you will need to push the human out of the loop. And this will happen in combat inevitably, so there will be AI in weapons. There's no way, because otherwise you're going to lose, because the AI is going to use the web more efficiently than a human in the loop. And such a thing also happens increasingly in trading. You see a number of companies gearing up to use AI technologies in trading and more and more pushing humans out of the loop. So what is the consequence? What we have is a trader that eats the economy and in order to deal with this, we will have to have regulation in real time to deal with attacks on the system. And eventually, we will need to have something like an AI regulated financial system, where the financial system itself becomes an intelligence system that models the world in real time and deals with it. But this also means that we are going to cede a lot of control to such a system. And it will be very difficult for us to intervene in such a system in the human interest if we don't set this up in the right way. Thank you very much for your attention. â™ª", '4.872571706771851')