('<center> <iframe width="500" height="320" src="https://www.youtube.com/embed/rDnEoyye86A"> </iframe> </center>', " I think there are going to be five talks, so if you have questions, jot them down and try to fit some of them in the end of the panel. I'm going to talk a little bit about why I think that AGI requires integrated models of cognition, why graphical architectures are a good idea, and about the Microsoft framework itself. I'm not going to talk about this a lot, because we are very short on time. And one of the reviewers asked me in his review why I would think that a graphical architecture would be a good question in the first place. And I think this is one of the points that we should briefly maybe elucidate. I believe that one thing that we should be thinking about briefly is what's actually consisting the biggest problem of AGI research? Is it that we do not have a proper roadmap, that we lack tools for evaluation? Do we need to understand things like creativity better? Do we need to focus on empathy and communication? Is the biggest question of AGI research maybe the existential risk that comes with it? Or is it a question of getting sufficient hardware, more parallel hardware, faster hardware, better CPUs, cheaper hardware? Or is it a big topic of funding, how can we get our research funded and so on? And I don't doubt that all of these questions are extremely important and interesting questions, except maybe for the funding questions. But I believe that the really biggest question of all of them is that we don't know how to achieve AGI at all yet. And I don't mean in the sense that we don't know how to achieve, say, mortality, or that we don't know how to achieve turning into godlike beings or whatever, but in a very mundane, secular sense. More like that we didn't know how we can achieve sorting a few hundred years ago. I do think that's entirely doable as a computer scientist. And I don't think that it can be difficult, because nature gets it right so many times by just kicking a lot of glue in the right place in our head and making it or constraining it sufficiently to perform all these cognitive operations that we also cherish. But we just don't know how to do it. We know how to do sorting. We can program this. But we don't know how to do AGI, because as programmers, if you know how to do sorting, we can program this, but we don't know how to do AGI, because as programmers, if we know how to do something, that means we have expressed it as a program. And so the big question is, how do we find out? And we already have good ideas in which corners to look, but still, we are far from knowing how to do it. And I don't think that the problem of AGI is to get a single paradigm perfect, like deep learning, make deep learning better, or optimality theory, or deep learning logic-based systems, or solve the ripple of language, or whatever. But instead, I think that we need to make progress in many areas. And this needs to lead to good enough solutions. And these good enough solutions need to cover things like autonomous decision making, and reflection, and adaptation, and the acquisition and the control of internal complexity. So how can we build a system that makes itself more complicated, but makes sure that this complexity is also regulated? How can we get perceptual processing in such a system? but make sure that this complexity is also regulated. How can we get perceptual processing in such a system? How can we achieve the basic cognitive operations and enable language and logic and so on to them? How can we get such a system to interact successfully with an environment and with other agents and so on? Then questions like resource management, attentional processing, any time characteristics, and so on. How can we work with limited resources? And I don't think that there is a single paradigm that can address these things, like building robots or focusing or embodiment. It would probably not be the right level to solve this host of problems. Or looking at neurons and brain architecture might not be the right level either. But I think that the biggest problems that lurk in the uncharted territories, those things that we do not understand very well. Personally, I totally agree with Maggie's talk that motivation is a very important topic that is attaching relevance to content. But I don't think that's a very difficult one. But this might be self-deception because I've been working on motivation for the past 10 years or so and now I think that, okay, we can set up a system with a finite set of drives which also make the system autonomously explore social domains and cognitive domains? But it is an important question, but it's one I think that can be solved in a decade of research and so on. But the really tricky things are maybe in the perceptual domain, how can we encode percepts properly and do perceptual learning bottom up and on the the other hand, do concept-driven hypothesis formation top-down. And you do this both with modal and amodal representations. And how can we reconcile this with parallel and fuzzy processing domains, like the associative operations on memory and analogy finding and pattern recognition and structured association building and so on? How can we reconcile localist representation with these parallel and passive processing domains? And we also need these localist combinatorial processing operations to get to planning and language and constructive thinking and so on. And the biggest deficits are not just in these different topics where we do lots of stuff, but in how to understand how these things are intertwined, how we can get them to play together, and how can they be combined to form all those abilities that we have. So as an attempt of getting there, 2002 we started work on the cognitive architecture micro-design, which is based on the cognitive architecture of micro design, which is based on work by psychologist Dietrich DÃ¶rner. Unfairly, you remarked that most AGI research doesn't use a decent theory for psychology, and this might have to do with the sparseness of decent theories in psychology, because psychology, unfortunately, is not a theory-driven discipline, and you don't get any points for trying to publish a theory in psychology. This is not how psychology works, which is unfortunate, because it means that we have to do it ourselves. We have to do this, maybe not in artificial intelligence, but in something broader and more cognitive science domains. Unfortunately, cognitive science over the past decade or so has turned into neuroscience, which brings us to AGI. So I guess that our job as AGI scientists, in some sense, is to come up with a decent theory of what a mind is, that is, with a decent theory of psychology. And this is baby steps towards such a theory. So it's an integrated architecture with round representations, and it has cognitive modulation. This modulation can configure the system in such a way that emotional states emerge. And it has a motivational system, which gets the system to set its own goals autonomously, including social and economic goals. And the whole thing is graph-based architecture. We are currently doing, since four or about a year now, a re-implementation of the system. When we started 10 years ago, software development was very different from what it is today. Back then it was all Java and XML. Today it's much more agile. We have the same functionality in a fraction of the number of lines of code. It's much more easy to work with this. And our focus is on making this thing readable, understandable, and we are putting together an open source version, which people can access on GitHub, which they can use with the browser without installing anything. So it's fast. One of the main goals is how can we explore ideas. And the representations in there are built on graphs, strictly speaking on hypergraphs, and they use threading activation networks as the dominant principle for their computation. That's a paradigmatic difference to other systems which use logic or rule-based systems or which try to mirror biological neurons as closely as possible, the spike trains and so on, or a combination thereof. But it's not a computationally different thing. It's a different way of taking a perspective on what the thing does. And since our goal is to get models as researchers of how we can look at the mind, we find this a very fruitful perspective. So our agents are built on universal mental representations which are compositional and distributed with the same formalism. There are a simple threshold element at the root of this, which are combined. It is writing activation networks, and we can use them to express points and scripts and associative relationships and so on. The basic building block of this is what we call a concept node. A concept node has a single slot and a number of gates. And these gates are tantamount to the link types. So we have a very small finite set of link types. And most of these links are causal in some sense. And taxonomic, the is-er, has-er, is-er and the inverse relationship. And then we have the partonomic relationship. This is a has-a-been-is-part-of relationship pair, which is, in some more general sense, attribute relationship. And we have type activation of different kinds, which is spread throughout the network. And together with sensors and actuators that do relate the system to operations on the environment and within itself, we can build more complex things and complex relationships. So the basic relationships are partonomic and categorical. We also have a simple relationship, which is useful for connecting these things to databases and so on for programming purposes. And then we have a horizontal-alternate-analyzing relationship, which is a predecessor relationship that usually expresses causal linkages. These concept nodes are a special case of nodes. We have n slots and n gates. The gates have a gate function and several parameters. In here, there's a node function. And in the simplest case, the node function does nothing but transmit activation from the slots, which are the activation things, to the gates. But they can do more complicated stuff. So we can hide arbitrary functionality in there and build arbitrarily complex agents with these node nets. And all of our agents are built using these spreading activation networks with nodes. Activation spreading can be seen as a special case of message passing via matrix multiplication. And we have constrained the activation spreading according to the links, so we don't have runaway activation usually in these forms of early spreading activation networks that don't occur. We implement structural inheritance as co-activation of concepts. We have different speeds for activation propagation. So this enables us to build simple hypergraph capabilities in the systems, because sometimes we need conditional linkage in the graph. We will typically only have connections between nodes which are independent of the connections that these nodes have to other nodes. But if you think about conceptual domains, very often you need conditioning connections, that is in the context of one concept, a concept has a different meaning than the context of another one. So we need hypergraph properties. Okay, and we allow, this allows us to have a combination with neural learning and associative retrieval. I'm not going to go into details just because we are out of time, basically, already. The Microbsci framework builds all these agents out of these nodes and can connect robotic domains into virtual environments. Usually, we use virtual environments because robots at this point provide very poor affordances. It's very difficult to build a robot that can climb a tree, rip down a bit of wood, construct an X from it, or whatever. And it's not that difficult to build equivalent operations in terms of discoverability and combinatorial richness in a virtual environment. The framework is built on a server application with a runtime. And the server allows us to distribute this over networks. And people can use it over the internet without having their own installations. We apply this to research with psychologists, which use the model for human problem solving and expressing personality properties as variations of the motivational system. And also commercially, where we have microbsci as the core of a platform for acquiring social knowledge by monitoring how people plan in a social domain, abstracting over these plans. This work is only possible because of my co-workers, especially Dominic Verlandt, and it's supported by the Pot Heaven AG and the Berlin School of Mind and Brain. You can find some more information on microbsci.com. There's more to be coming soon when we put the open source version of the current edition online. And I'll be looking forward to questions during the panel and later on. Thanks. Bye. you you", '9.75947380065918')