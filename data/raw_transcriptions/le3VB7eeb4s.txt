('<center> <iframe width="500" height="320" src="https://www.youtube.com/embed/le3VB7eeb4s"> </iframe> </center>', " Thank you Glenn, that was amazing. You really got me there for a minute. I had this, I was really tempted to pack it up and start completely under the headline of cognitive science to understand how mind does, can occur in the physical universe. And then I realized that it's just about the application of neural eye technology to engineer vandal systems to blow up people. I mean, when you get the applications, but what you're actually doing it, I'm an analyst of cognitive science. And if I look at this, it looks pretty much as what we do at the head of AGI on AI, which is supposed to be different. And if I look at what people are doing, apparently, in collective science, it looks more like engineering. How would you put that together, to ask the first question? unpack the question. So I think any time you want to go from science to application, you've got to endure the engineering that needs to be done. So it's incredibly rare, maybe completely absent, where the science transitions directly. So I think the cognitive science and related fields have provided a number of insights over the last 30 years that provide the foundation for developing a variety of capabilities and applications that are relevant in a variety of areas. It's not all about blowing people up. In fact, only a small portion of it is about blowing people up. Just to remind everybody, I talked about 15 monitoring and training applications of cognitive science work. And those are, I think, extremely general applications of the science of cognitive science. Thank you. Paul? So I think you have the mobile microphone. Yes. I'm willing to help. Definitely. I'll just give you the audio. Question for Kristen. I'm not sure I understood correctly. Were you claiming that AGI systems are not subject to the issues of computability, or were you saying something else there? Because certainly everything in computation, whether you think of it as algorithmic or not, is subject to these limitations. Yeah. So in one of the slides, we pointed out that there are two senses to computation that are used intermingling and interchangeably, but they have very different implications and meanings. So computationalism can mean the very narrow algorithmic view, which is the foundation of computer science, but systems are not algorithms. And so in that sense, if by computation you mean whatever a computer can do, you really are talking about a much larger set of things and phenomena. And just like the Turing machine focuses our attention on the wrong points, in my opinion, too strong a focus on algorithms will essentially blind you to a lot of things that have, that are very different, of different nature. So, are you then claiming that in this broader world, the limitations on computability don't hold? Is that the claim? Because Turing machines are a model for all of what computers do. And computability... No, it's not. Are you saying that this is the version of interactive computing is somehow different from... The Turing model doesn't deal with time, for instance. It doesn't deal with resources. It's a very simplistic model I mean yes you could say it's general but it's general in the way that it ignores things it's not general like E equals m g squared like you know tying very complex things together and a coherent whole it's simply it's general in the sense that you know it's very simple. It is simplistic. You are claiming that computers can do things that are non-computable because somehow they are more general. No, I am saying that the Turing model of computation is incomplete as to cover all of the things that matter in cognition and computational things are the things that computers can do, yeah. So for instance, computer networks don't implement an algorithm. It's an interaction between algorithms, but we don't have an algorithm for describing the internet, for instance. Well, but just to be clear, I mean, it would seem on a mathematical basis that anything you can implement in a software, in a programming language, on a digital computer could, if you wanted to, be modeled in terms of a Turing machine. Now that may be an awkward, or annoying, or useless way to do it. Not without looking stuff out, that is really important. That just seems mathematically wrong to me. Well, you know, I guess that's what's underlying the policy. The mathematics that describes time properly, and you know, all this. Well, but I... You need the time model to do it. Well, are you saying that you need the continuum to model time and the discrete series of time steps is not adequate? I'm saying that the mathematics we have don't really describe very well the wide variety of systems that are important to either biology or... Well, I mean, I agree that the Turing machine model is useless in practice for designing or describing... I think a related point, I don't know where the speakers would stand on this, but I think a related point is that from the standpoint of the theory or the mathematics of information processing. A lot of what I just saw is stuck in like 1940. So it's not like when COX-I and AI got started soon after the Turing machine model and other equivalent models, the lambda calculus was mentioned. It's not like people working in those fields stop working. And the comments about philosophy and AI, I think, are well taken. But this is Dennett's problem. He keeps talking about Cogstock and AI as if it's out of 1940. Turing himself in his dissertation exceeded the Turing machine. That was the point of his dissertation. Church came to him and said, is there a way to exceed it? He said, I'll look into it. And that started a long train of work. Now, you might say the math is irrelevant to AGI, but the math is out there. And I think Chris is entirely right. That math is there, it's different. It may or may not, depending on the case, irreducible to ordinary turn-of-the-change computation, but that's a very real development, and I suspect the fields will have to decide whether it's relevant to them. You don't see it at COGPSI. That's true, but it is out there. I remember that you once made the objection, for instance, that cognition could not be expressed on the Turing machine because cognition is not reversible, whereas Turing computation is always reversible. It seems to me that this can probably be fixed by adding, for instance, a random number generator on operations that happen in the Turing machine and then make the operations that happen on the Turing machine also reversible, because we don't know that stochastic element then. And in this sense, it's fixable. But there is a debate here about, let's say, the question whether cognition needs inheriting more or less than Turing machines, and what is more or less is, so rather the notion of Turing machines is practically meaningless or not useful for describing the interactions of say large scale neural networks or of other calculus or any other paradigm that we have in an implemented computing system. This is a different question. There is this theoretical question, what's the right approach to understand the limits of computational systems. And right now, I didn't go into this in 15 minutes, because if we start to discuss whether, like, like Aronson suggests that in certain circumstances, some kinds of quantum computers can exceed PSPACE or outside, outside of PSPACE, which most people, including the indulgence, so I don't believe they say that that, as I think is currently the canonical view, quantum computing can be implemented on classical computers effectively but not efficiently. And on the other hand, it's not clear how that is relevant to understanding cognition. There is this other notion whether we need hypercomputation in order to explain cognition. There is this other notion that we need hypercomputation in order to explain cognition. And this leads us into metaphysical territory because it's arguable that if hypercomputation exists in the physical universe, we wouldn't be able to measure it. Thank you. I just want to be unambiguous. I'm not taking any stand. I'm just reporting the brute empirical fact, OK, that that part of formal science, which, let's say, culminated with Church's thesis and a deep understanding of that level of computation, trust me, and I think you know, that did not stop. It still goes on to say that there is a way to do it. understanding of that level of computation, trust me, and I think you know, that did not stop. It still goes on today, and for every single conference of this type, there are in conferences where mathematicians, logicians, and theoretical computer scientists are working on the math, and still going forward. Now, whether or not that's relevant, I agree, to AGI or not, that's a separate question. I'm just saying it exists, and specifically what Chris is saying in general corresponds to those developments where people labor over those issues and the better models that was called. What's the math called that exists out there that will deal properly with time? This isn't a... I'll tell you, process algebra is really primitive. If you want to try to describe a triple loop with an influx of energy and constraints of time, be my guest. But I think it will search long and hard to find that. It's not gift-wrapped, but whatever the phenomena that you describe intuitively that worries you about a conventional model is going to have some correspondence in the minds of a formally inclined person concerned about it. So if it's a view of time that is not discrete and naive, then you would need a computing model that treats time differently in those things. Unconventional computing is a conference, for example, that routinely treats those kinds of models where there's a breakage from discrete linear, you know, set paradigms of time. So again, I'm not saying that one of these things is gift-wrapped, that you can take it out of the box, but I understand the other part of what you said, Chris, in your presentation, that there's a breakage of relevance. I think this is where Paul was trying to get at, and I guess I'm the same puzzle, but you know exactly what are you saying. But the part of what you're saying that pertains to the inadequacy of a standard, simple model for a Turing machine, I absolutely, and that is the engine for lots of what these folks are doing in unconventional computations. Part of what I'm saying is an over-reliance on formalisms today is premature for AGI. I'm not saying computer science is useless, that would be idiotic. I think there's the story about the guy looking for his car keys under the street light because it's the only place where the light is. I very often get that feeling. In biology, people struggle to find the proper math to describe even simple processes themselves. I don't see why we should assume that the math is proper for our task, that it's any simpler than what happens to the cell. But I don't know. OK, I think that we are almost at the end of our session. I would like to also briefly direct your attention to this amazing list of requirements from the New World's Physical Symbol Systems. And I think if you look at this list, most of us will probably agree that we would tick almost all of the boxes. Personally, I would be a little hesitant with 11 and 12, a right to evolution, and be realizable within the brain of the physical system because both of them are methodological decisions with an AGI that could or not, could not be adopted. But everything else seems to be extremely relevant to me today, which is amazing since now it's 2014. extremely relevant to me today, which is amazing since now it's 2014. Yeah, a quick question for the whole panel. I think for Josh I first have to ask because of your final statement, do you think that there is such a thing as a science of engineering, because you said AGI needs to be science and not engineering. And if so, perhaps we can convince you that there is a science in engineering. I'd ask each of the panelists, do you feel that there are advances that need to be made in the science of engineering before we can succeed at AGI? If you have speculations about that, they might be, that'd be great. 15 seconds or what? That's a very interesting meta question. I think that there is, there can be a science of everything, because to me, science is basically every systematic, critical pursuit of knowledge. That is, for me, the definition of science. The methodology arises from needs to be systematic and criticisable and then will develop depending on the subject. And of course there can be a science of engineering and because we do lack some critical parts in our sense of engineering, for instance, how can we split the task of realising all those things of a very large team of people with very diverse expertise and physical locations and funding sources and get them to work on a common goal. How quickly for instance, there are not people that would want to do HCI right now in the world. The manpower is there. They have time, they are able to write Wikipedia or play games on the internet. It's all there. If you come up with an algorithm to divide the task in small snippets that people can then crowdsource together, maybe we are there yet, they are in a week. But like the science of engineering to do that. So maybe this is the answer to your question, but I don't know if it's a serious enough answer. Should we let Paul have the last word? Sure. that I want to know long-term questions to other computer science science whether I science or the just engineering my own definition of science is very similar to the options I won't say it but to me I was always did a science go back to her assignment science of the is very similar to Yashin's, so I won't say it, but to me, AI has always been a science. I mean, if you go back to Herb Simon, science of the artificial, I try to go a step beyond that and say, you don't need the artificial there, that science is in fact about understanding everything, whether it's natural or artificial. So there's a science in AI, which is about understanding intelligence and how intelligence can work in a machine. There's an engineering side, where you're building things to be useful. So AI includes both science and engineering because there's both understanding of the phenomena and sort of leveraging those phenomena to change the world. And I think AGI should have those same two components also. Thank you. All right, well it's not that far after 6, so I think we should quit while we're ahead. Thanks for an excellent session on the outside API. Thanks everyone for persisting through four long days until the end, and hopefully we'll see many of you next year in Berlin. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. outside ATI. Thanks everyone for persisting through four long days till the end. And hopefully we'll see many of you next year in Berlin. And thank you so much, Ben and the organizers, for hosting this wonderful event. Thank you for all the inspiration from the audience and wonderful discussion. Thank you.", '9.753567934036255')