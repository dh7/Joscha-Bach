('<center> <iframe width="500" height="320" src="https://www.youtube.com/embed/Jr7gY3JyzP8"> </iframe> </center>', " Translator 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 The reason why I entered academia is because I am really, really interested in how our minds work, who we are, how we function, how we relate to the universe. And I found that our best bet in finding out how we work, who we are, and what our minds are, is artificial intelligence, because it allows us to test our theories by building computer programs that process information in very much the same way as our brains do it. And thereby, we see what we don't understand. We are right now in the middle of a revolution, the revolution of deep learning. It arguably started about in the spring of 2012, when a team of engineers from Stanford, led by Andrew Ng, started to build a neural network. And they took about 10 million randomly selected frames from YouTube, put them into it. And this neural network had run for three days on 16,000 CPU cores. And after these three days, it was able to recognize images, even though it had never been told that it was looking at images in the first place. It was just looking for structure in the data that it had fed into this network. It was completely naive. So, after three days, it was able to recognize about 16% of the images that the researchers showed this neural network and they used a database called ImageNet, which has 20,000 different image categories in it, and the result was 70% better than anything that existed at this point. It also was able to gain internet fame because it was able to recognize cats with about 75% accuracy, which is not that surprising if you think it was trained on YouTube, right? ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Deep learning is about building feature detectors, hierarchies of feature detectors, pattern matchers, hundreds of layers in some of these systems. And we train them by using a method that we call gradient descent that slowly adjusts the weights of the links to minimize recognition errors. These networks have made tremendous progress in the last four years. Just last year, they got better than people in recognizing images in the ImageNet database. They also got better than people in playing Pac-Man. This year, they outperformed humans at playing Go, which surprised a lot of people in the artificial intelligence community because we thought Go is so complex that it's going to stay out of reach of machines for quite some time. Elon Musk hopes to give us self-driving cars in two years from now. Google thinks it's more like four. And no matter how long it takes, self-driving cars will probably be a reality in our streets very soon. So how can we bridge the gap between these systems and minds? Because they are clearly not minds. There is a vast difference between these deep learning systems and who we are. When we think about minds in the context of artificial intelligence, we often think about the Turing test. That is, how can we build a system that makes a human think that it is intelligent? Actually, I think that the Turing mistake might be a slight misunderstanding. We need to go beyond this. I think we need to look for systems that are able to perform a Turing test on you. Because you know, when a system has understood that it has a mind that is conscious of certain things, that it understands certain things, it might start looking for systems like itself in the world. And in fact, that's what we do with each other all the time. When we talk to each other, we try to find out what the other person is conscious of. Because we have realized, this is something that I understand. Do you understand this too? Are you a mind in this area? How can we get to such systems, and how long is it going to take? When Mari Minsky started the field about 60 years ago, he said it's going to take us anything between 4 and 400 years. I believe we are very much on track with this prognosis. Right from the start, the field fell apart in two streams which you could call cognitive artificial intelligence and narrow AI. Cognitive AI is about understanding minds by building computers that think, how far we can get there, I don't know yet. But narrow AI is about building better data processing. And this is the vast majority of the AI systems that we see today. They are narrow AI. So imagine we get a system that has to look at a picture like this and find the dancer, Alyssa Maxim, in it. How would you go about this? Our algorithms, what they basically have to do is, they have to filter out everything that changes about Alyssa all the time. So they have to filter out her particular pose. They have to filter out the lighting of the image. They have to filter out her dress, her facial expression. And the only thing that is left is what's never changing about Elisa. Right? But this is not how we do it. We might start with the same low-level input as our algorithms, but we create a complete world. We don't filter out the facial expression. We keep it. We keep the dress, and the lighting, and the pose, and so on. And we form a mental world. We don't filter out the facial expression, we keep it. We keep the dress and the lighting and the pose and so on. We form a mental world from it that has lots of interacting elements. This mental world is built from percepts and then extended into mental simulations. The percepts are built by finding order in the basic patterns that are a systemic interface to the world and the simulations are the mental world that we live in. It's the virtual world that our brain creates, that gives us an impression to live in a world with sounds, and moving objects, and people, and ideas. So, our minds are not classifiers. They are simulators and experiencers. Actually, you and me, we are not organisms. We are the side effect of organisms that need to do information processing to regulate the interaction with the environment, right? Most of the information processing of organisms is done with simple feedback loops. For instance, in our brainstem, there are many, many feedback loops realized that regulate our body temperature, our breathing patterns, our heart rate. But often, feedback loops are not enough, you need to change behavior. For this, we have pleasure and pain. Pleasure tells you, do more of what you're currently doing. Pain tells you, do less of what you're currently doing. We have many kinds of pleasure and pain. They are all related to needs that we have. These needs are social needs, physiological needs, and cognitive needs. And most of my work is concerned in figuring out an architecture that regulates all these needs to find goals. Because we humans are not just goal-directed systems. We are goal-finding systems. In the first place, we find goals to satisfy our needs and avoid getting hurt, to frustrate our needs. These needs are what make us distinctly human because they direct our interaction with the environment in very specific human ways. To associate these needs with situations in the world, we have the hippocampus. Many animals have a hippocampus. It's the brain region that is able to associate stimuli with needs and behaviours. So we have impulses that direct us to seek out certain situations in the world. But very often, these patterns are not enough to recognise a situation. Food can look very, very different depending on the context, right? So we need something better than this. And for this, we have our neocortex. This neocortex creates mental simulations. It creates a simulated world, the world that we live in. To do this, it needs to have representations that are compositional, that can be put together like Lego bricks. Individual neurons cannot do this. Individual neurons are like plants, each of them is slightly different. They cannot learn how to fit together thousands of different neurons depending on the context, and you need to switch that context. Imagine you're reading a page in a book. When you read the page in a book, you read all the concepts in there and you put them together into a mental simulation. You basically hallucinate a scene, right, that is in this book. When you read the page in a book, you read all the concepts in there and you put them together into a mental simulation. You basically hallucinate a scene, right, that is in this book. And you close this book, you open up another book, you take this hallucination apart and you create a different simulation from pretty much the same elements. How is it possible that these building blocks fit together? We currently think that our brain uses small circuits, cortical columns, that are each made of a few hundred neurons. And they provide this interface so they can fit together about 100 million of these building blocks. The cortical columns talk to their neighbours and thereby they compute functions together to produce mental simulations. They link up in brain areas and they also talk to other brain areas further upstream and downstream in our cognitive processing. The muscle part of my work is concerned with how these systems can self-organize, how these cortical columns can talk to each other and link up in a structure like this. Imagine that these brain areas are like an orchestra. Each of the brain areas is like an instrument playing a part of the music of our mind. These instruments listen to the instruments in their neighborhood and use some of the ideas that the other instruments are producing and weave them into their own melodies and pass them on. This orchestra also has a conductor. This conductor is not something like a superhuman being sitting inside of the brain. This conductor is not something like a superhuman being sitting inside of the brain. This conductor is an instrument like the others in some sense, but it's listening to the surface of what the other instruments are playing. And it pays attention to whenever conflicts need to be resolved. It will tell some of the instruments to pipe up and to pipe down. And it will decide what's being played tonight. If you do not have this conductor online, then you will become a sleepwalker. A sleepwalker can still do most of the things just like the instruments and orchestra can play their music just fine, but they're going to play it on autopilot without a common organisation. A sleepwalker can get up and open the fridge door and make dinner, and you even cannot answer simple questions, but there will be nobody home. There will be no reflection, no goal-directedness. This conductor will pay attention to the different units. And most of it is subconscious, and some of the things that need to be resolved and controlled will be maintained by the conductor. The conductor keeps a protocol of what it attended to. This protocol is the only place where our experience is integrated. In the brain, it's probably maintained through the help of the dorsolateral prefrontal cortex. This integrated experience gives us a memory of what just happened, of what we experienced. This memory, by accessing this memory, we can perceive ourselves as being conscious, of having been conscious of sequences of things over the last moments in time. I call this the conductor theory of consciousness. This conscious stream allows us to tell us a story about who we are. Ourself is not our brain. The self is a story that the brain tells itself about its actions. So, what I would like to do is to build a system that is able to stand the two Turing tests, a system that is able to dream a world, and that figures out that it has a mind, and that can perform a Turing test on you. Thank you. Applause you", '10.644628047943115')