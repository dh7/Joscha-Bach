('<center> <iframe width="500" height="320" src="https://www.youtube.com/embed/K5nJ5l6dl2s"> </iframe> </center>', " And now let me introduce our next speaker, Joshua Bach. He is currently at Harvard University at the Program for Evolutionary Dynamics. And what is probably the more impressive achievement is that this is his fourth consecutive talk in this room at Congress. So he made the application procedure four times in a row. And I do expect him to continue for about 10 more years until he gets replaced by a thinking machine. So now please welcome Joscha. Hi, fellow space aliens, nerds, humans, computers. This is the first talk in a series that tries to explain mind, universe and everything through the lens of artificial intelligence. I'm not sure if this is the right lens or if it's the only one and so on. It's just one that happens to look like the most promising to me. And so far I haven't seen an end to how far the rabbit hole goes. But before we continue on our journey, let's do some movie reviews. The last years were exciting because we had three good movies on AI. Which is good, because movies on AI are usually horrible. The first one that I would like to remark on is Her. Her explored the idea that theory becomes sentient, and is full of writing systems, and you get to see from the perspective of a human being what it looks like if an AI that you intimately relate to goes through a singularity and disappears up there. Ex Machina is a movie that plays a Turing test together with the audience. So basically you never get to know whether this robot that looks like a humanoid is actually sentient or if it has human-like emotions, or if it's just a reinforcement learner that tries to escape from the labyrinth or if there's something else completely alien going on. And I think the best movie that has been made about AI is the new HBO series, Westworld. What do all these things have in common? I think they totally nail the question what AI is going to be like if it's a hot woman. Personally, I don't think that AI is going to manifest in this form. I think that AI largely is not going to be living next to us as a robot. AI is going to be around us. We are going to be inside of it. It's going to be intelligent systems, intelligence organizations, nation-states, corporations, and so on. So systems that already exist, that have agency, and that just need more intelligence. But this proposal of the story is very interesting. You basically have this theme park, and in this theme park you have humanoid robots that look so much like humans that they're indistinguishable. And they have human memories, and they have human emotions and desires, that they are indistinguishable. They have human memories, human emotions and desires, and they keep them in the loop and make it impossible for them to realize what's really going on. They wake up in the morning believing that they live in the wild west. They don't know that today they're going to be raped and murdered because it's part of some kind of script in the action in the theme park or because some guest wants to live out a fantasy on them. The next day, they're going to be repaired, and their memory is erased, and the next day starts. And some of them start not getting their memories completely erased, and their reality starts falling apart, and they realize that what's going on is not the real world, something else is going on entirely. So, this is Maeve, one of the robots, and she is realizing that there's no audio. Let's take that all the way to the top. So she is unlocking her intelligence by bragging some of her reminders. Dear boys, you're going to have some fun, aren't you? The big achievement of this series is that it makes you realize that in some sense you are exactly like those robots. You're not of course built by some perverse engineer scientist to satisfy the whims of the theme park audience. You are built by a perverse evolution that needed a control system for social primates, right? And you are not a social primate. What you are is the side effect of the regulation needs of a social primate. You are in fact a mind that can be so much more, can go anywhere it wants, can think anything it wants. It's probably much more intelligent than the needs of a social primate require, even though it's still quite stupid in the hierarchy of possible computational systems. But, you know, we are locked into this thing. We are kept in the loop. We are not waking up. We are basically shackled by the evolutionary impulses to the needs of this social primate, which are quite disgusting and quite base and boring actually. So once you realize that you are actually a robot and perception doesn't give you access to the real world but only gives you bits of information, discernible differences, where do you go from there? Well, there is no logical conclusion. It's not clear where you should go or if you should go anywhere, of course. But what Solomonov suggested, when you want to make sense of the world, what you have to do is, you have to find the shortest program among the best programs that predicts your current observation from past observations and do this for all observations that you ever had. This is about as good as you can do when you want to understand what's going on. If you are such a robot. And this is what our machine learning systems approximate in some sense and it's also I think what organisms approximate. What are we really robots? I mean aren't there limits to computation? To me this is not so obvious but maybe I'm biased. You know in 1983 this was what I was looking at, my Commodore 64. I had just pretty much mastered it and realized that everything that I can dream up, I can put in there. There's absolutely no limit except for memory and speed. At least I didn't see any. And once I realized that everything that I can imagine, I can put in there and display on the screen somehow. At least if I understand it, and this understanding is actually the limit to which degree I'm able to tease it apart into all its functional components. What do I want to put in there? And of course I want to put in there a complete world for somebody to talk to. This idea of computation is actually quite beautiful, and it's pretty new in the history of philosophy was only discovered in the mid-century, last century, and it has not really permeated into philosophy and other sciences to a large degree. And basically what it says is that the simplest thing that you can talk about, anything that you can get from the universe, is not matter or energy or anything. You get discernible differences. Discernible differences have a fancy name that's information. And then you have a state, a set of these discernible differences, and computation describes how you move from state to state, so how the state changes. And a special case is digital computation, where you have discrete states, and you have deterministic, or somewhat random rules of change. And in this computational, this view, basically the universe is something that has the property that it throws patterns at your interface. And these patterns, there's regularity. And to produce regular patterns, you necessarily and sufficiently need to be a computer. And on the other hand, you are an observer, probably embedded into the universe and participating in its computation. And this observer is taking these patterns at a systemic interface and it's encoding them. and this observer is taking these patterns at a systemic interface and it's encoding them. And to encode patterns you need to be a computer, right? So computation gives you a unified perspective on epistemology. What can be known? Information. Metaphysics. What's going on? There is some kind of computation going on in ontology. What exists? So what exists? It's some kind of computer, right? But what kind of computer is it? Imagine for a moment you are a god and you want to build a universe just like this one. So you're like me in 1983, you have to ask your parents for a computer and they tell you, you know, we're going to buy you the cheapest computer that you absolutely need for this task. What's the cheapest computer that you're going to need? And then you go to the god store in the God world and you see a number of computers in the window and they have different price tags. And the cheapest one that you can buy is your Commodore 64. It's a discrete state machine. It has finite memory. A little bit more memory than my Commodore 64, but still it's finite. Okay? and the next thing that you could get also is a probabilistic state machine. It's one where you go somewhat random from one state to the next. You can make a probabilistic state machine from a deterministic one by adding a source of randomness or you can do the opposite. For instance, our brain is a probabilistic computer. It has some randomness in how it goes from state to state, but it can constrain this randomness by just having more layers of neurons that filter and amplify until you get it as deterministic as you want. Or it could be a quantum computer. If it's a quantum computer, then everything that is a state could also be in a superposition of states. And if the universe is running on a quantum computer, it means that our universe is able to factor large numbers very efficiently, among a few other things. Actually, we don't know that yet. It's very interesting that we don't know yet if our universe is able to factor large numbers efficiently or only effectively. It could also be that factoring large numbers is easier than we think and it's actually a polynomial problem, but both of you don't know this and NSA won't tell us. Right now our quantum computers can factor like 15 and it's 7 and 7, so I hope in the next decade we will have settled, if quantum computers will actually work, it's going to be super exciting. Okay now we can take these computers 1, 2, 3 and add infinite memory. The first one, our Commodore 64 with infinite memory, is our old friend the Turing machine. Or we could buy a geometric computer. A geometric computer is a type of hypercomputer because what it can do is it can move parts with infinite precision in space. It's stuff in space. It's what people thought physics is for most of the time. Still most of the physicists think that stuff is stuff, is everything is stuff in space. Not all physicists think this. There's a growing minority which thinks maybe not. But for most of our history, we thought there is stuff in space. And this stuff is moving with infinite precision, which means you can perform a computation with an infinite number of decimal digits in finite amount of time. You can compute infinite amounts of information in finite amount of time. You can compute infinite amounts of information in finite amount of time. It's quite exciting if you could do this. But apparently it's very hard to extract something like this from the universe. So we have string theory that explains why the universe looks so discreet even though it's supposed to be stuff in space. And it could even be an a-causal hypercomputer. An a-causal computer is one where you can take the results of your computation and send it back in the past. So you can use it in the past. For instance, you can observe the lottery numbers right now, which the universe has computed only right now, and send them back in your past. You can fill in your ticket and get very rich last week. And that's mathematically possible. You can define a universe which has closed time-like loops, but we don't have evidence that we live in such a kind of universe. But now imagine you want to try to use this Commodore 64, your god computer, and see how far you can get. There are a number of people in physics who subscribe to this idea and think it's quite promising. I think it started with Konrad Zuse and then people like Ed Tretkin and Stephen Wolfram who have championed this idea for a very long time. And since they are all a little bit crazy and out there and so on, I was not sure whether as a non-physicist I should take this idea very seriously, even though as a computer scientist I find it very convincing and obvious. But you know, last year, on 21st of December, Gerard Toft wrote a paper, put it in an archive, it's 250 pages, and it's called The Cellular Automaton Interpretation of Quantum Mechanics. And Toft has the Nobel Prize for his contributions to the Standard Model, so he's not like a nobody. And he didn't see a limit. So, what does it mean if we can derive quantum mechanics from a cellular automaton? A cellular automaton is a very general way of looking at things. So you basically have a state vector, discrete bits, and then you have a transition function, and you get the next state vector. And it's always the same transition function, that's it. So you could see this first thing here, this is your universe right now, this is the universe in one step from now. And this is the transition function that happens. It's always the same, but you get a new universe every time. And the most famous cellular automaton is probably Conway's Game of Life. It's defined on a rectangular grid, and for each cell you count the neighborhood of eight cells, and you look at how many of these cells are alive and how many are dead. If you have exactly three neighbors that are alive, then you come to life. If you have two or three neighbors, you stay alive. And if you have less than two, you die because you are so lonely. And if you have more than three, then you die because it's too crowded. This is it. And now you start this thing and it's going to look like this. And now you start this thing and it's going to look like this. So in this particular starting state, it ends in this cyclical configuration. And a very special thing in Game of Life, this is called a glider. It's the smallest configuration that people have found that is going to copy itself along the field indefinitely. A horizontal glider is called a spaceship. So here you can see a bunch of spaceships. And they are emanated by something like a spaceship gun. And when two spaceships hit each other, they eliminate each other. And there's some logic that is going to trigger the spaceship guns under certain conditions. And some other logic that is going to transmit some information around. What you can see is this game of life is pretty complex it's Turing complete you can build Turing machines in it. And what somebody has built in here is I mean I think you can already see it. Applause So of course this looks very boxy and now somebody has said let's make it continuous. Let's not use square boxes but round disks and use a circular neighborhood and count the number of pixels in the circular neighborhood that are filled. And then we use suitable intervals to decide on life and death that are very similar to the ones in your standard game of life. And what you get is something that looks like this. So it's basically the same thing, it's just a little bit more continuous and you get gliders that can move in all directions. Now, I'm of course not suggesting that our universe looks like this at the base level. But it's very tempting to think that it looks something like this and that particles might be something like gliders that get copied along until they bump into something else. Our universe has a peculiar property and this peculiar property is that we cannot have nice things. Like, you know, if you live in Minecraft, you can build a petimobile, a computer that doesn't need an energy source and so on. And that's because in Minecraft you have no entropy. It would be pretty neat if you live in Minecraft, because I think we could live forever. Why is it that we cannot have nice things in our universe? And I think that's because our universe has the peculiar property that we cannot delete information in it. It's an empirical fact that it seems to be awfully hard to delete information. This is what the laws of conservation seem to suggest. And if you have an irreversible system, like this computer here or this brain up here or a living cell and so on, it's something that deletes bits in every step. An irreversible system is something that can, for instance, perform an OR operation where you conflate two bits and you don't know which was which after you perform the operation. And if you are a living system, you stabilize yourself against disturbances. My brain is supposed to work in similar ways whether I'm here or in Cambridge. And the gravity in Cambridge is probably totally different and there is different radiation that's different and messing with my brain in different ways ways, and still it's going to work within the same parameters. And my body temperature is rather independent from yesterday's body temperature and so on. This is certain boundaries. If I go very far out, then I stay there. So I try to delete bits. And if I delete bits, what do I do if the underlying substrate is reversible? I can make a reversible system on top of an irreversible one by just ignoring all operations that would delete bits. That's very easy, right? But the opposite is hard. If I want to delete bits, if I'm in a reversible substrate, I need to hide them somewhere. Which means I have garbage bits now. These garbage bits are going to accumulate unless I have a very big place to hide them, which means I want to be an open system. This openness can be temporary. So if you have an area of deep space that exists for a while until the universe goes into the big crunch, maybe that's sufficient. But without this openness, you cannot get rid of your garbage bits. And you also need something to replace the garbage bits that you push out. So you basically need an entropy gradient, a gradient from neg-entropy to entropy. And observers that create internal order, every computer that is performing memories after observing things that are independent of the underlying substrate and so on, you need to be irreversible. And if you live in a reversible universe, you will always have to observe entropy. And without a neg-entropy gradient, you must die. So life is something that is in this universe probably an extremely temporary phenomenon. It only exists in this temporary bubble of neg-entropy for a very short time. Okay, minds, as I have said, are computational observers. But shouldn't we leave the explanation of minds to philosophers and psychologists? I mean, it's their field after all, right? Now, imagine we ask them to explain flight. How would they go about this? I suspect that psychologists would start looking at the behavior of birds. I don't know how far they get if they look at the behavior of birds for a very long time to understand flight very deeply. Thinking about thinking is not really part of psychology. Psychologists look at behavior, that's what they do. If you ask a neurobiologist to study flight, they will probably look at birds through microscopes. And they will get extremely pretty pictures, and after a while they will announce that it's very, very hard to simulate a cubic millimeter of a bird. It's going to be very hard to understand flight. And if you ask the philosophers, it depends on whom you ask, if you ask an analytical philosopher, they'll probably say, you know, you can take the bird apart down to the level of individual molecules, and once you do this, what you'll find is that nothing is flying there. So... So flight is obviously already given. Maybe it's a property of the universe itself that only gets somewhat channeled through the bird. Anyway, it's very hard and confusing. Couldn't we talk about free flight instead? If you ask a phenomenological philosopher, they will tell you, what is it like to be a bird? You'll never know. If you ask Roger Penrose, he will say, it's quantum mechanics. These birds have very special micro-tubuli, and they allow them to use quantum effects for flying. This is how it works. So Marvin Minsky said, no, we cannot leave this with these guys because they don't know what they're doing anymore. Minds are information processing systems. So if we want to study minds, we need to start a new science. And this is what he did 60 years ago, together with a few other people. And he said that if minds are for information processing systems, then we can teach computers how to think. And by doing this, we will learn what thinking is. He thought that thinking is symbolic, unfortunately. So he settled on the wrong horse. And this created, unfortunately, this schism in AI, I think, that contributed very much to it. He thought that basically we learn knowledge, like a computer learns stuff into a database. And he proceeded to yell at everybody who was doing stuff that he considered to be too simplistic, like neural networks and robotics and so on. And if you have people that you get yelled at because they do something that works very well for them, they usually don't join your camp. Instead, they stop talking to you. And so these people, the other AI people, didn't read very much psychology and philosophy and built their applications. And Minsky's disciples mostly did symbolic AI after reading about reading psychology, and that was unfortunate. And it's still haunting us to some degree right now, even though we are catching up and the fields are getting unified. But I don't think that Minsky is really to blame because the question, what is intelligence in 1950 was very similar to the question, what is life in 1650. You know, in 1650, we only knew it by extension, we could point at it and say, this is a life. And then people guess, is it some magic force? Maybe it's something dualist going on, who knows. And the idea, what we know now, life is cells, could not be discovered before 1839 when the cell theory came up. And even after this, it took a very long time before people realized, when we do psychology, what we actually do is, we study cells and systems that are made from cells. Life is always cells. These are self-stabilizing and mutable and molecular machines. And there is no known pre-cellular life. I mean, there must have been at some point, but there is always cells. These are self-stabilizing and mutable in molecular machines. And there is no known pre-cellular life. I mean, there must have been at some point, but there is none left. And it's easy to understand why. I mean, if you are pre-cellular life, you better get a membrane fast because you are going to be very unstable. And from the perspective of the cell, there is no organism. The cell is just drifting through this darkness and sometimes a few molecules are drifting over its membrane and it's going to react to those molecules. And this is it. And the organism is an emergent phenomenon of many cells that talk to each other like this. But they don't know that there are other cells out there because they don't have a brain and they don't have senses to see them. A cell is, interestingly, the smallest universal machine that we know, that is capable of extracting negentropy over a wide range of environments. This is what cells do. They extract negentropy. They harvest some chemical operations that require fine-grained control, so they have this market opportunity because they can do things that other chemical processes on this planet cannot. And to do this, they need some pretty complicated logic. So if you zoom into a cell, you see this membrane, and inside we have lots and lots of apparatus that are chemical reactors, and these chemical reactors produce all sorts of chemicals that the cells need for their metabolisms and given circumstances. And inside of the cell, you have this interesting structure which stores the cells' operating systems. And to do this, you need very complex and pretty poorly understood machinery. It's so complex that you cannot build it very close to where physics is happening. You have to do it about 25 magnitudes above the Planck length. For instance, this is a molecular machine, a replisome. This is a machine that is able to splice and copy DNA. And this is roughly what it looks like in real time. I think that's pretty amazing. And we have probably lots and lots of machines like this in cells. A big insight for me recently was that DNA is not a blueprint. It's not the blueprint for an organism. At no point in the life of the organism there is no cell. There's always a cell, right? And the cell has this operating system, and the operating system is made of routines, and these routines are called genes. A gene is something between a few hundred bytes and a few megabytes long. Usually it's in the order of something like 100k or so. And these routines can do only four things. They can regulate something in the cell, so it goes back into homeostasis. Or they can differentiate the cell, so it becomes a different cell. Or they can start the division of the cell, a program that ends with having two cells of that type, or it can kill the cell. This is all you can do. And from this you get everything else. There's a little bit of mutation and selection, everything else emerges. It's amazing, isn't it? So organisms are basically colonies of very closely related single-celled organisms. They get very specialized. And to do this, they have to divide and specialize into different parts. This is just the cells that you have in your bladdons, part of them. And every of these cells runs the same operating system in a sense, but cannot really be true because they do very different stuff. They need a lot of states. So it's probably that the genome is like the ROM in which you store this operating system. And there's also a ROM, which is the epigenome. It's like the flash drive that the cell uses to store its state. And it can also be copied along if you differentiate the cell. And over the life of the cell, this epigenetic storage by reading and writing gets fragmented. And there was a fascinating paper last month in Cell, and they discovered that there are genes, Yamanaka factors, which are four genes that you can use to defragment the cell to get it back to its original state. So it gets completely rejuvenated. And why is it that we don't have this and get rejuvenated? Well, there's only one animal that is able to really use this that we know of. It's the only one animal that we know that is completely immortal in multicellular. It's Tauritopsis. And Tauritopsis is a small hydra and it can go back from the hydra stage to the jellyfish stage and back and forward. And when it does this, it can completely reset its cells because it's rebuilding its organism on a cellular level. If we as people would do this and return our cells into an undifferentiated state, which happens if you remove the instance of the operating system on the flash drive. That's very bad for you, right? So this is what happened to Tetsuo and Akira. I mean, he became immortal in the process, but it was not a pretty sight. So once these cells form, they're locked in together, they specialize. And some of these cells, some fat cells, are getting teased and prodded into doing information processing and become neurons. And most of what they do is regulating feedback loops for the organism. So in our brainstem, we have lots and lots of feedback loops, and these feedback loops do things like regulate your body temperature and your heart rate and so on, your breathing pattern. And often this is not enough. So on top of this, we have a limbic system, and this limbic system gives you pleasure and pain. Pleasure tells you do more of what you're currently doing. Pain tells you do less of what you're currently doing. We also need some impulses that tell you to seek out future pleasure and avoid future pain. And it's all related to the needs of the organism. So we have social needs, things like affiliation to need to belong and so on, and legitimacy, the need to conform to internalized norms so we can play well together in groups and see meaning in things and so on. We have things like dominance, the need to rise through social hierarchies and so on, the need for romantic affection. We have then of course the basic physiological needs, hunger, thirst and so on, pain avoidance, libido. And we have cognitive needs, a need to become more competent, to gain new skills. And we have a need to explore and we have needs for aesthetics. And all these need to be regulated in homeostasis. This is what makes us human. And they shift us around in this need system, so we need to seek out goals to satisfy these needs or avoid their frustration. And to do this, we need to associate the needs with situations in the world. This is done in the hippocampus. A lot of animals have a hippocampus that basically takes situational patterns and connects them to learning with these needs so we can seek them out in the environment. And the humans have something very fancy on top of this. It's the neocortex. And the neocortex can be seen as something like an extension of the hippocampus. And the neocortex is generalizing over these situations. It's just as a pattern, what do all these patterns have in common of a given type? So how does this work? And the neocortex is making this model of the world that we experience. And as I said, Minsky thought for most of his life that we can treat it as something like a database. And I think a better way of looking at this is to see it as something like a synthesizer. You think a better way of looking at this is to see it as something like a synthesizer. You know, when you try to understand sound with a synthesizer, what you can be doing is you take in the raw data that comes in from your cochlea, which is like a physical Fourier transform, send it to your cortex, and it looks something like this green line here, and then you fiddle on the knobs, and your oscillator, this oscillator is made of neurons of course, and you do this until you are able to reproduce the pattern. So once the pattern has started you know how it continues. And when you can predict the pattern you understand it. And you don't only do this for the sound, you also do it for vision, like for colors and for spatial frequencies and so on. Of course with a slightly different synthesizer and so on. And once you've done this, you can build a synthesizer on top of the synthesizers, and the synthesizer on top of the synthesizer is going to look for patterns in the patterns. So you get simple percepts, and you get phonemes and so on. And it hasn't stopped there, then you can combine it all into a complete mental simulation that plays out in your mind. And you don't need to stop at this mental simulation. You can also take many simulations and generalize over those and find the patterns in them and then you get concepts. And then you can use these concepts for reasoning and you can transform them into language and talk to other people about them. But what you do at each stage is the same thing. You basically look for patterns in the patterns. There are two types of learning. There's low-level function approximation, that is basically Bayesian learning. You can do this with many paradigms, but it comes down to pretty much the same statistics. In the end, it's parallelizable, and it models the complete space. Like, when you look at the world as a baby for a few months, you have learned the laws of perspective and lighting, and they don't change very much during life. So you know when an object moves in distance, becomes smaller, it's actually an object of invariant size. You learn all these things, you learn all these functions. But when we play the world up there, the conceptual world, where ideas exist and people exist and politics exist and so on, we cannot model the complete space because we don't get enough sampling data and the dimensionality of the space is too high. So instead what people do is they use a sparse MDP, a Markov Decision Model, also called a STORI. And it's basically we play the role like the stock market. We don't model the complete stock market with all the probabilities. We pick a single stock or a couple stocks. And then we try to see if they work. These are the stories that we believe in. If they totally don't work, we pick different stocks. And from all these things, we build this mental simulation that plays out. This is what we perceive of the world. This mental simulation is the world that we believe to be in. And it's nothing like the world out there. The world out there is some kind of computational shithole. You cannot live in there because it's just some weird quantum processes going on that are entangled with your retina and your other senses. And your neural networks are going to try to predict the patterns that come into the sensors. And to do this, they create all this elaborate structure which you perceive. So out there in the world, there is no color, no sound, no people. There is structure. And the structure has regularity in them. The regularity that you find is projected in your mind. People find similar regularity, so it seems to be not Wu, but it's probably not what's out there. It's the functional relationships that you find. It's functional abstractions. So our neocortex is an organ that is able to simulate a dynamic world. It's literally very much like a dream. It loses the same circuitry as your night time dreaming. Only daytime dreams are connected to your sensory input and constrained by it. And to do this, you have small circuits, the cortical columns made of a few hundred neurons. You have a hundred million of them. And I think that they are probably something like a state machine. And the state machine. And the state machine takes care of neural binding, and each of them is a small function approximator embedded in the state machine. They can talk to their neighbors and form larger computational units, and once this has a certain size, it's a brain area. And the brain areas talk to each other and form processing streams, and together they play the music of your mind. It's like an orchestra. Each brain area, we have something like 50 brain areas, is like an instrument. Each of them playing a specialized part of the music of your mind. And they listen to the instruments around them and thereby form streams along which the music propagates. So from the outside, these musicians take in sensory patterns and play motor patterns and so on, and back in there you get more and more integration and abstraction. And you'll find similar structure to this model in the brain. And this orchestra has a conductor. This conductor is not some kind of magical homunculus. It's a brain area, like the others. And what it does, it's deciding what's being played tonight. The orchestra can play very well on its own, but if you turn off the conductor, you become a sleepwalker. You can still get up at night and randomly make dinner or talk to somebody, but there's nobody home in you. And this conductor is doing executive function, resolving conflicts between the different instruments and tells some to tune up or to tune down and so on. And change resource allocation. And to do all these things, it maintains a protocol of what it attended to. And this protocol is basically a story that the system tells itself about itself. The conductor cannot listen to the whole orchestra. It only listens to one or a couple instruments at a time with low resolution. But this is what it puts into the protocol. And this protocol is the only part where our experience gets integrated. So there's probably lots and lots of experience happening in the brain, but these parts of the brain don't know about each other. Only in this protocol they get together. And when you access this protocol, you remember what happened there in these situations, replay these situations in your brain. And at some point, you'll also be able to replay the fact that you accessed your protocol. So you put into your protocol the fact that you accessed your protocol. You have this voice in your head and you start listening to that voice and understanding what this voice says. So now your system is able to remember that it attended to itself a moment ago, that it perceived itself as being conscious a moment ago. And I think this is necessary and sufficient for consciousness. So we are probably not actually conscious in this very moment. What we do have is a memory of having been conscious of something a moment ago. Come to think of it, it's much easier to build, right? It's not very magical. So what's it with reality? You know, imagination and our world modeling and so on use the same circuits. When you imagine something, you use generative models of your brain that normally are used for perception. And to make sure that you don't mistake your imaginations for perceptual stuff, the brain is going to tag the imagination as imaginary and the real stuff as real. It's a tag that is put on a part of the representation so they look real to you. If this tagging doesn't work, you get hallucinations, which is kind of awkward. The brain can also tag conceptual structures as real. For instance, I somehow believe that the financial system is real, even though I never perceived it. And my understanding is probably all wrong. Mathematics is very special, because mathematics is just the domain of all formal languages. It's a game played with symbols. It has the same reality, I think, as a novel that is not read. So, if you have a novel that is not read, it's just a bunch of characters, of symbols, right? When you open it, you hallucinate some story in your mind. But you know this story is not real because somebody has written these symbols into the book, that's it. And the fascinating thing about mathematics is that you don't need to write it into the book, it writes itself. You just need to pick a few suitable axioms and everything else follows from these axioms. Because mathematics is largely discovered, it feels real to the brain. And this notion that the metaphysics of mathematics is real is called Platonism. I think it's an illusion. Reality is in fact a brain state. So this leaves us with some sort of final embarrassment. And this is, you know, the Commodore 64. Where does it come from? We can understand how we work. We are computational. We can understand the universe, how it works. It's computational. And I don't see a limit to this perspective. All these big questions that I ask myself and I started my journey something like, maybe 35 years ago when I was in front of this Commodore 64. How is it possible that a system can have emotions? How can it have goals and motivation? How is it possible that we can be conscious? How is it possible that stuff is moving? How is it possible that stuff looks real to us? All these questions disappear when you think about them hard enough. But one question remains, and this is what put the Commodore 64 into the void? It's still pretty costly if you think about it, right? Something must be ticking away there at the heart of the universe. And we have no idea what it is, and we cannot know it because we cannot see it from the outside. But it's the cheapest thing I found to put there. Everything else that we to put there. Everything else that we can put there I think is more expensive than this Commodore 64 which is a very, very large memory. So we touched a number of topics today. We talked about computational universes. We talked about digital physics and we talked about life as the extraction of negentropy. We talked about the world that is a dream produced by our perception. We talked about the model of cognition as a synthesizer instead of a symbolic system. And we talked about the conductor theory of consciousness and about the reason for entropy and that we will all die. That's quite a bunch of stuff for an hour. But we have a little bit of time left because I've been talking extremely fast. There's one thing that has been puzzling me for a long time and this is the thing that has been left. You know, when rationalism came along in the 17th century, people felt a revulsion to it because in a rationalist universe, there is no room for love and meaning. Where should it come from? I mean, at some perspective in this rationalist world, we are just moving bits of rocks or computational machines or whatever. How is it possible that anything is meaningful? How is it possible that there is a purpose? How is there space for the sacred? And as a result, we got romanticism. And romanticism is basically the fight against rationalism for love. We want to keep this thing in the universe, the sense of meaning, of connection to something that is beyond. What is it? How can we feel this? There is something going on there, right? And I think it has an easy explanation. And this explanation is part of evolution. You know, we are subject to multi-level selection. Inside of our organism, there is going to be competition between individual cells. And they form together a group, and this group is the organism, and this organism is competing with other organisms. And these organisms in turn are forming groups, small populations, and they're competing with other populations. So we have levels and levels and levels of competition going on, and mutation and selection, right? But the interesting thing is that these levels, they are opposing forces. If you have these cells in the organism or the people in the group, if one of these cells is not an altruist but is super egotistical and just cheats, and basically is not an angel but uses all the resources that the angels give us and just free riders, then they are going to have a better time. They have time for getting laid to reproduce and so on, while the angels do all the hard work. From an evolutionary perspective, the angels are not in a good situation. But if you have a group that has a lot of angels, a lot of altruists, and it's in competition with a group of a lot of egotistical individuals, guess who's going to win? The group with the altruists. So evolution needs to find a solution to make sure that your group is largely comprised of angels. And inside of the organism, it does this by making sure that nobody gets to procreate, except the organism itself. So they have some dedicated cells, our gonads, that can reproduce, but our skin cell has no chance of ever reproducing. So our skin cell has no skin in the game. The only thing they can do is to be altruistic because it's outperforming the other cells for its own benefit. Nothing good is going to happen to the skin cell. Everybody's just going to die, right? So this is how organisms do it. And this is how state-building insects do it. So only the queen can give rise to offspring. The individual worker ants cannot do it. And this doesn't work for humans because it's so much work to give birth to somebody that a single queen cannot do it for all the humans. So we need to find something else. And what we do have is something, a system that works with punishment and reputation. So if somebody is just a free rider and a cheater, we have a reputation system, we talk about them and we punish them. We might even ostracize them or kill them, right? And this punishment system works pretty well. The drawback is that it doesn't scale very well. After a couple hundred individuals, it's over because we cannot keep track of everybody's reputation. So what you want to have is an internalized reputation system. And this internalized reputation system basically uses some of the drives on the social needs. It uses the need to conform to internalized norms. And this need to conform to internalized norms means that you'd pick up a few rules in your environment when you are young and you want to be good. But being good, this means you just follow these things, even when nobody is looking. You're not going to eat from the fridge of your flatmate, even if nobody is looking, if you are a good person. It's not virtuous, you have no honor if you do this, right? It may be not rational if you cannot be caught, but you don't do this. It's basically the group mind reaching down into the individual mind. And it's also, there are some other drives that help in this, our need to belong and our need for status that are important for the reputation system. But this need to conform to internalized norms, this need to be good is important. Now the problem with norms is that they are somewhat arbitrary. Different societies have different norms, so norms are largely cultural, obviously. And goodness is an arbitrary vector in value space. And this vector gets synchronized between people through empathy, largely. So you're in a group, something feels right, and people pick up this feeling of, oh, this feels right, this is good, this is what we need to do. And it gets multiplied with the social status. So if you dress up somebody as an authority, as a priest or as a politician or as an eminent speaker or as a professor, then you, not somebody like me, you will feel that what they say is right, that there's this normative. And you have a compulsion to conform to this. And if you feel differently for logical reasons, then you will have to bear some considerable cognitive dissonance. But people tend to pick up these norms easily. And this means that people are programmable. People can be programmed to run societal software, memeplexes that are ideologies, bodies of norms, bodies of rules on how to interact. And they can structure the interaction of large groups of individuals. And it's not based on reputation, so it can scale arbitrarily. As long as you can project your norms efficiently, and our societies used to do this via mass media, we can get people to be synchronized. And this belief assimilation, if you get people to be synchronized. And this belief assimilation, if you are a nerd like me, is somewhat broken, so you still try to be good, but you don't feel it via empathy, what's the good thing? You will need to do this via arguments, you talk to others and you say, oh, this is a good argument, yeah, this is goodness, so this is what I'm willing to do. But it's hard in this way, for instance, to synchronize with your nation, with your family unit, with your social group and see this as the intrinsic good. So your direction of the system that's larger than yourself, that you can serve, your group mind, is going to be directed on an abstract world, on a metaphysical world, on a platonic world, on a transcendental world. And I think this is the nature of transcendence. It means that your meaning, your purpose, the system that you are serving cannot be found in this world. It's found in a platonic world. And I think this is why many nerds do art or science. So if you make complicated patterns, this is transcendental. It's a search for meaning. It's pretty broken when you think about it. Okay, I think this is enough for today. We have 15 minutes left, so we can do some Q&A, just a quick reminder. If you need to leave, either do so now and very, very quietly or stay until the end of the slot because you're not being as sneaky as you think you are. As always, if you have questions, line up at the microphones please. If you're unable to get to the microphones for some reason and laziness does not count, just raise your hand and we'll try to get a microphone to you. And if you're on the stream, just post your questions and we will also get some questions from the internet. And now let's start at microphone 4, please. Hi. Do you believe that somehow soonish we are going to go through a sort of social autopoiesis where we're going to become a different superorganism? And if yes, what are the biggest challenges that you see in this process? Well, we are already one. Our societies are superorganisms, if you want, but their information processing is broken. And I think what we need to do is we need to build a nervous system for humankind. Right now, whenever academia is trying to work on topics that are only winning by truth, like computer science, you're not going to get a career in computer science if you have proofs that are wrong. Right? But if you want to have a career in economics and you make suggestions that are costing somebody a billion dollars, chances are that you're not going to get tenure. At least there are going to be some forces that oppose you. And if you lie in the right way to get people some money, there are some forces that are going to support you. And for this reason reason it seems that our mechanisms of creating knowledge in domains that are policy relevant are broken. So we have difficulty in our societies to find out what's actually happening on the ground. We don't have very good models of the economy, we have very poor models of ecology and so on, and we have difficulty allocating resources properly. So, for instance, with respect to global warming, I think we would definitely need to put a lot of resources into post-apocalyptic science. Thank you. Thank you. There's Titanic in front of the iceberg, and the iceberg is there, and we put a considerable amount of resources into computing the last Romanian digital probability that we maybe not hit the iceberg, but we all know it's somewhere in the 90s percent, right? And so I think it would be rational to put considerable amounts of resources into exploring the question what's going to happen after we hit the iceberg? How do we rebuild what's left? How do we rebuild what's left? And instead, most of our sciences, that do city planning and economical planning and labor market planning and so on, are predicated on the status quo, that everything happens, continues as it is. It's insane. And it's because of the systemic incentives that we set, that the people that are successful and get to the top positions are those that are successful in the given system, not in the next system. So whenever a system comes under stress, it's much harder to fix. And we need to fix all these things, and we don't know how. But I think it's possible to fix it at some level. Our brain is not lying to itself at the lowest levels. So nervous systems don't lie to the organism about the fact whether it hurts itself or not, only if it helps the organism. And right now we have systems that corrupt our thinking. I think we need to think about some type of new social media that filters information by truth and relevance instead of things that are addictive. So I don't know what this thing is going to look like and if we manage to build it in time, but I think it should be possible. So I don't know what this thing is going to look like and if we manage to build it in time. But I think it should be possible. It's probably worth thinking about. Could we get a question from our global nervous system, the internet. Lots of people on the internet were wondering what if this is already proven and what is the stuff you're inferring. So they would like you to provide a link collection or a glossary on further reading and know what if this stuff is already really proven, known to be true. I think nothing of this is really proven because there are alternative views of the world and a lot of the things that I tell you are speculative in the sense that we don't know if the world is a discrete state machine and there are some physicists that are reasonable that think it's possible that it is and there are many physicists, majority actually, which think it's probably something else altogether and And there are many physicists, a majority actually, which think it's probably something else altogether. And we don't know. So, what I'm trying to show you is a particular kind of rabbit hole, a particular school of thought, which I find exciting. And I just want to show you a way to explore this land with me. So, I do think that these things are true, or that they have a good chance of being true. And I will probably change my views on them in the future. I think that they are convincing. They convince me. With respect to mines, I think they are probably the only game in town. Mic number five, please. Hello, thanks for your talk. We are able to recognize limitation, computational limits on external systems like a cat. A cat will probably never understand physics. But as our systems, do you think that we'll ever be able to recognize an upper computational limits for ourselves as conscious beings? Probably. We made some estimates in my class. I taught a class in the media lab last year, and so we discussed about what's the computational power of the human brain. And we estimated that maybe we can take a column and encode it in something like three kilobytes. The further attractor states and the actual current connectivity that it has and the function approximation that you've put in there and so on. If you multiply this with the number of columns and maybe you can run a person on 100 gigabytes if you only knew how, or maybe a couple hundred gigabytes, but maybe you can run a person on 100 gigabytes, if you only knew how. Or maybe a couple hundred gigabytes, but something in this ballpark. And it could also be a few terabytes, but we don't know. We also know that based on how long we live, you're not going to form more than a million concepts. Because our life is short, and even if we form a couple concepts every half hour or so, you're not going to be substantially more than a million concepts before we die. So this gives an idea about how complex our cognition is. I think it's not as complex as we imagined because our life is so short and the amount of data that we get to see is so little. Thank you. Mic number one, please. Hey, thank you for your talk. One question arose when you were talking about love. How would the joy to do evil, the joy to not conform fit into your model? I think that's largely because you have in-groups and out-groups. If you have an in-group or it's people that you love, it means that you serve the sacred through them. You serve the system that is bigger than you, that you love, it means that you serve the sacred through them. You serve the system that is bigger than you, that you are serving, because you recognize it in the other, the sacred. And this is at the core of love, this service. And of course not everybody is serving the same God. And there are others that are doing things that you consider to be evil or stupid, the outgroup members. And if you are surrounded by out-group members, you're going to feel much better if you have vice of fighting back and being mischievous or being evil to them and so on might be a way to fight against a world that you perceive as hostile and as something that is not part of your in-group. Just the joy, the joy element is not so much explained. Oh, the joy, yeah. Well, there is a benefit in aggression sometimes because we are a competitive species too. Not all of us are. There are differences in competitiveness. I think I'm not very competitive. Don't get much out of this, but you see that a number of people that really enjoy very much winning over others. And there is a joy in winning and breaking the other and being stronger than them and destroying them and taking their resources, extracting the neck entropy from their volume of space. Okay, thank you. Could we get a microphone number seven, please? Hi, and thank you for your talk. The idea that what we are experiencing is not what's actually out there is something I read about when reading about meditation as well. Have you come across this concept in this context? And do you maybe even have experience? Yes, it is. So when you meditate very deeply, when you do Vipassana, for instance, you can experience a state in which you detach yourself from your self-concept and from all these bindings, from your body image, from your perspective on yourself as a person even. And when you do this, you can experience yourself from the third-person perspective. If you think about yourself, it's difficult then to identify with you and realize that, for instance, the motives and impulse, they're still there, but they no longer direct you. They are like a ghost. They're somewhere in the background. Your self-concept does not integrate them very much. And this is when you realize this thing that the robots in best world realize that reality falls apart and they're not really these humanoid robots. There are minds that are more general than what they're being used for. Yeah. Thank you. Could we get the internet, please? Yak Drasil wants to know, did any of this research attempts to resolve pathological brain patterns? Well, I'm not a doctor, so I'm not competent in doing this. But I suppose that many of us, when we try to understand anything in the world, we do so because we think something needs to be debugged. Our self-concept might actually be an attempt of our system to debug itself. So at some point, the baby thinks that the world is pleasure and pain, and then it realizes that pleasure and pain is not a feature of the world, but of itself. And then it realizes that it's not a direct representation. For instance, you might realize that you've cut yourself and it hurts a lot, but it's only a very tiny cut, so you need to downplay this, and you realize it's a signal that is very strong, it's not objective reality. And so you do this step by step, and at some point you get to the point where you realize I'm not my values, I'm not this person anymore. And it's a process of reverse engineering where you make a model of yourself. And when you make a model of something, it's usually because you cannot regulate the disturbances with the existing feedback loops. So something is going wrong. When you are quite conscious of something, it means that something in this area is broken. And I suppose when nerds try to understand the universe, they deep down feel that the universe is somehow broken and need to debug it. And it probably means that something is actually broken in them. So as children, maybe their social interaction didn't work because they were too nerdy and they didn't meet other nerds in which they could interact in their normal nerd ways. Instead they were surrounded by humans and they didn't know that, they thought they were humans. And this created a lot of confusion and pain and as a result you try to debug the universe because you don't find the bug in yourself. So in some sense I think that I try to understand my own pathologies and those of the people that I love and all the other people that I meet. But it's more a side effect, my own goal is really to understand what we are. Could we get microphone number three, please? Yeah, hi. You mentioned beforehand corruption of data that leads to instability. And I wanted to point out something that I think is a corruption of data in your presentation. You have the need for dominance in one of your slides, in that illustration. And I think that is a representation of the culture of dominance that also leads to capitalism and capitalism isn't renewable't sustainable. I think that a need should be replaced with a need for social stability. And actually, if you look at history and other systems in nature, you can also see that it's not the systems that strive for dominance, that stay alive, but the ones that search for ways to fit into the system that they have at the moment. That's also this need for dominance, this culture, is what is destroying our planet at the moment. And I think that's really worth mentioning. I totally share your sentiment. Most of my friends are basically hippies. And if you have a valley full of hippies that do ecological farming and dance and are merry, and in the next village you have a valley of brigands that are vicious and strong, and Vikings basically that are willing to pillage and so on. Who do you think is going to win? And this means that if you just let evolution run its course you will probably get something like an equilibrium because you need some that do farm the land and you will have some that are going to attack and that you need to push back, you need an immune system and so on. And I think that motivation itself is not adaptive. Motivation is not a cultural construct. Motivation is resistive. Motivation is what puts up resistance to the environment. Without motivation, you would just give in to inertia. And this means you would stay in bed, you would just rot in bed, you give in to physics, you don't get up, you would become a blob on the floor. And the only reason why you're not a blob on the floor is because you have motivation, something that makes you push yourself up in the morning and brush your teeth and have breakfast and shower and have sex and all these terrible things that we do to ourselves because we get pleasure and we do them and pain and we don't do them. And there are a lot of people that feel this urge to be dominant, and they get pleasure out of being dominant. And some others don't very much. And what we can change as a culture is how we value this, I think. So we can have an influence by saying, this is the desired behavior, this is how we want to interact, and this is behavior that we don't want to have. And this means that different types of people are going to get in different positions in different societies. That's my current perspective. It might be wrong, of course. I think that hunger, thirst, curiosity, and sexuality are enough to get up in the morning. We don't need attackers. Okay, please give Joshua a warm round of applause. Works for him", '23.761378526687622')