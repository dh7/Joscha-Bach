('<center> <iframe width="500" height="320" src="https://www.youtube.com/embed/zEBGKLKOMI4"> </iframe> </center>', " That's it. Yeah. Thank you so much for agreeing to do this. We really appreciate your time. And last week, we listened to your Q&A with Lex Fridman. And we discussed how, correct me if I'm wrong, but this idea that in order to understand the human mind, you want to try and build artificial intelligence to sort of, how do you say, trying to understand the way that our minds work as well. So just for those who weren't here, please, could you give an overview of your work and why it's important to understand the human mind in relation to artificial intelligence? When artificial intelligence was started, it was not just the attempt to automate data processing, but it was also a philosophical project. And this philosophical project is only a small fraction of the whole effort of AI. It's the most important philosophical project there is, I think. And it's a project that started long before the 1950s, when Marvin Minsky coined this term artificial intelligence and started the field. I think it started, for instance, with the ideas of Leibniz and Lametri and many others who realized that thinking happens in representational languages and the natural languages that we are using are a subset of those and the natural language in which we perform philosophy and make sense of the world and communicate our ideas are difficult to use in such a way that the statements that we make in them are true use the judge the way that the statements that we make in them are true. Because the meaning of the words is defined in a relatively informal sense in natural language, right? And on the other hand, the mathematical languages where we start out with a clear definition of what truth is and what a statement means are so simple that it's very hard to say something about them, about the real world in mathematical languages. Which means that if we are making a mathematical model of anything, it's usually an extremely simplified universe with very few entities that is not really so much related to our normal universe. We just hope that there is a structural equivalence with some patterns in our normal universe, mathematical universes that we create. And what we also realize that our brain is facilitating the creation of a mathematical universe using a type of representational language. And if we were able to understand how this is working, we would be able to mathematize thinking, we would be able to mathematize the operations that our mind is doing, and eventually it would also mean that we can mathematize the languages in which a system performs its philosophy. We could just basically extract the principles, generalize over the principles by which a human mind creates meaning by trying to answer a question. And then we can scale this up far beyond the abilities of an individual human mind. And by automating this, we can basically start making proofs about reality. And this project would allow us to understand the universe at a much, much deeper level, where it would allow us to conquer the heavens, the noosphere. And that's a very, very old idea. Our civilization even in some sense starts with the project of building this tower that conquers the heavens, this giant intellectual project of making sense of everything. And in the original version, it fell apart because human minds have only limited capacity and the ability to synchronize the languages in which human minds think and communicate is limited. So if we want to make sense of everything we need to scale beyond the capacity of a single human mind. Brilliant. I'd encourage anyone here just to ask as many questions as you can of Josje. If you want to put them in the chat or raise your hand on the i gofyn ychydig o gwestiynau y gallwch, os ydych chi eisiau eu rhoi yn y siaradau neu'n ychwanegu eich cyfnod ar Zoom, gallwch ddweud wrthym os oes gennych cwestiwn. Os gallaf ddod o hyd, byddwn i'n hoffi gofyn, pa sy'n ymwneud Ã¢ y cyfnodau, ar hyn o bryd, o ddeallusiant dynol? Er enghraifft, os yw ddeallusiant dynol yn rhagwneud of so far of artificial intelligence. If, for example, if an artificial intelligence is programmed to manipulate propositions based on logic, what is the role of things that are illogical to an AI? For example, as musicians, I'd love to explore what is the potential value of something like art to artificial intelligence, because it's not necessarily something that can be put down to a logical system. We can think about what art means to us, and I think that there are basically three tiers of artistic appreciation. The bottom tier, the most uninteresting tier of artistic appreciation is this was made by an important artist and this is what determines the monetary value of an artwork on the art market for instance and it determines a lot of the attention that artwork is getting in the public sphere and the second tier, this is slightly more refined than this most base tier of artistic appreciation is, it looks good to me. And interestingly, most of the people who are stuck on the first tier look down on those on the second tier. And the third tier of artistic appreciation is, I value what it lets me see because art ultimately is about capturing conscious states, it's about capturing perspectives on the world and allowing us to see something that we otherwise could not see. And this doesn't mean that it has to look good, it doesn't mean that the individual who creates the art is somehow recognized as high status or something. But for instance, from this perspective, we can be able to see what a child is producing as art, because we value to see the eyes through the perspective of that child. Maybe we care about that child, or maybe we care about that part of the world seen through the eyes of the child, right? This is where we learn something about perception works in general, or we learn something about our own relation to the world or that child. And this is, I think, this perceptual art, this art of creating perceptual artifacts and reflecting about them, this art of taking perspectives, can be interesting to an AI in a particular way. It's basically this development of an aesthetic, the development of a model of how the world works and should work, of how things can be harmonious, is something that is expressed in art. So there was a sort of syllogism that was used to sort of explain why Felly roedd yna ddifrifolion sy'n cael eu defnyddio i ddweud pam nad yw metaforau, er enghraifft, yn ymddangos ar y cynllun logig. Felly os oeddwn i'n dweud rhywbeth fel, mae dynion yn mynd i'r ffyrdd, mae'r ffyrdd o'r ffyrdd, mae'r dynion yn y ffyrdd. Yn aml, nid yw'n cyflawni sylfaenol, ond mae'n cyflawni sylfaenol. does make a kind of intuitive sense. Do you think an AI would be able to develop the same kind of intuitive sense? There's a word to describe this called grokking something, where you get something. For example, I can't put into words why I like a piece of music so much, but it's because I get it. And it gets me in a certain way. There's a sort of music so much, but I just because I get it and it sort of gets, you know, it gets me in a certain sort of way. There's a sort of connectedness I feel to that piece. I was wondering, do you have any thoughts on this? The word grokking means two different things. In the original version grokking was introduced by Heinlein in the book Stranger in a Strange Land, where it refers to the ability of a human being that has grown up among Martians to understand whatever way Martians used to make sense of reality. And it's a concept that cannot be translated into English, because it is one that if you master it gives you supernatural powers. It allows you to interface this reality in a way that ordinary human comprehension cannot comprehend. So it's basically a different level of comprehension. And the book Stranger in a Strange Land of course is not describing an empirical phenomenon, but it invites you to imagine that there are different ways of making sense of reality and different ways to give you affordances to the universe that you're in. In machine learning, the word grokking has also sometimes been adopted for an interesting phenomenon. When you train a machine learning model, you often find that initially it becomes better and then it starts to overfit. It means it's much better at predicting training data, but it gets worse at predicting test data, stuff that it hasn't seen yet because it is connecting the dots too tightly. And then if you continue training and train and train and train, that something, something very interesting happens. The model snaps into a new mode, where it gets much better again. And this basically means that it has discovered a pattern in the pattern that allows it to see a high level of regularity. And obviously, this use of the word grokking is metaphorical, it's not the same thing that has been used by Heinlein in the book And now, of course, it's tempting to use the word grokking for all sorts of things But in the way in which you used it, it's almost the opposite You use the use of metaphor to just shift your concepts around by interpolating between concepts and then hallucinating what's on the other side of that operation Basically, concepts are the address space of your mental representations and you create a new concept by interpolating between or mixing matching existing concepts right and then you try to hallucinate what's on the other side. Can AI do that? Yes totally you can do this in DALI or stable diffusion right it demonstrates this. These models in my perspective are the best when you are using metaphors. When you use very vague language, it often finds very interesting solutions. It's a lot of fun to try this. Could you give us some examples of these solutions? My first deep encounter with DELHI-2 was after I got a test access. I used it to generate illustrations for the book of imaginary beings. That's a book that is pretty old, it was written by an Argentinian philologist and it's basically a collection of prompts, which is to say he has collected descriptions of fantastic beings, monsters, creatures from all over the world and sums them up. Sometimes it's a small paragraph, sometimes it's half a page and every of these animals is described in alphabetical order and there's a very unsystematic ordering scheme which makes for a very funny but also somewhat dry reading because there are no pictures in there. The best version of the book that I found in terms of illustration is 22 illustrations or so and I used a bee to generate hundreds of illustrations for it. And while I was doing this I was discovering many of the mutations of the system because when it's a difficulty to count, it's very hard to create a creature with nine heads, it's difficult to create higher order relationships, So it's hard to make one of the creatures very tall and blind and the other is very fat and cannibalistic. And if you take all these difficulties, you basically realize how you need to create lots and lots of metaphors to interpolate. And some of the descriptions that you get, like an animal described by Kafka or an animal described by C.S. Lewis or so are very literary, they are very poetical, they might point in a certain direction, but you don't know exactly what's on the side. And because of this ability of language to disambiguate very lightly, right, but you don't know exactly what's on the site. And because of this ability of language to disambiguate very lightly, natural language is not just constructive. It assumes that you already have seen so many things and have formed so many concepts that we can assume that we share these concepts. And in order to communicate, we just need to disambiguate them. We need to cut away everything from the block of marble that is not David or the lion. And by doing that, you can create something that can, by touching it very lightly, create something that is deliciously vague in our mind and fluid and tentative and ephemeral and it's able to do this. So, I see if I remember one. Two metaphysical beings that are exploring the world through the use of smell. What does this look like? The results were completely wonderful. They were so much better than my attempts to create a centaur or a Cerberus, and often failing because it has difficulty to glue different creatures together in the right spots and produce credible anatomy in this earlier version. But these metaphysical beings, they were just amazing. Brilliant. Okay, so you mentioned in the discussion with Lex Fridman that you were a descendant of the Bach family. First of all, does this mean that you're a descendant of someone like Johann Sebastian Bach? And does that mean that, I was wondering if the music of Bach had an influence on your own intellectual development, with this very sort of mathematical precision? No, it didn't. As far as I know, I'm related by an uncle, but I don't think that's super important. There are many pieces of Bach that I grew up with and it's just part of but just part of central European culture. That is, if you live in Leipzig or Thuringia, where I grew up, you will spend a lot of time in the context where you hear Bach's music in a liturgic context, for instance, or just in a normal context of an intellectual family. There was a lot of music that I liked early on, but there's also other music that I found much harder to understand and it took me years to get into them and to start to enjoy them. And in part that's because Basque music is of the type where you have to discover the shortest state machine that is able to generate the music. And this is the game that you are trying to solve while you are listening to this music. Not all of it, but a lot of it. And then you also zoom out and you understand the reason why he was interested in designing particular state machines and the larger machines in his own mind to which it does fit in and what kind of things he explored and so this is something that happens in some sense with almost every fellow, with every musician or with every composer that you realize that their music is part of a larger project of exploration in the same way as the works of a philosopher or of a novelist are often part of a larger exploration and that it makes sense to not just read them in isolation as individual pieces that are part of the particular discourse to which they contributed the thing but the development of a mind that is interacting with the world at large and you understand that much, much larger context of all the discourses that they are able to care about. For me, it's really fascinating how we grow up and the more we look at the world, the more levels we discover. And for as long as we live, we are not going to exhaust that. We've got a question in the chat from Joel. He asks, do you believe it's possible to fully recreate human consciousness with artificial means and if so, why? First of all, yes, I do. And if, why not? There is no reason to believe that there is a single class of phenomena in the universe that cannot be explained and that's consciousness. But if you look at more detail, how it works, I think that the answer, how consciousness can exist in the physical universe is relatively simple. It doesn't. Consciousness is not physical. Neurons cannot feel anything. Brains cannot feel anything. They're mechanical systems, right? How could the mechanical system feel anything or care about anything? And some scientists say that therefore, because computers are mechanical entities, simulations can also not feel anything. And it's not possible that simulations can feel anything. Only real things not feel anything and it's not possible that simulations can feel anything. Only real things can feel anything. And it's exactly backwards. Only simulations can feel something because consciousness is a simulated property. It is as if it is entirely virtual. Consciousness can exist only in dreams. And there are physical systems that have the capacity to weave dreams. They are basically looms for dreams. They produce representational carpets that link back into themselves and the representations that are woven into the carpet are parsed by the system in the next step and lead to the next step of the representations. And consciousness is a particular kind of representation. It is a representation of aspects of your attentional system. Consciousness represents reflexive attention. It's basically the control model reflexive attention. And reflexive attention is required for making constructions in your mind. So in order to do that, you need to have a memory that tells you what you tried in order to make a construct. So you can explain why to yourself, why you made these choices in building a representation of the world. And ultimately, the purpose of consciousness, I think, is to create coherence in your mental representations. It's the search for solutions in interpreting the world that consciousness facilitates. And I suspect it would be very hard to build a system that is achieving full coherence without having reflexive attention, which means without noticing that it's observing something and uses this as a starting point to create coherence in all the possible interpretations of the world that can coexist in a mind. We recently spoke with John Vavecki, who I believe you've had a discussion with on another podcast. I was wondering what are your disagreements with John Verveke? He talks a lot about relevance realizations being a big problem for trying to create artificial intelligence. Do you Mae'n siarad llawer am y sefydliadau o ddiddorol yn broblem gwych i greu dealltaeth ddynol. A ydych chi'n rannu'r ymdrech hwnnw? O ran y sgwrs gyda John Ffegi, mae'n siarad am y sgwrs yw'r ddynolwyr yw'r ddynion sy'n ddiddorol. things being of primary relevance. How do you prioritize a sort of structure of relevance realization for artificial intelligence? I don't see that relevance realization as a big problem. Relevance for us is assigned according to goals that we have and the goals are generated according to goals that we have and the goals are generated according to preferences that we have. And these preferences can, in principle, be arbitrary. It can be born with the set of innate needs, and they can deviate pretty far and get onto different trajectories, including two trajectories that completely fail. A lot of people don't have a well-developed sense for relevance. And it becomes interesting when you can start to change what you think is relevant, which means you identify what should I care about. And in order to figure out what you should care about, you need to figure out who you are, right? Which part of the universe are you interfacing with? What does that make you? What is your relationship to the world? Once you understand what your relationship is to the world, what relationship you have to the universe that brings you into existence, and I call this ability to model your relationship to the larger body of ideas and existing things in your mind to your world model sentience, then you will be able to determine what should be relevant to you and use this to drive yourself. And arguably, we don't have a lot of AI systems that can discover themselves in the world. And it's not so much the problem that machine learning algorithms cannot do this, but most of the machine learning paradigms that we have at the moment, do not connect the machine learning system to an environment in which it could discover itself. If you just, for instance, feed lots and lots of images into a system like DALI, or if you feed lots and lots of text into a system like GPT-3, or chat GPT, there is no way in which it can interact with itself. And with itself interacting with the world that it observes in this data. And so it's not going to develop a notion of what it is, in an interesting sense. And so it can also not tie any relevance to this, what it's observing. Instead, it will take the relevance from the structure that it discovers in the data. And it turns out this is for most of our purposes good enough, because it's exactly the sense of relevance that motivated people to draw these pictures or to photograph them and to put them into the internet, or to write the text and upload it to the internet. Right. So if you have data that's pre selected based on the fact that it was relevant to human beings, and you have a machine learning system that is big enough to in some sense parse the entire internet and find structure in it, it will converge on all the things that people found to be relevant. So in practice, I don't think that's an actual problem. My main disagreement is with John Wawiecki might be one of perspective. I take an engineering perspective to the world. So my goal is not so much to influence an audience and to produce good ideas for the audience, but my own intrinsic desire is to understand how things work and to understand how things work in the world. I need to take this perspective. How would I make that happen? If I was an evolutionary process, or if I was a human engineer, or if I was a universe that goes through all the objects, how is it possible that something exists in a way that produces the phenomena that I can observe? I think Abhishek's got a question. Abhishek? Yes, thank you, Dr. Buck, for doing the Q&A. It's really fascinating. I wanted to go to an earlier point based on what you said, when the question was posed to you about your ancestral lineage with Bach and so on, of Johann Sebastian Bach and so on, but it's not related to them. It's something you said that you feel that music and most composers, what they do. And as a musician and interacting with the scientists who does AI, I feel like it comes from a music perspective. You said music you feel is like, in trying to understand music, you're trying to do some form of pattern recognition in that you're trying to see what the whole composer's output is like. You're trying to see the context of where they're from, you're trying to understand the language they're working with, the game they are playing, the notes, and then eventually understand or decipher the piece of music in many ways. I feel like, well, that's a really interesting way to put music, and I kind of agree with it, because I was a late starter, and that's how I started learning classical music. It also is very convenient for an AI system to adopt a music model based on that because AI does pattern recognition well or any computer based, I mean, sorry for the really poor lingo. But what about the incredible vastness, vast diversity of people that are there? There are so many people who are self-aware, who have instincts, who have pattern recognition built within them, and they still have none of the inclinations towards music or none of the inclinations towards classical music, or even deciphering anything of classical music. If someone was to ever build a system that could interact with itself, would that mean that all the systems that interact with themselves have more or less the same, they're producing the same kind of systems all the time? Or is there going to be variability like that, like there is in humans? Some humans are very musical, some humans are not, some humans get boxed better than Ravel, some humans get Ravel better than boxed. It's all variability among humans and human consciousness. Would something like that, would that be a parallel for AI? Would that be variability when you introduced self-awareness or self-interaction for an AI? The interesting thing about music is that it's a set of languages that are not obviously representational. It's not clear basically what music represents. Instead, you have intrinsic rules that describe a space. And in that space, you can have objects. And these objects are of a perceptual nature and you can basically look at the way of the functions that are computing the sound in your mind and that are producing the regularity, the higher levels of the sound that you perceive as rhythm or as a cadence or as the structures of the musical phrases that are being used that can be used like textures or that can be used like... And what we find for instance is that there seems to be some super interesting isomorphism between the space of emotions and the space of musical expressions on some level, right? So it's possible to create music that is almost directly producing emotional states in people and you can use this as a language to describe emotion and not just emotion but attitudes. So if you can have music that feels almost as if it is a narrative that describes a sequence of attitudes that an agent or a group of agent goes through. And it's very interesting to observe how that works, right? So you can use music in a representational way and it's being used as a language in movies, right? Composers have developed this language and trained their audience to respond to particular parts better than they would do that in their native state. But it's interesting how it's possible that music can convey emotion without having this direct reference. There seems to be something going on here, where the internal representation that the brain is using to describe music and the representation that it uses to describe emotion are extremely similar. The potential of music in this regard is probably not completely exhausted. For instance, I am wondering whether it would be possible to use music as a language to describe geometry Geometry can be described as, for instance, the skeleton of the objects which you could describe as the differences in distribution of mass in space and you could have changes in objects, for instance, in their momentum or in the relative distances to each other express this with dimensions in the music So you could have for instance sounds at different pitches that change in volume or you could have changes between such sounds and so on and once you establish a referential meaning, you basically learn that language you should be able to have a type of music that is describing geometries, changing geometries, objects in space that are moving and interacting and changing. And if you would train yourself in such a language, it would mean that you hear a piece of music in that language, and a very complicated pitch language that has many instruments more complicated than you can easily produce with your own voice but by hearing that you would, in your mind's eye, see a scene playing out these geometries playing out, right? This would be a language that you have to learn and that would be a music that in principle is so rich that is able to describe complicated spatial events in a much more concise and precise way than spoken language can do it And maybe this type of language already exists and I've never heard about this type of music and wouldn't be surprised, I'm always late to the party But if not, somebody should invent it and would lead to a very interesting musical genre and it would also, I think, be super useful to have a community of speakers of a geometric music language and you could use this for arbitrary domains you could talk about developments, say, on the financial markets across many dimensions using such a language so you could have this auditory channel to convey arbitrary things in the world. And music is unconstrained from the relationship to the larger body of meaning that you have in natural language. Natural language is mostly interesting when you have established relationship between the conceptual space to which linguistic concepts point and the mental simulations that lay behind the conceptual space. And because music does not have this tight reference, it can create its own mathematical sub-universes that are disconnected from the world at large. And part of that is what makes music interesting, but it's also the reason why it's interesting to, uninteresting to a lot of people, because it does not have to mean anything. It can be just patterns and some people find it delightful and delicious to start at patterns and unravel structure and discover structure and others find it annoying and distracting because they have other stuff to think about. find it annoying and distracting because they have other stuff to think about. I think Stephen Chan has a question. Hi, thank you. Can you hear me OK? Yes. When you were speaking about the internal representation of music, what came to mind for me was the idea of embodied cognition in the sense of the feeling of something that kind of comes up in a guest y ddifrifolion a'r cerddoriaeth o fusnes, yr hyn sydd wedi dod i'n ffyrdd i mi oedd y syniad o cofnod cyfathrebu, yn ystod y teimlad o rhywbeth sy'n dod i mewn, ac rwy'n gwybod bod rhai lywydd yn y llyfr ynghylch y llyfr ei hun yn metaforaeth ar gyfer teimlad cyfathrebu o syniadau fel hap, er enghraifft, rwy'n y clwyd, rwy'n y llyfr, rwy'n y llyfr, mae yna ystod o gydnabod gyda'r defnydd o lyfr y byddwn i'n croesawu I'm on cloud nine, I'm over the moon, I'm over the... there's a sense of upness with the use of language that I'm not to cross a lot of different languages as well, I believe. The converse is true with a sense of sadness, like feeling down and feeling under the weather, that kind of sense. I guess that comes from the fact that we've got a nervous system and we feel things in a kind of certain way, I guess. I guess what thoughts you have with regards to artificial intelligence and that, actually, like the fact of the idea and concept of an embodied way of understanding our world, if that makes sense. There are several aspects to this. One is that there is information processing happening outside of the brain and outside of the nervous system. Every cell can in principle act like a neuron. That is, it can send conditional messages of multiple types using different chemical impulses and send those to its neighbors. But it also means that this type of information processing is very slow. So if you want to use cells in your body for information processing in the same way as the brain does, you can in principle, I think, and this means that evolution is probably doing that. But the spread of signals across cells in your bodies is going to be like millimeters per second at best. So these signals are being computed very, very slowly. It takes a long time for these signals to be known throughout your body. And plants probably have this as their main way of internal information processing. But animals have evolved a nervous system, which is to say a set of telegraph cells that differ from normal cells in their ability to send signals extremely quickly using some kind of Morse code around arbitrary distances in the body at a very high energy cost. And the purpose of neurons is to move your muscles as fast as physics allows. And this allows you in turn to compete with other animals. If you only had to compete with plants, you probably wouldn't need the nervous system. But if you were a plant, you couldn't afford a nervous system because photosynthesis only gives you so much energy and metabolism. So you need to run around and eat plants or even better to eat other animals to get all the nutrition that is required to feed this expensive telegraph network in your body. And in order to make that happen, you don't just need to move very quickly, you also need to make decisions very quickly, and you need to update your models of the environment very quickly. So you do not just double the information processing system that is sending information across the body, but you also create a second decision-making network and modeling network. And this new secondary brain that organisms develop once this evolution came up as nervous systems is not completely displacing the other one, but it's getting decoupled from it. And if you decouple the nervous system from the body, it's still able to perform a lot of the things that you normally do. If you fall asleep at night, you are decoupled from your sensory apparatus, you don't have sensory input anymore. And this is both true for proprioceptive input and for input from your visual and auditory domains. And still meaning is not gone, Consciousness is not gone. Feelings are not gone. You can have feelings in your dream, which means that the feelings that you perceive are being generated in your brain and in the nature, not in your body. In the nature, there are geometric representations because they are produced by some neural network. In effect, geometric means that you have a bunch of dimensions in which you have continuous values. Geometry is the mathematics of too many parts to count. And most of the perceptual world is made of too many parts to count, so it uses geometry to represent things. And our reflexive mind needs to reflect on the things that it talks about, which means it needs to be able to take them apart apart and to manipulate the things that are being taken apart. It needs to be compositional and systematic, which is to say grammatical. So you have a grammatical mind and a geometric mind. And our perception and reflection happens at that interface between the grammatical analytic mind and the perceptual mind. And feelings are a way in which your mind is communicating situation assessments, attitudes, and so on, to the reflexive mind. Right? And this means that you have to inform your mind about geometrical parameters, a bunch of continuous numbers How do you do this? You basically need to create a space in which you make them distinct And the only space that is always available, that is always instantiated, is your body map map. You can create many spaces, you can imagine your living room or you can look at the world around you and create a visual representation of the scene in your mind, but these spaces get disassembled when you move into a different room. You usually don't have that many at a time and they're not constant, but your body map is always instantiated and available because there's always stuff going on in your body that you want to be able to refer to. So the feelings get projected into your body map, at least for most people. And that's the characteristic locations where they tend to pop up. Like you have feelings of insecurity in your lower abdomen, you have feelings of connectedness to other people in your chest region, your heart, you have feelings of safety when you communicate and of the status that you have in the communication in your throat and so on, right? And all these things are not necessarily playing out in your body itself. It's not that you need your solar plexus to compute social power or that your gut is very involved in evaluating whether the world is disconcerting to you. These are in part secondary effects caused by the down-regulation of the nervous system in your body when you are going into a fight-or-flight situation, but for the most part they are the side effect of you projecting feelings in your body to make them distinct. And when you look at the nature of a feeling, it is a movement in space, right? It is an expansion or contraction or a sense that something is moving against a resistance or it's overcoming a resistance. And in addition, there is a valence, a sense of good and bad across multiple dimensions and expectations of changes of these things in the future. But ultimately, it just comes down to a space in which movement happens or doesn't happen or is constrained. Right? So it's isomorphic to the structure in which your model, the physical environment in which you interact this Newtonian world that you perceive. And this is all mathematical, it's all mathematical representations that play out in the nervous system. Where embodiment becomes more interesting is if you want to build a system that is communicating with people on a very intuitive deep level, so it goes into resonance with their minds, you probably need to have a system that is sampling the world at least at the same frequency as our nervous system is doing it. And you basically create feedback loops into the world. And the other thing is if you want to create a system that is discovering itself in the world in real time, you basically need to give it an environment where it has a closed feedback loop in such a way that it can discover the loop between volition, action, outcome of action, perception, and changes in its own volition as a result of these outcomes. Your body is being discovered as part of that loop. Without that loop, without this ability to see this connection between action, volition, and changes in the environment, you would not discover that you have a body. The body is actually just that link. It's a notion of a link. And in this sense, you can also have a body in a dream, whereby the dream is of just that link. It's a notion of a link. And in this sense, you can also have a body in a dream whereby the dream is of course completely contained in your mind. In your dream, when you have a body, there's nothing outside of your mind. It's completely inside of the representation. And yet, you can have the sense of a representation of a body that allows you to perform actions in your dream world. And that is the crucial thing, right? So having this feedback, this reflectivity in which you update the world and then see the outcomes of these changes and you realize the specifics of yourself in there is necessary for forming a self-concept and having attitudes that are continuous is necessary for having feelings and also you need to have this reflection apparatus. But the physical body itself is neither necessary nor sufficient. Long answer. Yeah, I mean, brilliant answer, thank you so much. This sense of, how do you say, the mind-running sort of software. In our discussion with Karl Ruck, who wrote a lot about the Eleusinian mysteries in Greece, we discussed how the rituals and the mythology of the Eleusinian mysteries were a kind of sort of programming for the participants, what they saw in like a shared vision of the gods. Do you think that the same is true, you talk about in the Lex Fridman podcast about religion in a similar way, it being a sort of programming for the minds of its followers, like a sort of operating system if you like. In my own education, gods were not treated properly and also during my formative years I did not stumble on any book that gave gods an adequate treatment. I did read the bible as a child and later I tried to piece an understanding together that would allow me to get a better understanding of what gods are. What I noticed about the Greek gods is that they are for the most part not normative in the sense that they are not carriers of virtue. Right? Most people don't feel that they should emulate Zeus. But it's a guy they know, right? You know this guy who is the head of a family and is extremely masculine and testosterone driven and tries to get into everybody's pants and is very powerful and vengeful and irresponsible and very, very there. And has this explosive thing with the throwing fire from the sky. And it's a very specific archetype, right? You get to this archetype by taking the space of human personalities and then you look for a local maximum. And all the Greek gods, or almost the entire pantheon, is the result of that, right? You look at the space of human personalities and you look at the latent dimensions of that space and then you put the sliders to the max and whenever you have a characteristic point in that space because you maxed out some of the sliders you have one of the Greek gods. And so the Greek gods are in some sense acting like communal selves that have shared mind space on people's brains. And people discover them by iterating over the space of personalities. So they're basically natural entities that exist on the minds of people through their storytelling. Functionally, the Greek gods, as we know them today, are superheroes in superhero comics. They basically are tools to create stories about the world and to relate to them. And they also have demigods. And demigods are different from the normal gods because they are basically human beings that are not forgotten because they have good stories connected to them. If you look at Heracles, Heracles is very boring, right, as a personality. He's super generic. He is only not forgettable because of the things that happened to him. But otherwise, he's a generic hero that doesn't have very distinct personality properties. And the reason why people remember this particular individual is really just the stories that are tied to them. So, a god, this is a small g, is basically a self that is spanning multiple minds. Your own self only exists on your own mind. Other people have a simulation of yourself, but it's not doing anything unless they observe you doing anything. Because they notice that the locus of action is completely outside of their own mind when they model you. And when you model yourself on your own mind, you realize that the locus of action of your own self is entirely within your mind. So this creates this binding, but with gods it's slightly different. Individuals that imagine a god usually participate in the creation and the implementation of that god in the world and all the things that this god can do as an agent in the world. And you notice that part of that happens outside of you, right? And what you let it do is constrained by the specification of that god. So a god is an agent that is as real as your own agency, if you believe in it, if enough people believe in it, and enough people believe in it. And so it's implemented on the minds of people or of nervous systems in general. It's conceivable that gods can also exist outside of human minds or are only partially in human minds and a lot of their connectivity and functionality is in other systems in nature, like ecosystems and so on. But by the interaction of people and ecosystems, you might be able to create entities that you're interacting with. It's nothing superstitious about them. It's just a way in which your brain makes sense of reality by modeling the existence of certain agents. Another thing that was not part of my education was epistemology, which means it's probably not part of most of our education. Epistemology is the philosophical field that decides under which conditions something is true. When are you justified to have a certain belief. So when you ask yourself does God exist, the question is first of all what is God here? And when you can perceive God's existence it means it's a perceptual representation. It is represented's a perceptual representation. It is represented in the perceptual-geometric part of your mind for some reason. And if you conceptualize it, it means it's represented in the analytical part of your mind. You're always talking about representations. You cannot observe physics directly. You cannot observe reality directly. The only thing that you get is a bunch of patterns at a level that is too low to discern them directly. So you usually cannot track the excitations of individual sensory neurons. Instead, what you get is functions that are being computed over the interactions of many neurons in the aggregate at a certain time scale. And then is the question, is this representation that you're building adequate? Where does this representation come from? Why does your brain pick up this pattern? What is it that is going in resonance with? And so when you are noticing that an angel is speaking to you, of course, this means that there is a part of your mind that is generating a voice, or the equivalent thereof, in such a way that another part of your mind can observe that happening and reflects on it. But what does that mean? Why did your brain do that? Why did your brain come up with this representation? And so the same thing is, of course, true for the gods. If you ask yourself, why do you perceive the existence of a god or even of a total god in the monotheist religions. Where does the specification for this entity come from? Why is it stabilized on your brain? And that is the actual question that you need to answer, right? It's not so much that you have to ask yourself, is this thing in reality? Well, something might be implemented that gives rise to that representation. What actually is it? What pattern is it that you're picking up on and why? actually is it? What pattern is it that you're picking up on and why? I mean, I was going to ask about something related to that, but you've just answered it. I think Abhishek has another question in the meantime. Your audio is gone again. How about now? Is that again? No, yeah, I apologize. There's something happening with my wires in my earphone that's kind of not working. I hope it's not too much of an inconvenience. No, it's better. Oh, thank you. So there are some fascinating insights on the mental processes that you've spoken about so far, which I believe in trying to recreate a consciousness in systems, you do have to really observe what our own mental processes are and actually understand them really well. And what really caught me was that there are very, very interesting parallels between what you said and the commentaries of Tibetan Buddhists on their own mind and through meditation and through deep insights as well. And yes, I was quite really enjoying the cognitive process, as you mentioned it, and perception and so on. Could I ask for an insight on what you think is the cause of variability between humans? I perceive blue, other people perceive blue, but some of them really like blue and some of them don't. And so I really enjoy amber yellow, that's my favorite color really. So stuff like that, but what is this, what in your mind is the insight that causes difference? Because it's the same, in essence there's a similar consciousness process in terms of perception and analysis, like the basics are the same between people, but I listen to Bach and I enjoy it, some people listen to Bach and they're like this is too much, I want to switch on to K-pop or Ravel or something like that. So what do you think is the cause of variability in colors or flavors or something like that? The short answer is that for some reason your mind likes to explore certain things more than others. And most of the differences that we find in talent between people and an interest in people are differences in specific attention which means you get rewards for exploring domains that put you into a particular state that your mind finds useful for instance maybe somebody as a child has found that there is a certain hour of the day when they were safe and left alone and could think in peace and maybe the light was bluish during that hour. And so they start creating initial association between a certain mood which they liked and a certain color in the environment. And this creates an attractor which means that if they want to put themselves into that state they might try to imagine that color more. But what also happened is that your best friend wore a clothing of a particular color as a child. And so the association to this color gives you a particular kind of emotion that you call up whenever you want to be in that state again, and this reinforces this attractor. So in a sense, it's conceivable that you might have a strong preference for color. But there are also many people which don't have a particular preference for color, But there are also many people which don't have a particular preference for color. Because they don't create these associations or perceive them as distortion. Why should you perceive one color as more preferable for your mental state than another one when you want to be always at a good state? So you should basically train yourself to become independent of the perception of different colors in your environment and your mood. And people make different choices on that path. And it's not necessarily people, because this happens for the most part upstream of the self. So it happens before this level where you become a person, at the level where basic aesthetic decisions are made in your mind. And you mentioned initially that in order to recreate something like human consciousness, we would have to understand precisely of how human consciousness works. And I don't think that's the case. I think that in order to understand the mind, you can go down the route of Minsky's Society of Mind book and you try to describe the entire architecture and you end up with something that is extremely complicated and made from many moving parts that are difficult to get right by an engineer. Nobody has been able to recreate the entirety of the society of mind in a cognitive architecture in some kind of computer program. And I also suspect that nature would struggle if you try to express this all as some kind of genetic code that is expanded into a particular brain architecture. So instead, what's happening is, understand how something wants to grow into a mind, build the seed. What are the conditions for a system that if you give it a sufficient substrate is going to change that substrate until it becomes a mind and there's a person in that mind that is driving the interaction with the environment. And that is much, much simpler. It's just a way that is more difficult for us to reason about. Because it's something that we cannot observe. I can observe personality properties, or I can observe the artistic and color preferences of people, but it's much harder to observe what is the thing that grows in a person until it develops something like a color preference. But this is the actual question that you probably need to answer if you want to build such a system. How can I set up an evolution in a sufficient substrate that gives rise to this form of organization that is a human mind? Following up on that, based on your answer, I can say, I consider that, so I think you consider that the variability between people is not intrinsic to their conscious process or to their mind, but it's a conditioned thing. It's something that they have seen through perception and association that has turned into a particular preference in a certain way, right? So you think a favorite color or a favorite flavor of ice cream, for example, those are not, I mean, those are the minor ones, but again, aesthetic choices, they are more conditioned rather than intrinsic to the person, intrinsic to the consciousness in your world. Yes, but if you take identical twins and you expose them to the same stimuli, and then they tend to form the same responses to those stimuli. And so there is an interaction between nature and nurture. And the degree to which your environment is determined by nature rather than nurture is 100% nature. Which means the degree to which you have a plastic response to your environment is also completely built into your organism. And it's probably not constant. So individuals have a different degree of plasticity when being confronted with the same events. There are going to be some children that are super stubborn, not autonomous and do not respond very much to what their teachers and parents tell them, because they have their own mind and try to make sense of the world on their own terms. And there are others which distrust whatever their own mind comes up and they will seek out ideas from the environment and displace their own ideas as fast as they can with the ideas that they pick up in the environment and feel safer when they're able to do that. And this is an interpersonal difference that might be intrinsic, that might be encoded in the way in which your brain works very early on, and this puts you onto a different trajectory. Now in the exact words you used, it almost seems like it's a physical encoding there. Is it built into the organism or how your brain works? But we also talked about how you also talked about how the mind or feelings are not a physical entity as well. So what is, how is, how is nature predetermining something, predetermining things in a person if it's not in a physical way, if we accept that consciousness and the mind itself are not physical entities, how can that be, what is the source of this predeterminism? What is the mode of operation of the predeterminism coming from? Yeah, mind and brain are not the same thing, right? But they're also not independent. And it turns out that the mind is a different way to talk about the same set of phenomena as the brain. The mind talks about patterns that play out in the brain. And you yourself are a pattern within the patterns. If you zoom in, what you see is there is no mind. There is also no brain. There is no organism. There are just cells. And the organism is a pattern and the coordinated interaction between cells. And if you zoom in further, you also realize that there is no cell. There is just molecules and the cell is a coordinated pattern and the interaction between the molecules. And you can produce these regularities by setting up the system in such a way that is self-stabilizing, that it remains within certain specifications. And this ability to remain within certain specifications usually the result of control. Control means that you have a target value that is measured in comparison to the present value of reality. And the system is set up in such a way that it takes that measurement as an input to decrease that distance, like a thermostat does. The thermostat has a target value put into it, which is what would the temperature in my room be, and you have a current value, what is the current temperature, and if that gets too large, the heating is turned on, and if it's small enough, the heating is turned off again. And this is the simplest form of control yet you can have. But the more efficient way of controlling is going to use a model of the future, which means you try to predict the integral of the deviation of the temperature over time that would happen if you were to turn the heating on or off right now. Right, and now means that from your perspective of your new, more sophisticated thermostat, the universe is no longer just a single frame is this present temperature, but it's a branch of universes that are branching into different ways, depending on the choices that you're going to make over the temperature. And this allows you to make a plan of how you should heat. So this energy cost of all becomes much lower than the directly acting thermostat. And by having preferences over future trajectories and making decisions and committing to them, committing to a plan and how to keep the room over time to save energy and so on. That turns the thermostat into an agent. An agent is a controller for future states. And to control future states, you need to model counterfactuals, you need to model reality that isn't here yet. And this requires that you have a causal insulation from the physical substrate in which you are, but you need to use a part of the universe to represent the universe that doesn't exist yet, to make representations to make some make counterfactuals to make the part of the universe behave independently of how the universe is right now. That system is a computer and the smallest naturally occurring computer that we know of is the cell. The cell has a computer built into it that allows us to make such representations and execute on them. And on the level of the organism, we have other computers, basically arrangement between cells that have the ability to form representations and allow to predict the future and make models of the future and control them. And so our own agency, the ability to control the future, is the result of our brains interacting, of cells interacting in such a way that they form different layers of computers. And software is a pattern in the pattern of these systems, right? It's a natural law. Software means that if you are arranging things in the universe in a particular way, you will observe the following pattern playing out regardless of where you do that in the universe. Right. So a word processor is in that class of physical loss, the word processor is the law, it says, if you arrange transistors in this particular way, regardless of the material of the transistors, and they have the following specification, they switch in this particular way, and you put them in the following state, then the state after that is going to be that and the state after that is going to be that and the state after that is going to be that, and the state after that is going to be that, and the state after that is going to be that. And the word processor is a way to talk about the regularity in these state sequences. It allows you to interact with the world using that particular law that the word processor emerges, then you put bench transistors in these states. And the same is true for our own mental states. So a spirit is an operating system for an autonomous robot, whereby the autonomous robot can be a person or a plant or a nation state, or an ecosystem. And the spirit is controlling the agency of that system, the preferences of that system for the future, that allows the system to stabilize itself in an ever-changing physical environment. So when you say causally independent, are you suggesting that there exists something of our, and you're trying to find some similarities with the mind. Are we saying that there is something, some aspect of the mind that's causally independent of the hardware that is the body or the brain in essence? And that's kind of one of the ways in which we were able to bring about, let's say counterfactuals and maybe cause anxiety for ourselves, thinking about the various counterfactuals that may never happen. But is there something about the mind that you think then is causally independent to the physical substrates? If you think about a camera and you look at, say, an old chemical photo camera and you see the light entering the lens of the camera and interacting with the substrate of the film in the camera. You realize that it's completely dependent on what happens in front of the lens and other factors like the temperature of the camera might play a role and so on. There is no causal insulation. What happens on the substrate of the camera is directly a result of how the camera interacts at this point in time is developed around it. But if you think about your iPhone, maybe, and it runs a game on it, this game is working the same of whether we are sitting in the subway, or whether you are sitting on your front porch, of whether the temperature is five degrees higher or lower. It's independent of what happens in front of the camera of the phone and so on. But you can take this thing over a very large range of environments, it's good to do the same. And this is what I mean by this causal insulation. It doesn't mean that it's causally independent. It's just the system has been constructed in such a way that is regulating all these disturbances away. So you can ignore them, at least for a wide range of phenomena. And the same thing happens in the cells in your brain. You can move your body around over a range of temperature and pressure ranges and so on. And your brain is essentially still going to give you the same results. So you can generalize over your environment, even when the environment changes. And this means that it's in some sense disembodied, right? Now your computation that is performed in the phone and the computation that is happening in your own mind is disembodied, is somewhat independent of the actual causal substrate. It's still being implemented in the lower level physics, right? There is no magic going on. It's entirely mechanical eventually, this pattern generation process. But the pattern generation process is set up in such a way that it corrects against the specifics of the environment. And the thing that preserves is only the irregularities of the mathematics itself. So it's performing a computation that gets more and more independent of the disturbances by the world. And the only disturbances you want to have are those that are perceptually relevant. And so, in your opinion, do you then think the sense of self, as continuing that discussion, then the sense of self that we have, because if we think if we zoom in and there is nothing but cells and if we zoom in further, there's nothing but molecules, then the sense of self, is that, in your opinion, something that's pure perception? Where are we just confusing, where are we perceiving things that are just collating all these causally insulated things and then calling it, oh this is independent of everything and this is permanently present within us, but this is the sense of self that we have. Do you think that's the way we perceive it, there is no self per se, but it's all just perception. Well, there is an agent in the world that is being implemented as patterns in the interaction between cells, right? That makes sense to say that there is something that exists that is represented by yourself. And yourself is the discovery of an agent in the world that is using the contents of the model that you're computing right now to drive behavior. Okay. But you notice there is a thought that I'm having and that thought is changing things in the world. There is an urge that I'm having and to which I give in and as a result, something moves in the world. And that is when you discover that thing, you discover the first person perspective that this agent has. All right. Thank you so much. Yeah, that's my question. I'll let others ask questions. Thank you. Julian, do you have a question? Yeah. This is extremely interesting. And I've heard you speak in previous conversations about sort of your role on the, your view on the finite and the infinite in computation and in logic and how you described geometry as the mathematics of having too many things to count. I wondered if you could expand upon the role of the infinite or rather how it might actually be incorrectly asserted. There are basically two ways of doing mathematics, of learning mathematics in school. One is the normie way, which means your teacher tells you what's true, and you try to believe the teacher. And the other one is the nerd way, which means the teacher says something, and you account for the possibility that the teacher might be confused or lying and you will not accept anything the teacher says before it makes sense to you. And for something to make sense to you, you need to be able to recreate it in your own mind. At the level of where it was formulated, I want to understand why would you have that idea? What is this claim that you're making? What representation does it correspond to? So for instance, when my wife was asked in school as a young girl, mathematics teacher, why is two plus two four? The teacher did not explain this as a simple game that we played. Mathematics is the domain of all these games. And we just have come up with these five rules which are called Peano's axioms, which say zero is a natural number and the successor of a natural number is also a natural number and so on and so on. And if we just use these rules, we can define a subsequent labeling scheme. We can give every location in the world a name. And we can have an unbounded number of names. And they are ordered. And this allows us to define operations in which you can move around in the space, for instance, addition by which you can jump around in the space in a direction, or multiplication in which you can zoom in this space, right, or rotation in which you can define multi-dimensional numbers and move between those dimensions by keeping the object shape constant. This is what he should have told her. Instead he told her, because we say so. Because important people have decided that this is true. And this meant that she shut up and shut down and moved to her in a happy place because she didn't want to have anything to do with this. It made no sense. Just also with terrier brutishness and arbitrariness. And this is this difference between understanding mathematics from first principles and from this normative perspective where you have to understand something because people who are much smarter than you can ever hope to be agreed that this is the case using methods that you never hope to understand. And my own perspective on mathematics was also of this nerdy kind, which meant that I didn't understand mathematics in school because it was not taught in a way that I could understand. Instead, I had a Commodore 64 and the Commodore 64 had a very interesting quirk. The programming language that it had didn't have any way to make geometry. So for instance, you had no command in the basic language of the Commodore 64 to draw a line on the screen. So how do you draw a line on the screen on the Commodore 64 to draw a line on the screen. How do you draw a line on the screen on the Commodore 64? Because of course I wanted to do that, I wanted to do 3D graphics. And at the time there was no 3D graphics program for Commodore 64. Also I lived in Eastern Germany, which meant I had to write most of my software for myself. And so what I learned is that the Commodore 64 is representing everything on the screen as bits and bytes. Every character on the screen is made up by 8 by 8 pixels. And each of these pixels is represented as a vector of 8 bits. And these 8 bits are encoded as a number between 0 and 255 if you translate them to decimal, but actually they're just binary numbers where every digit is either on or off. You can change these individual digits using Boolean logic, AND, OR, and NOT. If you want to change a line on the screen, you need to find the part of your computer's memory that stores all the pixels on the screen. And then you need to change the individual bits, which means you read out the current value of the byte at the area where the pixel that you want to change is. And then you need to flip this pixel by using and and or, right? And then you write this resulting number back into this memory address. And if you want to make a line, you have to find out where the individual coordinates are in your space and how they're mapped to the address space of the computer and to the bits in that address space. Then you change all the bits. Once you've done that, you can also start to make geometry of three-dimensional objects. You basically need to give multiple coordinates in a three-dimensional space and then you need to map this to a two-dimensional space using very simple arithmetic that you can derive by yourself. It's not hard to figure out how to map 3D into 2D and then translate this into small programs in BASIC that perform all these computations for you and voila, you can now construct a three-dimensional object and present it on the screen. And only much, much later I realized that I thought mathematics has its own way of doing that. I thought that they have an amazing way to create geometry that I would never be able to discover and complicated hieroglyphics, which they reference these amazing ways. And then later I learned that these amazing hieroglyphics are just clunky ways to write loops and call subroutines. And that mathematics in some sense is a code base. But it was a code base that was developed before computers existed. So people had to run all this code on their own minds or using pen and paper. And they didn't know how minds work. So mathematics is defined sometimes this way that you think geometry is given, because your perceptual system learns how to compute geometry. But it only does this to an approximate degree. And at some point, we noticed this relationship between geometry and algebra. And in school, I think we learned the wrong way around. Algebra exists in the first place to compute geometry. That's why we invented it. The reason why you can describe how a ball is being thrown through the air using some kind of hyperbola, and you can describe this hyperbola using a small equation, is not an accident. That's the reason why we developed this language in which you can describe the equations. And you can do the same steps in your computer. And when you do this, you realize that you're never going to get to a concept of infinity, because it's not computable. There can be no computer program that gives you infinities. What you can have is unboundedness. You can have programs that give you values more and more the longer you compute. So you can have a program that gives you more and more digits of pi. more the longer you compute. So you can have a program that gives you more and more digits of pi but you cannot implement a subroutine that relies on having known the last digit of pi while it makes a rotation. It's rotation definitions that require you to know all digits of pi cannot exist. It doesn't make sense. You cannot construct them in any language and what GÃ¶del has discovered, if we assume that there was a mathematics in which that was possible, then it would break. The language in which we try to assume that infinities exist and we should presuppose them somehow is going to run into contradictions and we cannot avoid that. So there are only certain constructs that make sense, that run without contradictions. And it turns out never in mathematics have mathematicians actually used infinity to compute something, right? It's just a way to point at the unboundedness. But it's not something that you can fill into a formula and compute. So it was never a working part of mathematics to begin with. And the switch from the mathematics of the infinite to a mathematics that is computable, constructive mathematics, I think was a big step of what happened in the understanding of what languages are in the last century that was not properly digested by the mainstream of academic philosophy. I think, Sion see another question. Yes, so I have a question. So as far as I understand, what was the fundamental problem when we're trying to create a human mind like AI is assigning things to values, whatever that values means. But such assignment of values, such assignments of values can also be values themselves. So in what way can we be able to create this AI or human-like artificial intelligence such that it has the ability to keep this abstraction of a sum of values. Sorry, uhm... There are two types of values that you're talking about. One is a state, basically a pattern, like a bit vector, a number stored in a computer, a parameter. And the alternative to a parameter is a function. A function is something that can take parameters and turn them into other parameters. A lot of the things that we treat as values, for instance pi, is actually a function. Pi is a way in which you can figure out as many digits as you can afford. And in the computer program, you can often instead of a value, just write a function that you evaluate when you need it. So you don't need to store everything. You can often it's sufficient to store the way in which you can derive the actual value when you need it. And this allows you to compress reality, right? So our mind for the most part does not actually store values, what it stores is functions that allow the mind to generate other functions and then other functions which allow you to create the value as needed. So what you need to learn is functions, ways to compute, how to get from certain patterns to other patterns. The way in which you can imagine this to happen is if you think about a game engine. If you ever wrote a computer game with Unity or so, this is a predefined software that has lots and lots of objects in them. At the lowest level, you might have, for instance, textures for objects that you display on the screen. And these textures are superimposed on surfaces that you display on the screen. And these are superimposed or connected to skeletons of moving characters on the screen that you can animate. And the animations are connected to animation controllers that are being triggered based on whether the character is walking or jumping or swinging their sword. And this is connected to a model of a small agent that is being remote controlled by the player or by a computer program that controls an NPC, right? So you have a game engine that is using many levels of representation to produce a visual world on your screen that looks quite similar to the world that you perceive when you look into the world and allows you to capture causal relationships to such a degree of fidelity that you can interact with the computer game because it's a simulation of a real world and important aspects. And your representation of the world that you perceive around you is of that type. Your brain is not giving you access to the world as it is. There are no sounds and colors in physics. There are only patterns in the activations of the neurons coming in from your retina and from your cochlea. And it's not like these wires that come into your brain have different properties. It's all the same types of accents that come into your brain. The only thing that is different between them is the statistical patterns in the patterns coming in the activations. It's just statistical properties of the data that comes in that your brain is sensitive to. And your brain is making sense of these patterns by training itself as a game engine. And this game engine is basically made out of lots of software objects, lots of small functions, lots of controllers that instantiate these functions, and parameters that tell you what the function looks like. So you have a controller that produces faces in your mind when you activate it. And when you see a certain pattern in the real world, on your retina, then this pattern activates the face generator in your mind. And the phase generator is generating a phase that is conforming to the patterns that you are seeing that allows you to interpret the geometry and expression of the face and recognize the person behind the face and so on. So what you're looking at are parameters to functions. functions? Yes, so we will end up with something like a space of functions, but then again we can have a function that takes values but map to the space of functions. I can keep this abstraction, I can just take and map it to the functions and keep this. Yes, this is how it works. And it's interesting also to a large degree how the current primitive systems of generative AI work. So if you take a system like ChitGPT, it is learning functions. It's not just learning to recognize patterns, but it's able to learn functions by looking at all the patterns, how they hang together. And this allows you to tell JetGPT, please write following function in Python. And now translate this function into C or look at the following piece of code in a smart contract and find an exploit in it and write code for that exploit. These are all functions that the thing has discovered by looking at source code. Or you can ask it to take the following children's story and turn it into a poem or make a limerick that has a cat and pudding and spaceships in it. And these are all functions that it has learned. So is there a universal, but is there like a universal regularity or to these abstraction because I mean it seems to me that like it can be very arbitrary like the space or space of functions their job their intrinsic geometry or topology can be wild or anything we can imagine. The universal regularity used by the transformer is predictive coding. So basically you try to minimize prediction error. It works like autocomplete, that's in your phone. You try to write a few characters and it tries to figure out what is the next word according to the constraints that you entered, which means the sequence of previous words, which gives you the context and the characters that you already typed. And this autocompletion, if the statistics are complicated enough, is sufficient to discover the things that GPT-3 is taking from text or that DALI is taking from images. And it's not the same universal regularity that our own mind is using, I think, because our own mind doesn't use that much data to get to all these regularities. In fact, it would not be able to digest that much data. And instead, what our mind seems to be doing is that it optimizes for coherence. So it starts out with something that is already maximally coherent. And then it has succeeded in discovering all the structure that it can in a very small domain, it makes the domain larger. So it's basically building a representation of the world from the inside out from very small regularities that are quite very tight and builds this up into a larger model. Whereas GPT-3 starts with a model that is very vague about everything and then gradually becomes more and more concrete as it looks at more data. So if I can ask, so yes, so that I guess, so if I can ask a long question. So, yes, so I guess, so what makes you think to achieve, you know, the coherence as human mind, this process is kind of computable, it's possible to encode it, you know, in a way such a computer can operate. Like, because, yeah, because we don't know like this full space of functions or functions. We don't know, maybe we don't know its geometry. Maybe we can put constraint on it and we can learn what we have constrained. But like, in what way do you believe this is, or this is possible to be, you know, encoded in a way do you believe this is all this is it's possible to be you know you call it in a way a computer can compute so you could rephrase this as why is it that human brains discover the same geometry and i suspect that the answer is that if you have a system that is entangled with a certain resolution in space and time and has so many layers of representation and so much plasticity, there is a limit to what it can represent. Best model that can make under the circumstances. And this is just a mathematical property. It's a mathematical constraint. If you have a system with the following abilities to update and with the following timing characteristics and resolution characteristics, and you entangle it with the universe that it goes into resonance with, this is the best model that it can have. And our brains are approximating this. And they end up with pretty much the same approximations. And so if we want to recreate the same thing in a computer, it means we have to rediscover these mathematical constraints. Thank you very much. I just want to ask something on what we said before. So it's on Diolch yn fawr iawn. Rwyf am gofyn rhywbeth ar yr hyn rydyn ni'n ei ddweud cyn i chi. Mae'n ymwneud Ã¢, sut i ddweud, ymgyrch o ddiddorol, mae yna byd mentol ac yna byd ffysigol. Rydych chi wedi dweud, yn y podcast gyda Flex, rydych chi wedi dweud y bydd eich rhan mentol yn wir. that you regarded the, in the podcast with Flex, you said you regard the mental realm as real. This, I think, this sentiment is also shared with people like Carl Jung, who we're going to explore a bit later on into our discussions in society, but how do you go about verifying the contents of your mental experience as real. We talked about like archetypes and this kind of thing. Do archetypes have an objective existence? Is there an argument that you can make for things like beauty or reason as archetypes that exist in let's say the psyche? I think it's a misunderstanding. The property of realness, of experiencing something as real, can only exist in the mental model. For something to experience as real, it's neither necessary nor sufficient that it exists as a pattern in physics. You can perceive something as real in a dream, obviously, right? And there can be something right in front of you that you don't perceive as real. So the perception of an object as real, this property of realness, and this includes the experience of realness of your own self and of your own mental contents, needs to be generated in your own mind. And in your own mind, you have two domains in which you model reality. And this is what the old text described as the earth and heavens. Right? One is this world model, this sphere of stuff in space, that is the game engine that your mind uses to describe the reality around you, the scene in which you are, in which everything is a region in the dynamic free space. And then you have the world of ideas. And both of them co-exist in your mind. It's different domains of models that interact with each other. And when we understand Descartes is describing two ontological substances, like there is one substance similar to floor or wheat or clay that is mental, and another substance that is stuff in space, we misunderstand him. Or maybe he misunderstood it. Because most of these domains, the space of ideas and the domain of stuff in space, they co-exist in the mind as different realms of modeling. That makes more sense, I think. I've spoken to Sonu Chandrasani, who we're going to talk to later on in our Q&As. He said something similar, he said something like that the idea that exists in Jung, which is that he regards the psyche as real, he says is a mistranslation from the German, he says that the psyche is actual in that it sort of has an agency. Would that make more sense within this, if I understood you properly? I think that's confusing and is not helping. The Psyche is real to the degree that it's implemented and there is something about you that is fixed but it's not completely fixed. Basically our own self is as real as the voice and the wind that blows through the mountains. As long as the wind is blowing, the voice is there, but if the wind changes, then the voice is going to change, right? If I shock a person or if they are in a trance state and so on, they become a different person. And until they go back to their previous parameters. So what they are is a result of the parameters that are currently implemented in their brain. And this makes them behave in a particular way, self-perceive in a particular way, reflect in a particular way. There are some aspects of those that are constant, which allow you to recognize the individual across all these changes. And some of these things can change dramatically, which we then perceive as changes in emotion, motivation, and mood of that person and so on, or in mental coherence of that person. But these are all software things, they're all virtual, and the representation of the events that allows us to perceive them as real requires them to be virtual. Consciousness is a virtual property. It is as if. There are only cells, right? These cells are not the organism. The organism is a function that describes the patterns between the cells. And this function is an emerging phenomenon. It is as real as the word processor, which is to say it only exists as a mode of interpretation. The cells don't feel anything. It would just be very useful for a bunch of cells to know what it would be like if there was a person that cares. So they create a simulation of that person. And there is no world that is accessible to all the cells that are interacting with each other. But it would be very useful for them to know what it would be like if there was a comprehensible world with macroscopic objects that you can control the interactions with. So it creates a simulation of that world. And the interaction between the self and that world happens in the mind as a simulation in a game engine. That is entangled with the sensory feedback of the world and the actions that you can perform on the world. Just another thing on this that I found really interesting. You said it as well on another podcast that you said ideas don't die, only people die. In our conversation with Sheldon Solomon, who's the creator of terror management theory, which is this psychological theory that basically suggests that exposure to something like death anxiety makes people cling more strongly to their ideas than their world views. If ideas and worlds don't die, is this why people identify with their beliefs and create things like dogmas? There are many reasons for which you can create dogmas but typically your fear of death is the result of you clinging to some things that need to be done, that can only be done by you. If you give up the idea that things need to be done, or that they need to be done by you, that usually leads to a diminishment of the fear of death. And the reason why dogmas exist is often because you can create beliefs that are self-reinforcing. Once came up with the concept of a belief attractor. A belief attractor emerges because the beliefs can change the probability of changing other beliefs. And this means that you can create a system of beliefs that is self-reinforcing and is distorting the space in which you can move from beliefs in such a way that you cannot believe your local bubble. Ideologies tend to do this. Ideology distort the human thought space in such a way that the victim of the ideology that is hosting it on their mind is cut off from the rest of human thought space. A lot of ideas, once you are in an ideology, become unthinkable. And this is a very useful tool to lock people in, to lock them up with people of their in-group and to make sure that they are not fraternizing with the out-group too much because the out-group is having unthinkable thoughts. So dogmatic worldviews can serve an important role in controlling people. And the reason why Homo sapiens has been more successful than the other species that existed, like Homo neanderthalensis, might be exactly this programmability. Maybe it's our susceptibility to ideas that allows us to remote control people, which made the success of homo sapiens possible but individually it also means that there is a very big danger that we fall into a dogmatic thinking that we get captured and domesticated by the ideas of other people and get controlled in this way and become unable to comprehend the world on our own terms. able to comprehend the world on our own terms. Let's repeat what you said about the cause of death anxiety. You said you believe it arises because of our attachment to the idea of that things need to be done and it has to be us who need to do the things. Does it also apply to things needs to be experienced and it has to be us who experience things, something like that? Is how you define that anxiety? Experiencing is a form of doing. You can test this, it's not belief, it's empirical. You can just sit down and stop caring and then you discover that there are multiple levels of caring and for instance you can stop caring about thoughts that arise in your mind. And you will notice that you stop making lists in your mind, you stop evoking things compulsively thinking to us today need to do the laundry or tomorrow, do I need to pay my bills, and so on and so on. Just doesn't rise anymore, because you're just thoughts and you don't pay attention to them, they're not important anymore. And then what you realize what what's left, what is actually important to you, what is it that you care about? And this might be how your body feels at this moment, maybe you sit in an unpleasant way, or you're cold, and so on. But you may realize, oh, it's still a bit of parameters, I don't actually need to care. So I turned this off to I don't need to care about how I sit and whether it's comfortable or not, just to make sure I need to get a position that I know is not going to hurt my body. And I'd stay in this position and I can just ignore what my body says about this. And once you do this, you may realize that the only thing that's left that you care about, maybe it's love, maybe it's the connectedness to your sacred purposes that you share with others. And that is driving everything that you do and makes you motivated to reflect about the world and your place in it. And then you give up on love and you stop caring about that thing. And then what you realize the only thing that's left is aesthetics. So you only try to find patterns and the things that you perceive and observe and how they fit together. And when you say the patterns are also not important, I don't care about that. I don't need to pay my neurons for finding structures. Then you just fall asleep. Just fuzz out. Yeah, okay. I think I should, I will, I shall undertake a similar exercise before coming up with questions on it because I do feel like it's very similar to a meditative process in instead how you're not, instead of not carrying, you're paying attention without adding to what you're paying attention to, like thoughts come up, you're not adding to the thoughts, you're consciously not paying attention. What I try to describe is that everything that goes on your mind is the result of a hierarchy of purposes that are activated in your mind that make you spin contents. And you can turn off all these urges. And if you turn them off, you notice that certain functionality of your mind stops being there. You're just stopping producing certain types of content. And this is true for all the contents. You basically can turn off everything. And when you say you... Unfortunately, we switch back after a while, right? So basically, nature has set up our brain in such a way that by itself, it tends to fall into certain attractor states. And you can move yourself out of them. And there's a little bit danger in this. There are people which have meditated themselves into an untenable spot. So don't overdo it. You can indeed reprogram yourself in such a way that you become permanently dysfunctional with meditation. So in some sense I believe that meditation when done seriously and without supervision is more dangerous than most drugs. Because the effects of drugs that people are taking can be devastating, especially if they trigger latent psychosis and so on. But for most people, they're very temporary and they go back to their original state. Whereas when you achieve the same state that people go into it by just shifting the chemical equilibrium of their brain for a short moment. And they do this permanently using a gradual stepwise process. They might perform changes that are much more difficult to undo. And there's usually a reason why your brain is set up in a particular way. And for most people, it's a good way, even if the environment is not compatible with them. It's just we often spend our time in compatible environments, environments that are not suitable for our brains. And as a result, people develop meditation as a coping strategy. But I don't think that we evolved to be able to deal with our environment only if you sit still for two hours and boot. Uh, in essence, when you say stop caring, are you saying, what are you implying with the word care? Does it like stop paying a certain type of attention or start being attached to something that you're thinking about? What exactly are you implying by that? Many people, attachment has a valence. People think I'm too attached and getting less attachment is always good. But this is not the case, right? If you stop being attached to your children, then you stop taking care of your children, unless somebody forces you to, right? So it's a good thing for the most part, if you care about having children and their well-being, that you are attached to them and attached to their well-being. And of course, there's a little bit of a loop in here. You can, in some sense, put yourself into a state where you don't care. And once you're on the other side, you will also not feel there's anything wrong with not caring. But it's tough luck for your kids, but you are safe. You are on the other side now. And so there is this beard attractor thing again, that you basically, by being in a certain mode of attachment, you become somebody who wants to have that mode of attachment. And the reason why I point this out here is philosophical. I'm not suggesting that you guys should all sit down and meditate yourself in a particular state, because it would be so much better if you were in that state. No, I'm only interested in how does this work, what is attachment, how does our mind generate representations and for what reasons. And what we can find that it's not something that we need to take on face or that we need to take out of a book. It's something that I felt I discovered myself because I made these experiments. Thank you. Yeah, that was quite the insightful answer. There's so much to observe in your own mental processes as I'm trying to understand that. Thank you. Tawi, did you want to ask a question? Yes, please, Chris. Yeah, it's probably easier if I just talk it rather than type it. Thanks, Joshua. This has been's probably easier if I just talk it rather than type it. Thanks, Joshua. This has been really fun and fascinating as well. I think at the beginning you mentioned that you believe that AI is the most important philosophical project that there is. And I was wondering if you could just say more about why you think that is and where you think it's going in the future also. Because for example, I know quite a few musicians who've worked with AI or specialized in working with AI, and they've generally come to the conclusion that it's an extremely useful tool, an incredible, you know, creative tool, but they're not hung up at all on the idea of whether it'll become an autonomous creative agent anymore. They've accepted that it's basically a very advanced tool that they can lean on and, you know, it'll have a relationship with humans whereby they can curate what the thing generates. And I'm assuming you're expecting something like that in the long term future, in that we'll have a relationship with AI, whatever state it reaches, however advanced it gets. And so yeah, I was just wondering if you could say a bit more about that. And also that it seemed like you were implying that it would be like the successful Tower of Babel project. Is that, I don't know if that's correct, but it sounded like that's what you were saying. But I took that story as a parable about hubris rather than anything else. Yeah, I think that the biblical texts have been partially mistranslated by the Christians and the folkloristic meaning that we assign to terms is the result of that mistranslation. For instance, in Genesis 1 it starts out with a creative spirit hovering over a substrate that is still void and that needs to find structure and describes the beginning of cognitive development in the mind. And when this text was being translated, there was no way in which people would understand the word substrate. So it's being translated as water. And you have this weird situation that before there is even light, darkness, there is already water. And then people try to make that fit and find an interpretation where the words mean things, but it's the other way around. You have to think about what is possibly being expressed. And then you see what's in the language and in this process you discover some of the meaning of the words that must have been intended and when we think about how minds emerge there needs to be a feedback loop that leads to the discovery of a self and what's interesting for us when we look at an artistic product is this capturing of this state of a subject that relates to something. That is what makes us interested in art. And if people are still at tier two, where they are looking only at the form, does this look good to me? And then look at a piece of music generated by an AI that is able to iterate over state machines that make patterns of sound. This might sound good, right, but once you understand what you're looking at, is what you're interested in, it's not so much the pattern, but the thing behind the pattern, the subject that is perceiving something, you might perceive that it's empty. you might perceive that it's empty. And you find this discourse a lot in the generative AI space, where you have lots of people that produce stuff that looks good but is empty, because there is clearly no organizing principle behind it. There is no subject. There is nothing that experiences and relates to it. And you notice this when you pay close attention over several of the creations and you basically see that it's just randomly arranging patterns that it has picked up. And so GPT-3 and DALI in some sense are a random number generator that deflects its output over all the gibberers that it finds in the internet in visual or textual form. And once you have comprehended these patterns on the internet, once you know pretty much the same patterns of the internet, and subjectively, I feel that with GPT-3, I roughly feel that I roughly know everything that you could see as read on the internet. Most of the stuff on the internet is not that deep. And the level at which GPT-3 can instruct information of it is not at the level of a true expert, because the algorithms are not that good. So you just realize it's mixing and matching those things. And it's doing this with much more effort and attention to detail and so on as than human beings could do, and at a much greater breadth. But at some point it gets boring. Because you could do this better, right? It's a subject could do this better. And you are more interested in this autonomous mind that is performing the creative task of relating itself to the universe. That is not to say that every subject is interesting, right? Many subjects are very generic and don't do anything new or never try to do anything new that they then publish. And you need to get to the level where they are real and where they have actual resolution and where something actually matters to them. But it would be possible to build this now. I think it would be possible to build an AI artist. And this would work by this thing recording its interactions with the world and taking a stock of everything that it does. So it would need to take into account when it creates something new, everything that is created so far, and the interactions that have taken over these artifacts. For instance, there's an audience that was discussing it with the system. And this resulting system would not be human, right? It would be in a very inhuman artist that would create in a very different way. But it would be a way that we would could begin to comprehend. It would be confronted with a non-human artist that is reflecting on the world and actually cares about what it produces, that has a recognizable voice and identity that is growing along with its body of art. And I think this could be incredibly interesting. Right, once we can make one, of course, we can make many and create a complete overload for the audience. But imagine we would build such an artificial artist, I think this could be actually super interesting to to observe what this thing is doing. And nobody has done it yet. So it's something that is I think, in our not too distant future, that somebody is going to build the subject that is I think in our not too distant future that somebody is going to build the subject That is going to take to care about what it produces Yeah, yeah. Oh yeah, I just remembered. So, basically would you say that something that we kind of do apart from doing for really for money, but like as a hobby or as something we are interested in is for the same reason that it's a kind of a self-preservation instinct the same way that sex is also a self-preservation instinct because we are afraid to die. So, like, sex is basically like you having your genetic information passing over to another human being and thus forward there's going to be a new life form that has your information, that has you, because it has what you are and will only help you. And as such, that's perhaps why it feels good in terms of biology, because this is essential for the survival of human species. And at the same time, this is more of a lower form of self-preservation. But the thing is, there is a higher form of self-preservation in such that when you do art, when you compose music or when you write an article about anything about mathematics, history, you're inputting your own code the same way that you're inputting your genetic code into a human being, the same way you're increasing your code into paper or violin or anything else. There's going to be later, after 100 years or maybe any amount of time, somebody is going to see a fraction of your ego in some way. I suspect you have that backwards. We don't have sex because we are afraid of death. It's the opposite. We have sex because we are reckless. The decision with whom you procreate is the most important social and economic decision that you can make. It should actually be painful. Turns out people are willing to do this under conditions of pain. People do pre-implantation diagnostics and artificial insemination under very painful and unpleasant and embarrassing conditions. And they do this because they want to have children. And it's completely orthogonal to the desire to have sex. And when people have sex, it's mostly not because they want to have children. And in most instances, when people have sex, people take great precautions to not have children because they realize that sex is not there to produce children, it just randomizes whom you pay child support. It's an offset. Of course, you can take this perspective that sex is actually the meaning, right? So you can say we live to have sex, and we give birth to children so they can have sex too, because it's the most important thing. And this exists, right? But it's a kink. And for instance, I suspect if a person is motivating themselves through pain, at some point they will become kinky, because they will associate the pain with something positive. They will realize putting myself in a state where I expose myself to pain is something that allows me to reach my potential. And the opposite, if a person is motivating themselves with pleasure, they also become kinky, but in the hedonist way. And art, in this sense, is mostly a kink. It happens not because people use it as a tool to live more, but they use it to get away from the things that would actually constitute progress for themselves in life. So instead of building a house and finding relationships to friends and building a family and so on, they make complicated patterns. It's totally fascinating once you realize this, right? And to me, this realization came when I talked to a musician who was doing IDM at music festivals. And he told me about this usual plight of the artist that the really good stuff, nobody's interested in it. What they want is the lowest common denominator that is somewhat danceable, that can be completely generic. And so I realized this, right? You are going to this festival, which is an economic institution that exists for allowing people to network around here in the desert close to Silicon Valley. And you are telling the organizers, you know, I am addicted to making very complicated noises and you should pay me for this. Why should I do this as the organizer? You should do this so more people become addicted to these complicated noises. Because, see, they're very addictive. I like them very much. And then the festival organizer says, nah, do you see another reason? And the organizer says, the musician says, yeah, it also allows sometimes people to connect to each other and to socialize and to dance and to have a good time. And then the festival organizer says, okay, this is the part that I'm going to pay you for. Right? So they have this tension that normal people who are right in the head, for the most part, don't become artists. One way of looking at this is, a manager once asked me, why people like me were not building companies most of the time, and instead they were sitting down and producing ideas and theories and so on. I told him, you know, we are elves. The elves, they are singing and dancing in the forest. They create palaces in their mind, which they show to each other. They eat to make art. They do magic. It's they eat to make art, they do magic. And from the perspective of the elves, you people are orcs. You only consume art as a tool, as for education or entertainment or as a status ornament. And you eat to eat. Everything you do is to make more orcs that can eat more. And that's very ugly to us. And it's of course very tempting for the elves to think that they are the more refined and sustainable version. But it's not true, of course. Elves are defective orcs. They are deeply confused about what actually matters. There's also this third kind, the dwarves, and those are those that like patterns. They just like to dig down and find crystals and what they find, and a lot of mathematicians and so on are basically engineers are dwarves. It's very interesting that Tolkien unearthed these archetypes. They're constructed, right, constructed to give us this insight into different types of motivation and psychology in the tribes that emerge over them. So when we realize that we are a hedonist, or that we are an artist, or that we are addicted to pain, it's not necessarily that we discovered a big universal. It might have discovered a king. Fantastic. Maybe just because we're running out of time to close I'd love to ask a question which is we speak with regards to some artworks as they are deeper than others so the depth of an artwork is something you were just talking about previously about the internet is mostly boring and this kind of thing and so AI art is sort of based on this sort of like boring sort of database. Like for your conception of an AI artist, I was wondering if you could perhaps just speculate on what people can do to increase the depth of the art that AI creates. It's in some sense related to how do you make your own art more relevant. And there are two aspects to this. One is how can you maximize the audience? That is the boring part, right? In order to maximize the audience, you need to find a segment that goes for the stuff that you want to produce and you need to move pretty exactly half a tier above them. If you're more than half a tier above this largest audience, then they can no longer understand you. And if you are at the same level or below then they're not interested. And that is a very strategic process that by itself has the wrong incentives. So I find it much more interesting when art is being produced by somebody who is trying to get real, which means they try to talk about the networks of meaning that they're actually part of, that they're relating to. It's similar to morality, right? If you are a 20-year-old college activist, you are probably an idealist, which means that your idea of what's moral behavior is derived by hallucinating in a moral community, right? An ideal of morality of humanity should be like based on your present understanding. This hallucinated entity is the arbiter of good and evil that is directing your behavior. And at some point you become a full adult and what you observe is that there are actual networks of caring that flow through humanity. There for instance the relationship that you have to your friends and children and the relationship that other people have to their children and friends. And these networks are connected. And they happen on many layers. And some of these layers are about ideas and ideals and aesthetics and how society should be working. And some of them are about symmetries. And some of them are about things that matter to people for all sorts of reasons, right. And this creates the actual network of caring that exists on this planet, and you're part of it. And so when you talk about morality, you are talking about this actual network of caring, not some hallucinated thing. You're talking about the thing that you're part of. And the same thing is true for art, right? You instead of hallucinating patterns that look pretty to you, you try to find out something that captures your experience. And once you start to do this from one end, it's already deep because it's the entire universe of representations that you created in your own mind that it's connected to. That is such an insightful point. I think it connects a lot with what we were talking about with John Leveque actually about trying to create art that captures people in a sort of collective flow state where everyone's sort of moved together by the art and therefore the art is sort of something that speaks to everyone. And it doesn't have to speak to everyone. You can also have art that is expressed in such a complex language that very few people understand it and that's fine. You can have art that doesn't require a flow state but that requires an extremely reflective or metacognitive state. All these things exist, they're all valid. metacognitive state. All these things exist, they are all valid. Yeah, I think that too as well. There's this brilliant art that I think is in all those different realms of understanding. The beautiful artwork I just covered last year was done by Justine Toney. Justine Toney got infamous because she derailed the Occupy movement. She is a very fascinating high-level troll, very, very smart. And on her website, she has developed an interpreter of the lambda calculus that is written in very few bytes. And this thing is an amazing work of art, right? But it's nothing that is digestible to most people. And it is also not creating a flow state when you parse it. It's quite tedious to parse, but it's very beautiful. And it's a very deep reflection about some part of reality that is quite arcane to most people, but it's art in its motivation. There's also the kind of art that we need to take in the back of our mind as part of that larger space of things that allow you to see things. And some of them might not be connected to your own mind yet, and you might not be able to branch into them and to move into them. So most of the art is going to be to some degree incomprehensible to you. And this ability to develop new areas of comprehension is probably one of the biggest values that art brings. I think that's a really beautiful place to end. Thank you so much for your time and your generosity. It's been such an incredible discussion and yes, so many insights in what you've just said. So thank you so much. Likewise, I enjoyed this very much. Thank you for facilitating this. Sorry? Thank you for facilitating this. I'm very grateful for the conversation. We're very glad that you enjoyed it. So I'm thinking, so with these recordings, I usually post them on to YouTube for public consumption. Is that something you're okay with? No, of course. Go ahead. Brilliant. I'll let you know how it goes. Thank you so much. Yeah. Brilliant. Goodbye. Have a wonderful afternoon. Or evening now. Thank you so much. Bye bye. Bye bye. wonderful afternoon.", '58.439143657684326')