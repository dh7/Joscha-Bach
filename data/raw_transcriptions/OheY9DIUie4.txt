('<center> <iframe width="500" height="320" src="https://www.youtube.com/embed/OheY9DIUie4"> </iframe> </center>', " Thank you so much for having me at this very exciting symposium. We have seen a number of growth curves today that look like this, and these are the growth curves that get us very excited. But when we zoom out a little bit, we realize that usually there's a thing that happens inevitably if you live in a universe with finite resources and you depend on the puddle of neg entropy that you live on, you basically reach a saturation. So basically everything that initially looks like this is the first portion of something that looks like this. There's the saturation point. And if you zoom out a little bit more, then you often find that it's actually a hump, right? Because what comes up usually must go down at some point. Again, so phenomena tend to be temporary. And so these trends are very different on a different level of modeling. And very often, the thing that you're looking at is actually something else. So what is it that you're looking at? What is true? And when we think about truth, we have this notion of a ground truth. It's an interesting question. Does our universe have a ground truth? I think it's probably not an episode of Twin Peaks. It seems to be in a particular way. The idea that the universe is in a definite way and progresses in a definite way gives pretty good predictions, right? You can test alternate ideas and they don't give very good predictions. So it seems to be a good idea that our universe might have a ground truth. Of course as an observer that is embedded in this universe, for trivial reasons I can easily prove that I cannot know that ground truth because it could be a hallucination, right, this universe that I'm seeing. I would still maybe have to explain the fact that I'm able to hallucinate. But when I'm hallucinating very hard, I might not have the necessary coherence to trust my thoughts about my own hallucinations. So I need to make a lot of assumptions as an observer already that I can then try to test to see whether they give good predictions to know what kind of observations I can make and whether I should trust them. And this idea to which degree you should trust your observation, this is called epistemology. What can you know to be true and to which degree? And there's like a fundamental law of epistemology which was discovered in about 1620 by Francis Bacon. He was certainly not the first one and not the last. This is the confidence in your beliefs must equal this weight of the evidence. You should have all the possible beliefs, have them all. You're not free to pick one because you don't know. If you don't know which belief to pick, you are forced to be agnostic. You're now believing that you're agnostic. If you have integrity in your beliefs, you believe that you don't know. And then you have to quantify the degree to which you don't know. And you're not free to pick an arbitrary null hypothesis. I mean, you know this from your interactions with your colleagues. The null hypothesis tends to be a very elaborate conspiracy theory that you just share with your peers. But this is not the way to find truth, right? You want to step back from this. You want to map the space of all the possible theories that could explain what goes on. And you need to express them in a word. Certainly, you need to compare them. And this is where it gets to language. So in a very general sense, language is more than natural language. It's also the things that you used to think in, that mental representations are formed. It's anything that can represent something. So you can make models. And a language, basically, is a set of rules for representing and changing models, and the set of all languages is what we call mathematics. And the ability to make models is what we call intelligence, right? Intelligence is the ability to make models. It's not the same thing as reaching your goals. This is what we call smart, or the ability to pick the right goals, which is what we call wise. Very intelligent people are often neither smart nor wise. So intelligence is also something that is multi-generational as a property. So our models often cannot be made within a single generation. A single researcher can probably not find out the difference between cats and dogs. And that is something that makes sense to be differentiated into. You need to build all these models for many generations. It takes more than one generation to invent a natural language and then to make it true and universal and strict so you can make actual proofs in it and so on. And to discover the preconditions for making truth. This took a long time, right? It takes many centuries. And so there's this weird thing that while generations only produce these thoughts, individuals are often much smarter than the generation that they are in. Because people tend to converge to beliefs. And if you converge to a belief, it's less truthful than when you didn't have a convergence force. So whenever you have something that tries to force you towards convergence, it forces you away from truth. And truth is a very subtle and brittle vector, right? So as soon as you feel that there's a force acting on you that is not exactly pulling you towards truth, on average, a group of people is not going to end up at truth. An individual might decide to resist this, a group cannot, which is why groups usually have difficulty with truth. So what we find is that while individuals might be smarter, civilizations tend to be smarter than individuals. So if you zoom out over many generations, you will find that civilizations get a few things right that no individual gets right. There is something like a civilizational intellect where many, many people make many, many bets. And all these bets together pan out better. And it's also something that grows. And it's like a cathedral that's being built. And that cathedral is built over many, many centuries. This is a civilizational intellect in a way, and a civilizational hive mind that tries to find a model of the universe and the civilization in that universe, and tries to become conscious in this sense. And this thing is generated by people that think about this and do this in a way that adds to this big building. It's like a giant cathedral. It's a thing that we built over many generations. It's been a machine, a truth god, but it's a god that doesn't care about you. It's a god that doesn't give meaning to your existence. It rewards you for your earthly toils. It is not warm or cold. It doesn't help you. So the fire that drives you in order to feed and build that thing must come from elsewhere. But this machine, in a way, is the founding myth of our civilization, that people built this thing, this global thing that would reach the heavens, that would explain everything, that is there to know and conquer it all, this global optimum of the modeling space. And this project fell apart because people started not speaking the same language. They started using different languages. There were suddenly postmodernists and continental philosophers and lots of people that spoke in such a different way that it was no longer communication possible. So this happens all the time. In order to build an intellectual tradition, you something like a time to think for a while. You need to be able to sit down and think in peace and quiet for a few thousand years. And this never happens. Basically after a couple hundred years the dog flies open and a bunch of thugs comes in and says it's revolution now. The king is dead and you also all die. And they tear down this building that has been built over many generations. And two generations later, the knowledge worker drones of the descendants of the new king come in and say, OK, we need to have this thing again. And they try to recreate it. And they usually just recreate its likeness and don't get the foundations right. So all our civilizational intellects have scars in them. And these scars make it very hard for us to think about certain things. We have names for them, but often we don't really know what they mean because they don't point to the right foundations anymore. So many of the things that we talk about, things like meaning, God, consciousness, mind, and so on, we think that we know what they mean, but we don't. This makes it very hard for us to really talk about them. And the way to systematically talk about things is mathematics. Mathematics is the domain of all languages. And the subset that mathematicians are mostly interested in is the set of all formal languages, which means languages with properties in which you can make proofs, in which you can decide what's a valid statement or not. And David Hilbert was super interested in this around 1900. He came up with super interesting questions, still keeping mathematicians busy today. And in 1920, he came up with a super interesting question. He said, let's prove mathematics itself. Let's do metamathematics. Let's show that mathematics works. Basically, let's build a machine that is able to run mathematics in it. And let's make a machine that is able to run mathematics in it. And let's make this machine for mathematics, right? So if mathematics can do everything, like make all the models, we should be able to make a model of mathematics that we can run in mathematics. And then it was a very bad thing that happened in 1931. Kurt Gödel discovered that you cannot build an interpreter in mathematics that doesn't blow up if you feed it certain programs. And Goethe has shown this by, Turing has shown this by inventing a machine, a computer that was not invented at the time, to make that visible. This Turing machine is one possible computer. And Turing and Church had shown later that all the computers have the same power. It doesn't really matter which one you pick. But if you have such a computer and you try to do mathematics in it, there are some programs if you feed this, the semantics will blow up. But that's also good news because a little bit later, Turing came to the realization, oh, we have some properties in mathematics, like for instance, truth is defined as something that you can do after, get to, after infinitely many steps. There is nothing physical that can do infinitely many steps. Maybe there's also nothing in mathematics that can do infinitely many steps and get the result after that. What is the value of a function that nobody has computed yet, right? It should be undefined, it should be unknown. Maybe you can put a probability on it, but it doesn't have a value, right? So maybe a truth that is independent of somebody actually doing the work to find it is not a valid way. So this way of defining truth already existed in the mathematics, it's called constructive mathematics. So everything that has a value there needs to be computed. For instance, pi doesn't have a value. Pi is a function. Nobody knows the last digit of pi. Nobody living inside of a physical universe or in a mathematical universe is ever going to build a machine that's going to figure out the last digit of pi, as far as we know. Pretty good proof candidates for that. So we can build a machine that gives you digits of pi, and the costs get more and more high when you try to get more digits. And at some point, in any universe that you exist, you can no longer afford that cost. So the interesting insight that Turing and Minsky had is we are probably machines that can find truth under certain circumstances. We don't quite know whether we are completely general, but maybe we are. And all the mathematics that humans will ever encounter is done on our computational brains. It's done with these things that go from state to state, that follow certain rules that are somewhat deterministic, that are completely random to get there, otherwise you don't get anywhere. And based on this, you are able to process information and make sense of a universe that reveals itself to yourself as differences in information, right? And the meaning of information is the relationship to change in other information. If you make a model, you identify how information predicts changes in other information. This is the way we make sense of the world. identify how information predicts changes in other information. This is the way we make sense of the world. So now we have an epistemology that we can work with. We have an ontology. We have information that is discernible differences. We have a state that is a set of discernible differences. And the computation describes the state changes of a system by a rule that correlates adjacent states. And the computation can be continuous, or it can be discrete, which means it moves in discrete steps. And it can be probabilistic, or it can be discrete, which means it moves in discrete steps. And it can be probabilistic or it can be deterministic. So what kind of computer would we need to run a universe like ours? It's an open question in physics. If you talk to foundational physicists, they have very different opinions personally. But the space of possible theories is known. None of them is completely proven at this point. And so if you try to enumerate this space, the simple thing would be like a Commodore 64. It's a discrete state machine in which every state is definite, there's a finite amount of memory, of course this universe will have a lot of memory, but still. Then it's possible that it's a probabilistic state machine, that means every state can have several possible successor states, so the universe branches in a way. And it's like if you want to see all these states and implement them all, you need a computer which has a memory leak, basically has an infinite amount of state that it could be in. Or you could have a quantum computer in which every state is a superposition of states, or every state can be a superposition of states. Or you can have all these things with infinite memory. And number four is basically the discrete state machine with infinite memory is a Turing machine, in Turing's definition. Or you could have a geometric hypercomputer where the state transitions are completely continuous. And in every state, infinitely many bits are moved and compared with each other. And then you have an acausal hypercomputer where you can send information back in time and so on. So these are all possibilities to think about computers and what kind of computer we're in. Are there time loops in our universe, closed time-like loops? We don't know that. It's meant we can construct mathematics in which this is possible. But it turns out that apparently, there was possibility that the Commodore 64 is enough. A person that wrote first a book about it was Konrad Suse, Der Rechnende Raum, The Calculating Space. And then Ed Fredkin and Stephen Wolfram picked up this idea. And of course, these people are crazy. And then at least that's what many of the physicists will tell you. But then came Toft. And Toft has his Nobel Prize for his contributions to the standard model. And a couple of years ago, he wrote a book and put it on archive, the cellular automaton theory of quantum mechanics. And basically, he doesn't find a limit to reduce quantum mechanics to cellular automata in what he's doing. So what does it mean that the universe is a cellular automaton? It means that you have a state space. Every moment in the universe is a cellular automaton? It means that basically you have a state space. Every moment in the universe is a state vector. And then you have a rule that gets you to the next state. Laws of physics are the rules that correlate adjacent states. Now, what's a cellular automaton? The most famous one is probably this one. It's called Conway's Game of Life, discovered in the 1950s. It's super simple. So basically, you have a grid, a very regular flat grid. Every cell has exactly eight neighbors. This is a cell. This is its neighborhood. And you count the number of neighbors that are alive. Every cell that's green here is a live cell. Everything that's black is dead. If a cell has exactly three living neighbors, it will come to life in the next step. If it has less than two neighbors, it's going to die because it's too lonely. And if it's more than neighbors, it's going to die because it's too lonely. And if it's more than three, it's going to die of suffocation. These are the rules. You now do this step by step. And as a result, the whole thing will start to evolve in a certain way. It moves. And then it settles into a stable pattern after a while. This always happens. The stable pattern can have a period of one, which means everything is dead. But it could also be that it goes on in a very, very complex pattern for a very long time. So there are some patterns that have the property that they are periodic, but they copy themselves along the lattice, along this space, right? You call this pattern a glider. And using these gliders, you can send information around in the lattice. You can send information between different positions in that emergent space. Before you can send information from location to location, you don't really have a space. Now, suddenly, these gliders turn Game of Life into a space, and you can make stuff happen in that space. So this is all made in Game of Life, and it zooms out. You see here gliders that are being produced by small automata, which are called glider guns. It's all done using this very basic simple rule, right? This is only this. Only the starting configuration is different. And what you can see here is you can build Game of Life and Game of Life. It's Turing-complete. Turing-completeness means you can build any automaton that is at least a universal computer in every other universal computer that is at least a universal computer. So how can we make this more continuous and have gliders that move in all directions? Somebody made a version of life that's called smooth life. So you use just many more pixels, and then you count the fraction of the pixels that are alive in a certain radius around you, set similar intervals, and what you get is something like this. So then you can think about this, how this would generalize into number theory, basically try to find all the possible sets of interaction that make it possible that gliders exist. And a glider is basically something that constrains information to a local volume of space, which means usually if you live in something that has an irregular lattice in it, you want to make this robust against disturbances. So this thing needs to be near differentiable, which means the operations that keep that thing in motion and in the constraint in a space are rotations. And then we discover that there are only rotations in two dimensions, four dimensions, eight dimensions. These are identical to the spinor spaces. But this is a different story. This leads us to a universe that we possibly inhabit so we can basically build a mathematical theory a priori of a possible universe with interactions in which information is sent around in space. And then we can check for the set of mathematical theories in which that is the case if one of those conforms to what we can actually observe and we are possibly in this thing. We will never know whether we will be in this thing but what we can do now is we can try to mathematically explore the space of possible universes that could potentially give rise to particle interactions that are shaped in such a way that it could give rise to something like us. And then we could check whether the predictions of such a model conform to ours. We don't live in a universe like this. This is Minecraft. This is a universe in which you can build, as you see here, a perpetual mobility. You can build a perpetual mobility in Minecraft because Minecraft can forget previous states. You can delete information in Minecraft. Our universe, empirically, is reversible, which means it does not forget information. If you make something clean, something else gets dirty. Which means if you want to stabilize your structure against the onslaught of a universe that wants to go in a different way with its structure, you need to delete the changes that you're making in a way, because otherwise they accumulate. The disturbances will accumulate in your system, which means you have to flush them out. And these garbage bits are what we call entropy. So an irreversible process is one that deletes bits. And a reversible one is where every state has exactly one preceding state. And empirically, it seems that we live in a universe that is reversible. And maybe we can explain this by the fact that our universe is somewhat deterministic, because if it's deterministic, even if it starts out irreversible, like Game of Life, that forgets states, after a while it becomes periodic. Once you are periodic, you are reversible. It's an interesting question whether it's possible to have an alternative to computationalism once you get out of this. So the problem with computationalism is that once you discover it, you can explain everything with it. Because everything that I see is only differences in information, and it can always account for these differences in information with a computational theory. I will always be able to construct a computer that produces an arbitrary pattern that I'm going to see on the screen. No matter what pattern you give me, I will be able to write a program that makes it. It's trivial. So there is no way to prove that my computational theory is not the right one, or that my computationalist framework is the right one. Because as soon as I discover computational languages, I will never get in a situation where I can prove that a computational language is not the adequate tool, because it will always produce the best model under the circumstances. But if the universe is something else entirely, we will never know, right? And there is a suspicion, like Penrose has this, he thinks that our brains actually can do all of the mathematics, and there are things that they can do that machines cannot do. He hasn't shown anybody anything like this, but he thinks that this is Gödel's implication. I think it's his misunderstanding. But he basically believes that it's possible that our universe is, in our mind, an unplanted mathematics that are more than computational. They're not just continuous or something, but something fundamentally different. They're also not just quantum. Quantum is just a computation in the complex numbers. It's nothing magical. It's just a different way to look at computations. But Penrose thinks there might be something that is more than computation, some kind of extra computational operator. He wouldn't quite put it into these words, I guess. But this is a way of looking at it. And the difficulty is, if such a thing exists, we cannot observe it. We can also not describe it, and we cannot think about it. Because it cannot be done with any language. So in a way, if you cannot observe it, if you cannot describe it, and if you cannot think about it, what kind of evidence can we have to have any confidence in the existence of that thing? Maybe a non-zero one, but it's hard to say. It should be probably infinitesimally small from my perspective. So I suspect that minds are indeed computational observers. The traditional perspective that we have in idealism is the insight that we live in a dream. In the old days, people figured out that we actually live in a dream, like magic is possible. There are certain rituals that you can perform that will completely change your life. Sometimes telepathy, sometimes you can look into the future. You can make magical rituals to look into the future. You can make magical rituals to look into the future. You can make magical rituals that allow you to levitate and so on. But there is a price that you have to pay for magic. If you do too much magic, your life tends to fall apart further down the line apparently if you read these books. So there is something very interesting going on there. But idealism is basically the idea that we live in a dream dreamt on the mind of a higher plane of existence. And it's typically being understood in opposition to materialism, which means we live in a mechanical universe. But I don't think that these theories are actually in opposition. They are complementary. The mind of a higher plane of existence is generated by the brain of a primate that lives in a physical universe. The universe that we experience is not the physical universe. It's a dream generated by the neocortex to predict data on your sensory interface. There are no colors and sounds in the physical world. Colors and sounds are geometric models that your mind produces to predict the next set of patterns on the thalamus. When you see people, there are no people in the physical world. There is a weird quantum graph out there. And you predict features of that by predicting things that happen on your retina, or you think happen on your retina, based on models that your brain is computing. And these models that your brain is computing is what you experience as reality. It's a hallucination generated by your brain. The same circuits that produce dreams during the night produce dreams during the day. But during the day, if your brain is well calibrated, track the changes in your environment and predict them as well as they can. Right? But this is the reason why magic works. You can fuck it up. You can change your memories. You can change your predictions. You can think that you are able to predict next week's lottery numbers, but you actually bet your money you're going to lose because the bank always wins always wins. This is the condition that we find ourselves in. So we can explain this pretty elegantly in this sense. So this standard perspective of idealism is that we have this dreamt universe, and this exists within the mind. The mind dreams this universe. And then we have the dualist perspective, where you have basically two computers, one that is producing regular patterns, and another one that is the mind that encodes and processes these regular patterns. There's an interface between them. And then there is the idea of computationalist monism, which is pretty much materialism. So if you have a universe that produces regular patterns, it also produces the mind, which is a set of regular patterns that have the properties that are able to take stuff in over an interface and encode it into regular patterns by itself that are representations of what goes on to predict them. And as it turns out, we are simulated observers inside of this mind. So myself is a model inside of the model of the world, right? Myself is an agent that my mind has created, or it's a representation of an agent the mind has created to make its own interaction with the universe predictable and explainable. So our computational ideas give us a unified perspective on epistemology, what can be known, on metaphysics, what's going on, and on ontology, what exists. And people like Marvin Minsky thought, OK, now if you want to understand the mind, we need to take computers and teach them how to think and in that process, people able to understand what minds are. And they started an amazing field, but Minsky was, I think, too smart for his own good. What he discovered was that languages are super important, so he started symbolic AI and basically tried to build downwards from an idea of symbolic knowledge, downwards into reality, to ground this knowledge eventually in perception. And his cognitive AI was symbolic AI. And there were a lot of other people that did other things that were more inspired by cybernetics and by neural networks. And Minsky yelled at these people because what they were doing was too simplistic. And it was true, it was very simplistic. But when you yell at people that do things that work quite well and get better all the time, they usually don't stop doing what they're doing, but they stop talking to you. So Minsky, who had read Piaget and understood his significance for the mind, created an enormous, burned ground around his idea of cognitive AI that nobody crossed anymore. Most of the people that did AI in practice were not Minsky's disciples, even though those existed and basically tried to emulate his thoughts. The others, they did everything, but they didn't read Piaget. They didn't think about the mind anymore. They thought about how to make machines smarter and teach them interesting things. And that basically this rift is something from which AI hasn't recovered really to this day. Big problem also in AI was that the question what is intelligence, and I think it's the ability to make models in 1950, was a lot like the question what is life in 1650. Basically people knew by pointing at it, but they didn't know what it was that they're pointing at. And now we know the answer for life is pretty simple. It's cells. Life is the dynamics of cells. There must have been pre-cellular life at some point, but it was not stable and was gone quickly. And abiogenesis is probably super rare. A cell is a molecular machine that is able to extract neck entropy over a wide range of environments. It's the smallest than we know. And so self-stabilizing neutral molecular machines, they combine the Turing machine with this tape with the right head on it. And you have a self-replicator and a neck entropy extractor. And the whole thing can participate in an evolution to adapt. So if we zoom into the cell, it's super fascinating how complicated this machinery is. And the genome basically is an operating system for the cell, it's super fascinating how complicated this machinery is. And the genome basically is an operating system for the cell. It defines a number of programs encoded as organic acids that tell the cell how to transition from one state into the other, depending on the environmental conditions, and the reading state of the right head. It's very much like a cellular automaton implemented on top of a Turing machine in every cell. So it's an arbitrary complex function. And it's a relatively poorly understood machinery, but it's surprisingly complex. So this is your DNA string. You have the replisome. The replisome is the thing that is able to splice DNA to copy it. This is stuff that's roughly playing out in real time. It's amazing that this machinery exists, right? So most of our DNA codes for making a cell or repairing a cell, meaning you never make a cell. It's a very interesting thing. Organisms and cells are not made. No organism starts with no cells, right? You always take cells and divide them. This first cell is still alive in all of us. We are all instances of the first cell. But not us, because we, I'm a story that is being told in the brain that is formed by lots of these cells. But yeah. So the DNA is not a blueprint, but it's an operating system. And genes either regulate, differentiate, divide, or kill the cell. And that's all they can do, basically. And this differentiation makes it possible that we get different cell types. And this leads to the type of organism that we are in that is built from different cell types. And these different cell types basically need to run different instances of the same operating system. They all share the same DNA. But they also need to have different state. This is the differentiation, the different mode. A neuron needs to work very differently from a bone cell. So you have this tree in which they differentiate to form the different cell types. And this is a very small branch of that tree. And the difficulty is that this flash drive of the cell where it stores its state is what we call epigenetics. It's mostly intraorganismic. It's within the same organism. The information transfer in cells are differentiated. It's not much between organisms. This is basically something that deteriorates over time. It's one of the reasons for senescence. Our cells deteriorate, and we need to go to the next generation because of this specialization that we put into cells which makes it necessary that the cells have flash drives. And you can reformat the flash drive to make the cell completely young again. And there is one animal that does this. It's Tauritopsis. It's the only multicellular animal that we know that is does this. It's Turritopsis. It's the only multicellular animal that we know that is truly immortal. It's a hydra that is able to switch between the hydra and the jellyfish stage. And while it does this, the cells lose all differentiation. It's not an option for us because we don't want to turn back into a blastocyte and lose all differentiation while we are immortal and rejuvenate us. It would not be very helpful. So our ways of rejuvenating us is to have kids. It's a very poor substitute. So basically these cells, they are a way to adapt to environments and they actively search via evolution, or the evolution is the active search process that makes it possible for a part of physical universe to become more conformant to the conditions of the area of the physical universe that are into. Before this, the search is only in the sense that there are some regions of the universe which have that property because they have that property. And now suddenly, there are regions of the universe that have that property because there is a search method that makes it happen. This increases complexity now by itself, in a way. And as soon as this happens, you have singularities. This leads to increasing complexity. And one of the first singularities in our planet was this oxygenation event, where basically the meaning of life turned out to be the hydrogenation of carbon dioxide. Build your own structure by taking carbon dioxide from the atmosphere via photosynthetic process. To do this you need to have a controlled reactor. So this is a market opportunity for life. You can do something where you can outsmart a dump chemical reaction, an exothermic reaction, and do something where you need to add a little bit of energy to harvest more. This is basically always the market opportunity of life, controlled chemical reactions. And you can do some more smart chemical reactions on top of this. So the next singularity was that cells realized I can harvest on the neck entropy from the environment by eating other cells. They are a very good source of neck entropy. They've harvested a lot of neck entropy and stored it already in their own structure. I can take that. So let's form a pirate ship, let's form a small colony of raiders that moves around and harvests other cells. This is animals, here we are. And some of these animals decided that they would take part of this colony of the cells and deputize them with making the information processing for that thing for regulation purposes. And you have a nervous system. So how does this nervous system work? It basically has a lot of feedback loops that take care of the regulation. And whenever the regulation is insufficient, our brain has something that reinforces certain regulations and makes us weaker. So it's a learning system. And this learning system works by our pleasure and pain. Pleasure tells you do more of what you're currently doing, pain tells you do less of what you're currently doing, right? So this is already a very good learning paradigm but it has the drawback that it doesn't generalize very well. You want to generalize over different types of pleasures and pains and you want to predict them in the future. So once you sort your pains and pleasures you get a pains and pleasures, you get a system of needs. An organism has to fulfill a number of needs. And depending on its environment, there are also social needs and maybe cognitive needs. So our brain, unsurprisingly, does not only implement the regulation of physiological needs, but also of social needs and cognitive needs. So for instance, our embedding in a social group is part of our need regulation. And the hippocampus is a thing that is able to generalize needs to situations. So it associates needs, pleasure and pain, with situations and environment. And we need to generalize over this, and this is what the neocortex is doing. So the generalization over situations that are related to our needs, this is what the neocortex is doing. It finds out what do all health situations, which create pain and pleasure in different dimensions, have in common or not. And it does this basically, a good metaphor is a synthesizer. The neural networks are quite different from biological neurons. They basically rate a chain sum of real numbers. And they're trained with a chain rule. And while there is a superficial similarity when you skim very hard to biological neurons, the computations are very different. It's a very different paradigm. A nicer way to think about this, what the brain is doing, is a synthesizer. If you know a synthesizer, it's a bunch of almost randomly put together electrical elements. And they have the property that when you put electricity in them, they go into oscillations. And you have a few knobs in which you can change the way these oscillations work. And over time, you figure out to make these oscillations do exactly what you want to do. So they can produce, for instance, a sound, a sound exactly the one that you like. And you can use that pattern that they produce to predict patterns in your environment. So sound is a pattern generated by some kind of synthesizer in your brain that makes it possible to predict patterns from the environment, right? Sound doesn't exist out there. It's being played by a synthesizer in your brain to make sense of the data. So sound is a particular class of synthesizers. This is exactly what we call sound. And this doesn't only work for sound. You can also do this for vision. So there are synthesizers that This is exactly what we call sound. And this doesn't only work for sound. You can also do this for vision. So there are synthesizers that reproduce color and spatial frequencies. Oscillators, right? And once you've done this, once you've trained them, you find good knob settings to make them reproduce the low-level patterns that you can see. You can look for patterns inside of the patterns, which means you look for meta patterns. You link them together, and you realize that you can, for instance, organize lots of different sounds into a single sound that only differs by pitch. So now we have a meta pattern that explains more of the sound. And the same thing happens for colors and spatial frequencies. You can lump them together and you get visual precepts. And you do this and then you merge the modalities at some point. And you figure out that these visual patterns and the sound pattern can be explained by mapping them to regions in the same three dimensional space. And that you can explain the patterns in this three dimensional space by assuming that there are objects in this three dimensional space which are pretty much the same in different situations that you experience. So we realize the people that I meet here that look very similar to some of the people that I met in San Diego, for instance, these are actually the same people. And to make that inference, I need to have something like a conceptual representation and address space of these mental representations that allow me to create possible words and generalize over the things that I've seen. This is concepts, right? So in order to make that happen, we have several types of learning. These are basically function approximation mechanisms. And this is what the neocortex is doing. And it organizes itself into small circuits. And these circuits need to bind together into building blocks similar to Lego to form representations, take them apart, and in different, form different representations. And the ways they form each other, they form little maps that are organized in quartical areas and these maps talk to each other and you can imagine that these quartical areas play together like an orchestra. So it's a stream of music that are being processed there and every musician listens to the music around it and uses some of the elements to make its own music and pass it on. There's also a conductor. The conductor is not homunculus. It's just an instrument like the others. And its job is to resolve conflicts and decide what's being played tonight. If you don't have the conductor, you turn into a some number list. And you can also imagine this thing to be like an investment bank. You have lots of these units, quarterly columns, that are there to improve anticipated reward. And the anticipated reward to make models about the universe how to do this and models of your own actions in the face of that universe, this is what they're doing. And the reward is given by management but it would be a motivational system. So you now have a system that organizes itself. It organizes itself into more and more hierarchies. It's an AI. It's an AI built by an organism in order to make sense of its relationship to the universe via learning. And it figures out that the best model that it can come up with is it lives in a three-dimensional world. So it produces a generator that produces a three-dimensional world and renders it in your mind by a hierarchy of synthesizers. And it realizes the whole game that I'm playing is about a person. And the brain is not a person. The brain cannot feel anything. Neurons cannot feel anything. It's a physical system. But for the brain, it would be very useful to know what it would be like to feel something. So what the brain is doing, it creates a simulacrum of a person, a story about a person that is playing out in that thing. This person is an NPC, a non-player character. It's a character that is being directed by the result of what all the brain is doing, by the regulation that it has computed. But it's being used to tell the story. And then this story, the story of a person, gets access to the language center and says, oh my god, everything feels so much. And the sky is so blue. And this cannot be explained physically. Of course it cannot. Physical system cannot be conscious. Only a simulation can. Christoph Koch has got it backwards. He says that simulation cannot be conscious. No, consciousness is a simulated property of a simulacrum. OK, now it would be interesting to go above this, because it doesn't stop there. There is a certain way in which people link together that produces intelligent agents. For instance, a corporation or a tribe or a state is an intelligent agent. It has agency. It has a memory. It has goals, and so on. It's not sentient. So far, it's not sentient. But it embodies information processing principles, because we live still in multilevel selection, which means groups that cooperate tend to win over groups that don't, if these groups have an aligned interest. And the difficulty is how to align this interest. Humanity has found a very interesting solution. The first solution is reputation. So when you keep track of who did what, then nobody plays a very short game. You can do something about this. So everybody knows each other, they all play a long game, the reputation system is going to work. It doesn't work when you have a short game, which means you don't see people again that you interact with, or when you have too many people, because then it's difficult to keep track of who did what. So reputation systems don't scale. The ancestral tribes are very small. Like after 150 households, it breaks down. So the solution that our species have found means that we became less smart and gave up agency over our beliefs, and we became programmable. This programmability means that we are able to believe things without a good reason. You can be manipulated, hypnotized into adopting policies and beliefs without reason, other than convergence. And this ability to converge on beliefs, even when they are irrational, makes it possible for us to move in lockstep and form arbitrary functional units. And this is how we killed the Neanderthals. We were able to eat them all because we could out-compete them. It's not romantic. We never had any doubts that the Neanderthals are conscious, too, in the same sense as the Americans didn't have doubts that the slaves were conscious when they exploited them, or people that slaughter animals worry about their consciousness. This is not the point. They just didn't care because they wanted to eat them, or they wanted them to do the work. So the reason why people are able to converge on purpose is not because these purposes are objectively good. What you feel to be good is exactly that programming. Values are the way in which individuals are programmed to move in lockstep. It's a value is a belief without a prior. It does not follow from anything. You get it usually via empathy. So a lot of people that do ethics in the eth sense that don't understand that ethics is the principle of negotiation of conflicts of interest under conditions of shared purpose, they think that ethics is about being good. How do I find being good? Well, I'm a good person. Goodness is the degree to which others are able to emulate my sense of what's good. They're objectively bad people because they clearly don't do this. And oh my god, they are in large groups. And for most of the history, most of the people were bad. That is very concerning. And we really hope that we can change the universe into a state where people are more good and good things will happen as a result of this. It's a fascinating perspective that somebody can have that. It's surprisingly common. So if you have such a need for norms, and many people have that, if you're not a nerd, if you're a normie, it's basically in that word, right? Most humans are like this. Most people fall into norms. They're prone to fall prey to ideologies. So you basically look for a system that's larger than you, which you can serve, that gives meaning and purpose to your life. And this set of meaning is sacred. It's purposes above your ego. And this is not a bad thing. It makes our civilization possible. It's the precondition for love. You can only love people when you share a purpose with them, when you discover the sacred in them, the set of meanings that you cannot violate on pains of your life becoming meaningless. If you see that somebody is serving something that is sacred to you, you love them. This attraction is negotiable. Love is not negotiable. It's that you serve a similar system of meanings. This makes it possible. This is the inside perspective of me as a homo sapiens, a programmable primate that is able to cooperate with others. So I do have this, of course. If I wouldn't have this, I would be completely free of this. I would be a sociopath. It turns out that the sociopaths that run our economy probably do this not because they're evil people, and our economy is run by a conspiracy of evil people, but because their models are more truthful. Because the norms that have me in their grip, that make me think that there is meaning in loving other people and obeying a certain sacredness and I'm not willing to give them up because I subjectively feel that the universe would become empty and there's nobody to talk to anymore and to relate to and to laugh and be loved. These people have still more truthful things because their model of the world, that meaning, actually doesn't physically exist. The physical system cannot have meaning. There is no why to anything. If you have a more truthful system, your regulation will usually be better. So there's an interesting question. Can we build a machine that is completely truthful, a global modeling optimum? You can still give the system values and can tell it this is the preferred outcome. I mean, we live in physics. Nothing makes sense. Just things happen. But maybe you want to have some universe states prefer them over others, and you give this as a task to the system. Would be nice to have. So the first order AI was classical AI, and it's worked by trying to find a problem that is interesting enough that requires human intelligence and write an algorithm that can solve this, like playing chess or parsing natural language. And this is what people did until eight years ago. And what people do now mostly is that they write programs that learn this automatically, that find this function themselves. This is what deep learning is about. It's compositional functional approximation. It's just write a program that finds the program that does what you want. So instead of writing a program that plays chess, we write a program that learns to play chess. And it's so far not general. We don't know how to do this in a general case. But we can write a program that is to play chess. And it's so far not general. We don't know how to do this in a general case. But we can write a program that is very good at learning chess. And the next phase will probably be meta-learning. It will be learning how to learn. It's very tempting to think of our brain not as a learning system, but as a meta-learning system. Our brain is able to figure out how to learn a new thing. In an evolutionary sense, it's a very slow and unprincipled search for meta-learning systems. Almost didn't happen. Half a billion years left until the atmosphere is gone. It's not much. Took 1 and 1 half billion years to get where we are. And we needed a few meteors and super volcanoes to get evolution out of defective local optima, where some braindead lizard would eat all the intellectual upstarts before they could have long childhoods and generalize into two incomplete languages. So this is a very disturbing thought. It almost didn't happen. We are the first species that is going to leave more phones than bones in the ground. This has never happened on this planet. We are also probably the last one that is able to burn a lot of coal in a short time to give us this amazing amount of plumbing that we have. It's also the thing that's going to be the reason for why we could say now we have had a really good run and we are pretty much done. This is probably the last level of humanity. It's the most awesome one. We have all this amazing plumbing now. And we can do all these amazing things before it's over. And it's probably necessary to have a species that has this amazing amount of plumbing, like the internet. How cool is that? You have basically uncensored infrastructure in which you can talk about everything and have access to all of human knowledge. This is amazing, right? And it was only designed as a sub-feature of a giant porn repository, basically, right? That was introduced to everybody as a part of their normal household plumbing. Almost nobody uses Wikipedia to think, right think in these chat rooms to do philosophy and science and mathematics. But we can do this now. It's really good. So to me, it's more tempting, can we maybe leave a few messages to the next species that is going to get there after? I mean, we are obviously Gaia's solution to prevent the next ice age. And that's set the stage for a post-mammalian evolution. It's so exciting to think what comes after us. So it could be a general theory of search if the meta-learning is not enough. Is there a global optimum in the space of modeling functions? And this is maybe the civilization intellect. And it now seems that this thing, this machine to find truth and make sense of what truth is, is in itself a machine that can be physically implemented. It's an AI. It's a physical system that is able to find truth in optimal ways, as much as it can be done in a mathematical or physical universe. And to build this AI, I think, is one of the most interesting projects that they can aspire to before it's over, before the curtain falls. We already know when we are born, we will die. Evolution will always get you. We live in this reversible universe, which means entropy will always win out. This is a given. We always know that life is going to be a temporary phenomenon. It only exists for a brief period in a universe that is mostly dark. We have this brief flash of a mind on where the universe can be reflected. And I think we have a chance to go all the way to make a thing that finds the nature of our universe and our existence, build this model. So to me, one of the most exciting projects that we can have in the best time to be alive. that we can have in the best time to be alive. See, you are an optimist. All right. I try not to have emotions about that. It's hard, isn't it? All right. So do we have some questions for this fascinating talk? What level of emulation are you guys in right now? So do we have some questions for this fascinating talk? What level of emulation are you guys in right now? All right. So yes, okay. I just have to ask. But I just want to know just because I can't help myself. What happens when the wave function collapses? So there's no problem. I'm not a physicist, so I'm not entitled to have opinions about this. So everything I say needs to be bracketed. And the fact this is completely meaningless, because it comes from a non-physicist, I'm not anointed to the cult. And the only thing I did was to read a bunch of physics books and try to make sense of them from my very limited perspective, and I don't know whether anything of what I say has a good chance to be true. But it seems that the implication of the Schrodinger cat, when you think about this for a moment, becomes visible, and you put yourself into the shoes of the cat. You sit in this physic proof box. The airlock closes, and you go into superposition with respect to the other universe. It's not like there's a majority universe that knows what's going on, and your cat is in a minority universe. This universe of the cat is actually pretty large. It has an enormous amount of particles. So your Schrodinger box is not just basically insulating the cat from the universe. What it's doing is it bifurcates the universe into two universes, right, that are no longer entangled. And what happens is that these universes get de-correlated in a certain way with respect to their actualization, which means when we understand this, we are all Schrodinger cats. We blink in and out of existence, but we usually don't notice this because you blink in and out of existence at the same phase. We probably don't exist all the time. We exist in certain amounts of the slices of the evolution of the universe. So this universe is a cell automaton. We don't exist in every moment because the waves are not always sufficiently high. Imagine you look at a wave pattern on your pool. You see these waves moving around there. And some of these waves might be interacting with each other when they have the same phase. And otherwise, they just go through each other. And the wave itself is not always there when you squint. You see that sometimes it's at the surface. So this pattern is only visible in certain parts of the evolution of the universe. And measurement is the way in which parts of the evolution of the universe. And measurement is the way in which we face lock this, where we interact with each other to actualize parts of the universe with respect to us. So in a way, the phase space is probably implemented from my perspective. This is a possible interpretation of what goes on. But we don't exist all the time. And then we try to figure out where we are by measuring. So this reduction of uncertainty is a reduction of uncertainty of where we are in the phase space, which completely exists. This is one way of looking at it. There's another perspective that is, of course, space doesn't exist. Bell's inequality implies that space cannot be real. If you push something here and something wiggles over there, there is no space, right? We know that. We have understood this in the 1960s. So this means that the universe is not a big Excel table where you have space rows and time columns, but everything is a value in that table. But rather in the table, there are pointers, right? There is the same value implements this and this. And so a way of looking at this is the universe is a graph. It's a set of locations that can hold information that we can tell apart, and trajectories along which this information can travel. So this is what we mean by space-time. It's the set of locations that can hold information from our perspective, plus the trajectories that the information can take. And a good approximation of what seems to be going on, it's a lattice. So light can move in a lattice, and we can tell where the information can take. And a good approximation of what seems to be going on, it's a lattice. So light can move in a lattice, and we can tell where the information comes from. Information that we cannot tell where it comes from is just random noise, because we cannot find a relationship to other information. There's a lot of apparent random noise. And this is what we call non-local links, right? In the graph, if you have a lattice, you add links to the lattice, you will have additional links that cannot fit a glider to go through. The glider always needs a number of adjacent pixels, so it can carry information about where it came from. So what you will see with a non-local link is only a single blip, a shared property between two locations that an arbitrary position in the universe, so having information about that blip happening doesn't help you to predict anything else. You cannot correlate this to anything else, except when you know that this link exists. And this is this particular link. But you need to establish this via a classical connection, which means there needs to be another back channel that tells you this is actually this link. This means that you cannot really send information via this link. So the other thing is when you don't have enough links in your lattice, what happens now? We know it's not a graph, it's a lattice. And the dimensionality of the space is given by the number of links in the lattice that you have regularly. If you don't have enough links, you cannot triangulate something in space. Imagine you have an electron that doesn't have enough links to entangle it with anything but the nucleus of an atom. What is its position in space now? If you try to project this, it's a sphere. If you think that you live in a three-dimensional space and you want to figure out where is that electron in three-dimensional space, it's going to be in a sphere. And if it's in more than one link, like a chain of entanglements, it's going to be something like a spheroid. And if you have multiple electrons that interact with each other and with the nucleus but nothing else, you get orbitals. But these are probabilities of where you would observe them if you were in a free space, which you are not. You are computing indices that the universe is not computing. So the collapse of the waveform in this perspective means that the universe is getting to a point where the electron creates additional entanglements, usually stops being an electron in the process, and gives rise to a local interaction that can be mapped to a position in three-dimensional space now. So it's not that there is a surplus of information in your Hilbert space, and the surplus of information suddenly vanishes into a multiverse, but it's a deficit of information. You don't have enough information to triangulate this into a free space. And this is one of the defects of using classical mathematics for physics instead of computational mathematics. In classical mathematics, something has a value even if nobody had time to compute it. So the position of a particle in classical mathematics is always defined, which is very bad, because if it's actually not defined, you have a problem, right? If the position of the particle is not a number but a function that the universe hasn't computed yet, you can only describe it with a probability. So the collapse of the waveform might be an artifact of using the wrong mathematics. Okay. So I have a question, which I'm not sure I'm going to be able to formulate properly, and it's going to be in terms of shoulds. And I know shoulds don't really exist. Or whys. They exist from the perspective of an individual that's governed by a reward function. I get that. So my question is, why does it seem like the number of programs that are instantiated is increasing and programs like to instantiate more programs? Why does complexity increase? Yes. So the reason is, I think, evolution. Evolution is a search process that can create complexity to out-compete existing systems and sucking out entropy. But you are the set of principles that has out-competed all other systems and sucking entropy from your volume of space. So you can stabilize your structure. And it's a competition. Technically, humans are yeast. All the complexity that we make building thought theories is so we can erect some surfaces on which we out-compete other yeast. The meaning of life is to eat. From a perspective of somebody like me, who has a mutation in their mind, so I think conscious states aren't physically important, life is disgusting, right? Life is just yeast. Life is fabulous. OK, so I think we're are intrinsically important. Life is disgusting, right? Life is just yeast. Life is fabulous. OK, so I think we're going to segue. I think you're romanticizing it. Of course I am. It's part of my objective function.", '29.223822116851807')