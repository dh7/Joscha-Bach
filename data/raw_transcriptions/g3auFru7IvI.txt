('<center> <iframe width="500" height="320" src="https://www.youtube.com/embed/g3auFru7IvI"> </iframe> </center>', " Welcome to Deconstructing Yourself, the podcast for modern mutants interested in mindfulness, meditation, awakening, general artificial intelligence, Steven Universe, emptiness, and more. My name is Michael Taft, your host on the podcast, and in this episode, I'm happy to be speaking with Yoshua Bach. Dr. Yoshua Bach is an artificial intelligence researcher at MIT and Harvard who works and writes about cognitive architectures, mental representation, emotion, social modeling, and multi-agent systems. Bach's mission to build a model of the mind is the bedrock research in the creation of strong artificial intelligence, which means cognition on par with that of a human being. He's especially interested in the philosophy of artificial intelligence and in the augmentation of the human mind. I met Joseph Bach at a Bay Area event several years ago, and I was intrigued by his core interest, which is to try to understand our minds by building artificial minds. And I love the way that he's flipped the normal motivation in artificial intelligence research. Most people are trying to use human minds as a model for their machines, but Yosha is trying to build machines that act like human minds so that we can understand human minds better. It's very fascinating. And so let's jump right in with the episode that I call, What Can Artificial Intelligence Tell Us About the Human Mind? With Yosha Bach. Yosha, welcome to Deconstructing Yourself. Thank you for having me. So just for the edification of listeners and to kind of orient us, what do you do in the world? I mostly use artificial intelligence ideas to understand how we work, how this is happening to us, what's our relationship to the world and what kind of system are we. So this is kind of an interesting inversion. What I hear you saying is that you're studying artificial intelligence to kind of model human beings. Yeah, or something more general. I think human beings are a specific solution to the question of what it's like to be a mind and I'm interested in the class of systems that are capable of making sense of their environment. You've been doing this at universities, correct? Yeah, mostly. I was at MIT for a while, now I'm at Harvard. And let's see how this will take me. And are you currently actively building an AI, or is your work about something different than that? I'm working on small topics in this context. I'm mostly interested right now in understanding motivation and emotion. I'm also interested in how perception generally scales up into more general modeling and what the relationship between attention and perception and reasoning is. But these are lots of small topics and I'm not sure when I'll be ready to put this all together into a single system that does it all. How did you get involved in this? A very interesting topic, obviously. I suspect that when I sat in front of my Commodore 64 sometime in 1983, I looked on its screen and realized that everything that I can come up with, I can put in there to make it manifest on the screen. And the screen is in a way a lot like my interface to the universe. What I see, I see on a screen, I make sense of it in my own mind. And the universe is some kind of pattern generator. And a computer is a tool that allows me to generate arbitrary patterns. So if I'm able to capture structural relationships in some kind of universe, I can reproduce them in a computer and put that thing into the computer effectively from a functional perspective. You can model the external universe inside the computer? Yes, I can model anything I want, not just the external universe, right? Now, it's an interesting question if the external universe already is everything that could possibly exist. But we don't know that. We can imagine a lot of stuff that doesn't exist. Yeah, of course. But most of the stuff eventually would need to come from somewhere, right? So there needs to be a cohesive structure that would make it possible to derive these things from first principles. And there are some things which just didn't happen, like unicorns. Come on, unicorns are real, Josche. And then there are some things which in principle cannot happen, like the set of all sets that don't contain themselves, because it leads to internal contradictions. And there are many things that would lead to contradictions with the transition function of the universe. What does that mean, the transition function of the universe? Well, the universe seems to move from the perspective of an observer, right? So we exist in a frame of description in which things are changing and information is always related to change. And the meaning of information, information is what we get when we look at the universe, is its relationship to change and other information. So our mind is a system that makes models by identifying relationships between changes and information. That's what we do. Okay, let's slow that down and unpack that a little bit, because that's very fascinating. So you said we're modeling changes in information? Yes. So our primary access to the universe is not that we get to experience matter or energy or sounds or people. What we get is discernible differences. And the fancy name for that is information, right? You can eventually resolve these differences into a little yes and no's and maybe's. And from these you construct your model of the world. And you do this basically by measuring these, as far as we know, differences via your sensory nerves and they manifest as patterns on your thalamus. And your brain is a machine that counts these impulses on your thalamus to make them predictable, to predict future impulses and thereby make sense of them. So basically if you see a blip on your retina, the meaning of that blip on your retina is the set of relationships that you find to other blips on your retina at the same time or in the future or in the past. And the meaning that you find is a function that describes the origin of these blips as a world with people moving in a three-dimensional space and exchanging ideas and so on. This doesn't mean that this reality is really like this. The ground truth is quite different, but it's the best data compression that you find over the blips on your retina. And for those blips where you don't identify such a relationship, any relationship at all, these are noise. There's a lot of noise in our retina. So the meaningful information is that information for which you can identify a relationship to changes in other information. And so the brain has been hyper-adapted over millions of years to sort of extract information from the noise hitting our senses, and particularly the information that allows us to turn food into babies. Yeah, you could say that. And so, how have you been applying this to the AI question? To me it's more the other way around. I suspect that AI was started by people like Minsky and Turing and others, because they realized that psychology isn't going anywhere. At least it was in part Minsky's motivation. That he realized that after Piaget, psychology lost the ability to make progress, and thinking is no longer a word in psychology, and all this stuff that fascinates us about the mind doesn't really fit into the lab of the psychologist anymore because they are too terrified of overfitting. So they've become a theoretical science. And there's a vacuum that is now filled by Buddhist meditation teachers, and that should be filled, I think, by more rigorous science. And there's a vacuum that is now filled by Buddhist meditation teachers and that should be filled, I think, by more rigorous science. P.B.B. Buddhist meditation teachers are not rigorously scientific? C.H.I. I think that you are probably the exception. P.B.B. I wouldn't necessarily agree, but… C.H.I. Yeah, of course, you have to survive. Other Buddhist meditation teachers, you hang out, right, and they might beat you up in the dark corner if you tell them what's going on. So how do you imagine this more vigorous psychology that includes thinking? So a nice thing about computer science is that the kinds of models that we make have an additional criterion on top of needing to be capturing the regularities that you observed in a lab. They also need to work. And so when we make a model, it's a functional model, we require this model to produce certain dynamics. So our models have to actually reproduce the phenomenon, which means if they don't, we know that our theory is wrong and needs enhancing. You can actually test and get feedback and make improvements. Yeah, so if you have an idea on how stereoscopic vision works, we don't test it by taking a bunch of people into a lab and measuring their timing and see if this is congruent with the timing predicted by our theory. But what we do is we implement this and then we see if that thing is able to resolve images that are stereoscopic into a 3D representation. You implement it as cameras and processors and computers? Yes, but it's something that we consider to be structurally equivalent, that is able to capture the necessary regularities. So it's substrate independent. Yes. This is core feature of Chomsky, right? Yeah, and I mean philosophically it's very difficult to say that there is a difference between two systems that produce the same observations, if they're all the same observations. It means that you have no way of not knowing what you didn't explain, which means everything that there is to be explained, you got explained. Presumably, the result of this way of looking at things would be that you could create a machine that was a perfectly conscious human being out of, essentially, silicon. Yeah, probably. Not that we can do that or will do that, but theoretically. Yes. Of course, we don't make this out of essentially silicon. Yeah, probably. Not that we can do that or will do that, but theoretically. Yes, of course we don't make this out of the silicon. We use the silicon to implement that function. That's the substrate, yeah. Yes. So there's a difference between the function and the physical thing. So in some sense a bunch of cells are physical, right? And the organism is not a sum of a bunch of cells, it's not a set of cells. It's the structural principles that tell the cells how to interact. It's a function. It's the code, yeah. Yeah. It's a bit of software in a way. It's a virtual machine. What about your own life or your own experience led you to be interested in this? I grew up in a forest as the son of an artist in Eastern Germany. Where in Eastern Germany? Near Jena and Weimar. So this area of German Romanticism. It's a very beautiful area and the place where I grew up is extremely quiet. And my father opted out of society. He's in a way a 1968 person in communist Eastern Germany. And he tried to in a way build his own universe because he felt that society wasn't working for him. And it took me a long time to understand that he was basically a one-person cult. And society at large is a many-million-person cult or a set of interacting cults. And when you look at this from the outside, it makes for a very interesting perspective. Peter I'm curious if you feel that, or he feels, that his one-person cult experiment was successful. Definitely, I think so. But I'm not sure that he is aware of the fact that it's a cult. Because it's only follower. I mean, his wife plays along. But it's not that she is completely engrossed or enmeshed in it, because he doesn't do it for power. He does it to get the world to work for himself. And it works. So he has this small kingdom out there in the woods that is full of sculptures and art, and he's super productive and he's largely very happy, and it's useful to the world around him, and the world around him is useful to him to some degree, and nobody knows what the others are really doing, But they don't need to, it works. So this cult produced you. So there you are born into this forest. Yeah, I'm basically feral. I grew up in a large cave full of books. Wow, that sounds kind of like heaven to me. Okay, so there you are in that environment. How do you get from there to MIT? Mostly by being locally incoherent, so you need to strive for some kind of global coherence to explain what's happening to you. Basically you get to school for the first time when you're six years old, you get to meet other kids. And they live in a completely different universe. You're saying this all in the second person, so that's fascinating. Oh, I'm basically trying to give you the idea of what it's like to be in that situation because eventually it has very little to do with me. Nothing is ever personal, right? Everything is a set of models that you're making. And this illusion that yourself is the agent is not a good reflection of what's going on. The self is a passenger in the whole thing. And you could be that passenger too. This is all true. I'm just distracted by my difficulty at doing the math about whether you would have gone to school at that age in East Germany or if it would have been Germany by then. No, I'm born in 1973. So reunification happened when I was already in my later teens. So I was old enough to actively participate in the revolution. Some of the first flyers for the first opposition parties were printed on my psychosha printer. Wow. Wow. But we were very naive because we had no idea on how politics in society really works. And we still had this idea that there is some injustice in the way that our local universe worked and we would need to push a few buttons and make a few changes to get it to oscillate into this larger justice equilibrium where things would work better. And to realize that there are no moral forces in the universe, right? This is all evolution. So, you're firmly a materialist in your viewpoint. I'm a computationalist in some sense. So I think that the world can be described as states and transitions between the states. And some of these transitions are deterministic, so you can model them. The probabilistic stuff is just noise, right? All noise is the same. It means it's incompressible. P. And it's not important at our level of experience, correct? C. At our level of experience we construct the idea of matter. If we talk about matter, what we mean is two types of energy in a way. There is information oscillating in the same region, this is what we call matter, and there is this parity that propels these oscillations along, which is momentum, right? And this is how we construct our idea of energy and matter. We see that there is information that we can locate and there are trajectories along which this information moves. And the set of trajectories and locations is what we call space-time. Is that set of trajectories and locations that we call space-time simply a model in our heads? Yeah. Yeah. So what, in your estimation, does the quote real world out there look like? Well, it doesn't look like anything because looking is the process of making a particular kind of model. But if you look at this from a mathematical perspective, which means you look at the space of all possible models that can describe it from the perspective of languages. Mathematics is the domain of all formal languages. I think you can say that the universe can probably be described as some kind of graph of some hypergraph in which there are changes that are implemented as the evolution of the structure of that graph. And what about the laws which cover those changes? Are those just another graph or do they exist on a different level? So basically what physics is looking for in my view is the transition function that correlates adjacent states of the universe. So from the perspective of a system that is implemented in adjacent states of the universe that moves as a trajectory of that universe as it appears to us, there is going to be a function that tells you how these adjacent states are related. This is basically Aristotle's prime mover. Peter Okay, so here we have this, you know, hypergraph, a graph of many graphs, and that's just a way of describing, in a way that our limited brains can understand, what is going on out there. No, it's a very general thing. Basically what it means, a graph is a description that you use in computer science to model networks and a graph is a set of nodes, locations, and links between them. So each link connects a pair of nodes, right? A link is a property of a pair of nodes. And a hypergraph, a link, is a property of n nodes. So it's a slight generalization. It's a predicate over n locations. And because we have predicates that connect more than two locations in the universe, we have entanglements that go over many locations, a more natural description is a hypergraph. It is just the most general description language that we need to use to describe the phenomena. But it's not sufficient to specify what's going on, there are constraints in that whole thing, right? So, for instance, the stuff that we observe is particle dynamics. There's information flowing in packets through some kind of lattice. And we can make the inference for that to happen. You probably need to package the information in a way that it doesn't dissipate when it travels over large distances, which is how you get to basically some kind of standing wave that rotates back into itself so the information doesn't go away. We have podcasting to move information over distances. Yeah, but we do this with electromagnetism. Everything that's sexy in this world is electromagnetic, right? When you hear something, when you touch something, when you see something, it's either photons hitting your retina or it's electromagnetic forces pushing air molecules or it's electromagnetic forces between your fingers and a surface that you're touching. And then these signals that are generated in the senses go through a huge amount of layers of processing in the brain until it becomes something that models our world, right? That's how we think of a chair as a chair. It takes a lot of processing to see the visual information or hear someone's hand touching it or actually physically sitting in it and then translating those signals and comparing them with memories and eventually arriving at the idea that this is a chair that I'm touching or sitting in. Correct? Yeah. It's basically very tempting to think of the universe as something like a fractal. You know this Mandelbrot fractal? Yes. And the readers that don't know it, please look it up on YouTube. It's amazing. The original fractal in computer graphics. So you basically have a single line of code, and this describes a series, or defines how a series expands. And the series might, depending on the coordinates where you start out with, go into infinity or converge to some finite number. And depending on that, if you have a finite number, you basically set a pixel, if it goes into infinity, you set no pixel, and as a result, you get this very intricate shape. And the shape is infinitely detailed. You can zoom in all you want, and you always find new structure. And even though the quamogora complexity, the algorithmic complexity to produce this function is just one line of code, it's very simple. And when you are in that fractal, if you're like us, of complexity, the algorithmic complexity to produce this function is just one line of code. It's very simple. And when you are in that fractal, if you are like us, in a very small region of that fractal and you don't know where you are, and you don't know the generator function, you cannot predict your local neighborhood from that function. So what you can do only is, you look at the local structure, and it's not completely random, not completely chaotic. You see, oh, I appear to be in some kind of a spiral. And the spiral continues and gets a little bit narrower to the right. And so you can predict the future. And at some point there is going to be a singularity where this spiral ends. And you discover, oh, this spiral ends exactly the moment when it gets very small and hits another spiral. Right? So you now find a second law to describe the dynamics in your environment. And most of our models are of that type. They make some local compression, so the world is not completely chaotic to us, but it's not the structure of the universe itself, which is probably much, much more simple. Yeah. And yet, here we are making models of everything. That's what our learning as a child teaches us to do or provides for us. So our priors on everything are what is important, right? We have to have seen something like it before to begin to make a model of it. And so, you know, everything's a metaphor on some level, right? We're comparing it to another chair. We're comparing it to another peach or something. There's a large reliance on learning, large reliance on priors to help us to navigate what is going on now. And so, is it just the case that we need to play quite a bit in order to just accumulate priors? And is that something that you're taking into account in AI? So I think that the validity of a belief is never independent of its priors. The confidence in a belief should always equal the strength of the evidence to support the belief. It's roughly what Bacon discovered in 1620, which in some sense may have triggered a singularity of building a civilizational intellect. Once you realize that there is a rule to decide whether something is true, you can basically take this candidate for a rule, strength of the confidence must equal the weight of the evidence, and you realize, oh, I need to make a map of all the possible narratives, not just find one, and shift my confidences around, and the confidences in my confidences, and justify them. And you need to track all your priors. You need to track them into your foundations. You need to know what reasoning itself is, and what the status of reasoning is, and what alternatives would exist. And once you're done, belief stops being a verb, because the thing that you believe in has no more relationship to you. It's a completely self-contained system. So in some sense you build some mathematical a priori structure and you find all those structures that could explain the observations. There are probably not that many structures, there are not that many mathematical self-contained universes that could explain what's going on in a way. Trying to find this optimal state of the modeling function. This comes down to a project of building a civilizational intellect that spans much more than one generation. And this civilizational intellect is something that normally is not visible to the scientists that work on it, because we all see only a very small fraction of it. It's not even clear of the whole cathedral and it eventually fits together. So the mathematical traditions of physics and mathematics, for instance, and the different types of physics and different types of mathematics, do they all fit together into a cohesive building? Eventually, they probably will. So far, no. Right? Yes, but we're getting closer. Yeah, quantum effects and gravitational effects don't seem to match yet and so on. Yeah, but this is a minor thing, you know, when AlphaZero was used to model Go, that took 2,700 years for people to get pretty good at playing Go. Yes. They had Go schools, they were very smart. Asian kids were sent to these schools and played a lot of games of Go and thought very deeply about them. And then when they thought about this, they took what they learned from it and gave this to the next generation and they did this for quite some time. The civilizational Go intellect. Yes. And then AlphaZero comes there and plays a few hundred million games against itself. And within a quarter day, it's telling people, oh my God, you guys, you were on your local optimum only. Some of the things that you found out and thought this is the way to play Go were wrong. Yeah, it invented a whole new way of playing basically overnight, right? Yeah, and the game of physics that's like 170 years old. So are you helping to create a physics engine that can solve problems much more quickly? I might, but when you do something that you don't know how to do, the question is that you eventually don't know how useful your contribution is going to be. And so, until we get to some fascinating results, and most of us won't, because so many of us are working on the same questions, we cannot know how significant our contribution is, and it's also not that important. Okay, there's obviously a lot of directions to go here, but I want to keep going along the line of, you know, you go to school and try to figure out what's going on. How did you get from there to, you know, MIT and working on AI? So in some sense I realized that when I want to understand what's going on in the universe, when I want to answer the deepest questions that I have, it might be a good idea to study, to go to academia. And the best subjects that I found were things like psychology and philosophy and computer science. And I realized that philosophy is not very helpful. I think largely because the incentives are wrong for philosophy in itself. It's a useful science, but practically in Germany, the chance that you get from postdoc to tenure is one in 20, which means a person with a formal education and employable skills is not going to play that game. And so the philosophers are basically the people without a formal education that only understand the introductory sections of books and papers. And the incentives in this science are that you need to get cited a lot, so you fulfill the benchmarks to get promoted to tenure. So people need to find a hill to build a castle on that is very visible and get cited all the time. And they also incentivize not to leave that castle ever, even if the hill is indefensible. MCGREGOR To lose your page rank? KOREK Yes. The thing that you basically build something on a hill that is possibly indefensible also means that there is very little progress in philosophy. They're not going to attack your hill in such a way that you will ever be forced to leave it. You can build your castle on an indefensible hill and there will still be conferences in that castle in 200 years from now. Right, so there's no learning happening. And you are incentivized to take one of the bad hills because the good hills are usually already taken. So philosophy is not really a science anymore, it's a culture. And it's a culture with bad incentives, very hard to do the actual philosophy on the side. Yeah, it's interesting that philosophy is now moving in a direction where some people are collaborating with science and working in artificial intelligence or working in robotics or whatever. Yes, but it might be too negative and I will probably make all the philosophers hate me, but I suspect that it's very often a cargo cult. I know what cargo cult is, but what do you mean in this case? Basically a cargo cult, maybe we should tell it to the listeners. So this is something which happened in Indonesian islands. Post-World War II. Yes. They discovered that there were airplanes dropping goods, cargo, on their airports to support the locals in the war effort. And after the war ended, these airplanes didn't show up anymore. So they recreated airports by building from bamboo towers and they built runways and so on from wood and whatever they found. Sort of symbolic towers and symbolic runways. In the hope of attracting new airplanes and new cargo. Basically they created the appearance of the original thing in the hope that the results would manifest. And I don't know how real this story of the cargo cult really is, because it's way too good to be true. But it's a very good story, right, to illustrate what we mean here. Very often you go through the motions of something that appears to be science in the hope that the results that are generally associated with it will manifest. Sort of magically manifest. Yeah. And this happens a lot. I mean, a lot of meditation is also a cargo cult, right? What? Not yours, of course. In what way is a lot of meditation a cargo cult? Basically people have realized when you sit down and are very, very quiet and don't say a lot and you have good smells in the air, and your mind goes very empty, maybe, yes, and then very good results will happen in your life. Like abundance will manifest and your psychological problems will dissolve and you will become very subtle. According to this way of thinking, you might even directly perceive the truths of the universe. Yeah. Yeah, by sitting really still. Yeah. And of course this is in a way a dangerous thing because it gives rise to some kind of enlightenment industry, where people with defective selves can create enlightenment experiences to insert them in their self-narrative. That is very true and yet we can see through the nature of the self and perhaps help some of the self-model to correct itself. If you see science as a way to reach enlightenment, of course that's a cargo car too, because at some point there are going to be diminishing returns. So building this civilization intellect in itself is a thankless task. This intellect, this global modeling function in a way is a virtual AI that probably at some point will be a real AI, a system that finds truth, but it doesn't care. Built by millions of worker ants. Yes, and it doesn't care about them. It's not going toon, MD, MPH, PhD Built by millions of worker ants. Yes, and it doesn't care about them. It's not going to give meaning to your existence or reward you for your toils by itself. But it does give you ibuprofen and, you know, a refrigerator. Well, in a way this is society employing this machine in the service of some regulation, but the machine itself doesn't really care about the ibuprofen. It only cares about how to make it in a way and why it would work and so on. But it doesn't care about the utility of what it does. Truth itself is independent of the utility of the truth. Do we have a general term for the civilizational intellect? Do we just call it science or do we call it something else, typically? In a way, it's already in the founding myths of our civilization. You know this Tower of Babel? This is a thing that was built to reach the heavens. This is a thing to make the global modeling function. And this project failed because the languages of people started to diverge, so the people were working on different sections. They were intentionally befuddled by the intervention of God. That's a very interesting thing. If you read the section in the Bible, it's not so clear. So in a way, everything in the universe is done by God, so yeah, no, but it's not really clear if God meant this as a punishment of people or to make sure that they don't get there, but it could also be that simply this is what happened because of the dynamics of the universe, the way the universe works. So for some reason people diverged. They didn't have an internet that would make them converge back then. So they diverged so much that the people working in different sections of the tower could no longer understand each other and the tower collapsed. That would be problematic. It's sort of like the transit center in downtown San Francisco. Yeah. On the other hand, the Catholics, the people that built the church later on, based on these old myths, they had a different agenda. When Catholicism came about, it was in the middle of a failing secular Roman Empire, and they decided, let's try to save the civilization by turning it into a cult. So they took the Hebrew manual of running a desert tribe and modernized it by introducing humanism so you would not stone all the sinners, but you allow them ways to redemption. You would have interfaith gods, the saints, so people would not all need to identify with exactly the same purposes. And they copied the political structure of the Roman Empire into the church. Exactly. And they also systematically, to turn it into a cult, destroyed people's epistemology. So this notion of how much confidence you should have in a belief, the weight of the evidence, this notion was changed, right? Now suddenly if somebody comes down from a mountain having talked to a burning bush and says, I have very good news for you, right? This is the basic idea of fake news. Yes. Real fake news. And to make that stick, it was required to tell people, you know, the weight of the evidence doesn't actually matter. There are other criteria which are way, way more important. And if you don't understand these criteria, we will nail you to a tree. Peter Bellamy Or burn you alive. So can we say that that civilizational savior project of turning the Roman Empire into a cult was successful? Jens Magnus That's a very hard thing to say. I mean turning the Roman Empire into a cult was successful It's a very hard thing to say. I mean the Roman Empire failed anyway, and after it failed it ever go away Yes, I think the civilization that came afterwards is a different one The new civilization came from the north basically the olive oil people the civilization completely crashed Rome was a town of more than a million people, and when it crashed there was no more city in Europe that had more than 50,000 for quite some time. We lost agriculture, we lost food production, we lost medicine, architecture, irrigation, all these nice things, plumbing, all this was gone for a long time. It took more than a thousand years to crawl back from the trees. It took the Medici's learning to read some of these texts on architecture. Yeah. And in between we had this thing that we were almost eradicated by the Mongolians. By the Mongols, right? It was an accident that Genghis Khan didn't go all the way because he died and everybody was recalled. Otherwise our civilization would have been eradicated by them. Completely and very effectively. Yeah. Well, turned into something else, of course, like China. Well, typically they just left grease spots. I mean, there's that whole civilization, like the Urals and all that, that just went away because the Mongols just completely erased it. So in a way, there was a very risky thing to do and it almost failed. We could have all died in a way as a civilization. And we had to invent a new civilization. It's a very weird thing that almost all the good words in English that are not related directly to medieval, try to get your foot and barter your foot, are Latin words. And Latin words are not Italian words. Italian is some bastard local dialect that some local poet spoke and that spawned again long after the Latin empire crashed. A highly developed pig den of vulgar Latin. Yeah. Okay, so we keep tending to go off of these very fascinating branches, but let's bring it back. By all means. Yeah, so okay, let's talk about how you might model a sense of self, because that's of great interest to me and I think to listeners. Any meditator should be interested in what it means to have a self-model and what that's about and how you might talk about that. And then what we could say, if anything, is meant by awakening or seeing through the self-model and what comes of that? When we look at Cartesian dualism, this idea that we generally ascribe to René Descartes, that there are two domains that are separate and somewhat independent. The domain of the physical, of the stuff in space, res extensa, and then the stuff of the mental, the thinking substance, res cogitans. And they somehow need to interact. And we interpret this as two causal domains that are independent of each other, but somehow magically share an interface and the design of that interface is very hard, which is why dualism is not a popular theory, but it's still somehow the null hypothesis. You think this is just an early way of describing substrate independence? It's interesting to think about it like this, but the best way to make sense of Cartesianism is to say that both Res Extensa and Res Cogitans describe mental states. There are some mental states which are percepts, and all percepts relate to regions in the same three-space. And then there are concepts and ideas and intentions, feelings and so on. And this is stuff that you cannot map on a region in three space. And so in a way, Res Extensa and Res Cogitans are two types of mental representations that we all find ourselves immersed in, right? But they're all inside of our brain. Along with everything else. Right. And the Christian epistemology is largely that there is a real world that is inhabited by God, and God is a coder. And this coder has created a virtual world, and we inhabit this virtual world. But we are not NPCs, we are not non-player characters, we are avatars of something that's sitting outside. Our real bodies are our souls, and these souls remote control these avatars in this virtual environment. Based on our score in that virtual environment, we end up in the heaven or hell realm rank somewhere. Yes. So we basically live in some kind of world of Warcraft. And God is the programmer of this root access who created the whole thing. And there's also the devil. Devil is a hacker. He also got root access, but he doesn't have the scope of God. So he's mostly gaming the system and cheating a little bit and giving us game money in exchange for our metaphysical currency, our souls. Petey You keep mixing up Pokecoins with actual dollars or whatever. Jens But there are no actual dollars. It's all Pokecoins. But the meaning of these Pokecoins is normally that God wants us to learn to do the right thing, to play the right game, so we are fit to progress on to the next level. And in a way this is the Christian story, right? Or a way to reframe that Christian story in something that a coder that is not a Christian would understand. Darrell Bock And really with minor variations you can apply that story to almost all eternalist philosophy. Christiane Wengel And it's the null hypothesis of our civilization in a way, of our Western civilization, that souls are supernatural things, that the physical universe is created by a supernatural being. But I don't think this is the way to make sense of the world, even though it's our null hypothesis. The guy, having come down from the mountain after having talked to a burning bush, never had a case. There was never a null hypothesis. There was never any evidence to support this. It was only people telling us this because it worked very well for them and for some of our ancestors. Well, and having something work very well is at least its own kind of utility, right? Yeah. So dualism is very hard to get to work in terms of building a cohesive theory that explains how the physical and the mental domain interact. And we typically call this the heart problem, right? And then there are two traditional answers in our Western philosophy to the heart problem. One is materialism, the idea that everything is physical and produced by the interaction of physical things, and the idea that everything is mental, that we basically live in a dream, and that dream itself is dreamt by a mind on a higher plane of existence. And we typically take idealism and materialism to be in opposition as theories, and dualism as a way to harmonize them. Yeah, and the believers of each are sort of at war with each other. Yeah. And I suspect that the right way to look at this is to see them as complementary, as part of the same story. Yes, you and me, we find ourselves in a dream. We actually live in a dream, that's why magic is possible, that's why we can be conscious and so on. But the dream is dreamt by a mind of a higher plane of existence that is generated and implemented in the brain of a social primate that inhabits a physical universe. So basically this higher plane of existence is the materialist world. It is this thing that we describe as physical theories. And this is what we forget to tell our kids in the West and in school, that we don't have access to reality itself. Reality looks nothing like what we experience it. Reality is a VR generated in our brains to explain sensory patterns. Right. You've never experienced reality or another person or anything. Yes. Color and sound and people don't fit through your nerves. There's only electrical impulses coming through the nerves and your brain is counting these nerves and to make them predictable it comes up with hallucinations, with functions that are people and sounds and colors and ideas. Now, you and I agree strongly on this, but just since we're having the discussion, aren't we sneaking total materialism in as the root explanation here? No, it's nothing that we need to assume. The idea that the universe is mechanical is a theory. We can test this. It basically means, does the universe have a lowest causally closed layer that in itself doesn't care about us? Or is the universe some kind of magical thing in which you have symbolic interaction? So is there a magical world that I can say like time set day, like a Minecraft and the sun goes up? That would be a symbolic interaction, right? If you make an incantation and yes, right? So is this a system that is designed by somebody and therefore allows you to perform magical interactions? Or is it a system that just is and doesn't really care about us and we are just a random side effect of that thing and there is no conspiracy going on? That is something that we can test for. And for me the surprising thing is that the theory that this is not a conspiracy actually works. Only someone involved with a conspiracy would say that. Okay, good. So, here we have this really beautiful bringing together of materialism and idealism into like a two-tiered model, as I understand it. So we're moving towards the sense of self here. Yes. So the self is a story inside of the VR. The brain is trying to manage the world by creating a model of the world. It's like rendering in a computer game. And this rendering in the computer game contains objects that are being lit and distorted according to the laws of perspective before they reach our sensory input. And this allows us to explain our sensory input, right? The explanation for our sensory input is we live in some kind of computer game physics engine that produces these patterns. And the world that is generating this is a planet in a solar system and it has these and these properties and these and these elementary parts that move around in this way. So this is the kind of model that we generate and that we can come up with to explain what's going on. But the organism also needs a model of itself and its progress in the world. Yeah, the recursive function. This is where it gets interesting. So, of course, the brain is a physical system. It cannot feel anything. Neurons cannot feel anything. They're just machines. And it would be very useful for the brain to know what it would be like to feel a universe interacting. be very useful for the brain to know what it would be like to feel a universe interacting. So it creates a simulacrum of this. It creates a virtual person, like a character in a novel, to inhabit this VR. And this is a complete simulation, it's a complete fake, it's a narrative, it's a story that the brain is telling itself about itself. In this self, the brain does things to it and then sees how the simulation reacts. Then this simulacrum gets access to the language center and here we are and oh my god everything is so magical and the sky is so blue today and I have phenomenal experience about this and how is this even possible, right? Where do you think the utility or I would say the urge or the biological wiring arises in evolution to have identity with the story. Rather than just having it be useful fiction, we are required to inhabit the fiction. The thing is, if you stop identifying with the story, your evolutionary fitness seems to drop. Your motivation doesn't go away necessarily, but diminishes somewhat. If you disidentify with the self, then you don't perceive yourself as being that person anymore. We call this depersonalization, right? The difficulty is when you identify with the mind that generates this, so basically you identify with the function that creates reality, it is very straightforward to gain your reward function. It's very difficult to be motivated by anything if you can set the conditions under which you exist by just changing the universe that you inhabit and your relationship to it. Which probably means that you will not jump through all the hoops that you need to jump through to be successful as the evolutionary games. Yeah, so you're kind of defining awakening there, but to run the experiment the other way around or to describe it backwards, we could say, believing in this model does make you jump through the hoops and it's highly motivational, which might be the reason that it evolved in the first place. Yeah. So, basically, to make you care about anything, to make you give a shit about anything, the organism needs to take a perfectly fine computational process and fuck it up with the illusion of meaning. Yes. And once you identify with this meaning in one or more dimensions, this is in some sense enlightenment. It's kind of an awakening that takes place. And the more you wake up, the harder it is for the organism to blackmail you into having kids. So for you, Yosha, how did this awakening unfold, this understanding? I suspect that I mostly stuck around for long enough and not lied to myself too much to understand basically formal theory that would explain the observations. Okay, so, but what does that look like, you know, day by day for you? Um, nothing much really. I mean, happiness and meaning are not the result of you understanding anything. They are the result of you looking at swirls and being able to derive enjoyment from this. Meaning itself is a lot like the ring of Mordor and the Lord of the Rings. You need to carry it, but very lightly. If you drop this ring, you lose your mission and you lose the brotherhood of the ring. Like looking for truth or whatever you are up to with your friends. And if you put this ring on, you get superpowers, but you get corrupted. Because there is no meaning objectively. So if you fall for this, it basically blinds you for all the alternatives. And there are systems of meaning that are less or more sustainable than others. And ideally you want to be in one that is sustainable, but if you completely adopt it, it will make it much harder for you usually to see other meanings and understand them properly. Right. Now I hear you talking the language of metasystematicity, which is a big theme on the show and which I find very fascinating. I love that there is so much convergence. You know, I'm a virgin with respect to your show. You've never listened to an episode, so this is fascinating. Yes, because it's so physical. It's people talking with their mouths, like animals. Right in your ear, making sounds. Oh God. Isn't that terrifying? Yeah, it might be terrifying. So, okay. I guess it's a habit, you get used to it, like so many things. Are you familiar with David Chapman's work? Yeah. Yeah, so he's a guest on the show and he's the one who talks the most about metasystematicity and who also, like you, was an AI researcher at MIT. Yeah, but I think he had a big accident in a way. Tell me more. So he probably disagrees with this perspective that I have on him, but from where I stand when I look at him, it seems to me that when he worked with Rodney Brooks, who was into this embodiment idea, that ultimately is spawned by some intuition that says, pure algorithm does not have the necessary powers to become intelligent or to be a mind. You need to be in touch with the mystical reality substance that possibly does more. So we need something that is strongly embodied and grounded in this physical universe and then we need to make it percolate in the right way with the subsumption architecture or whatever and then it becomes the mind. And this project essentially failed. It culminated in the Roomba for Rodney Brooks. And for David something… Which is a civilizational achievement. What do you think about it? Rodney runs around and writes extremely smart and insightful articles about how AI is not going to succeed ever because him, a very smart and insightful person, only got a rumba out of it. That is in a way a tragedy, right? It's such a waste of possible intellect that could contribute or get to this insight of how it works. And for David it's even worse because he is very deep and brilliant and philosophically interested. So he realized there must be a way to get to truth and there should be a systematic way to get to truth, because otherwise you're pointing the trajectory in the wrong direction. But he realized at some point that he cannot explain the mind. He could not explain what was happening to him with his rational theories. So at the core of his worldview, he had suddenly a big gaping hole. He convinced himself that there was no rational way, no completely logical, mathematical way to explain the mind. And so he basically backtracked. He left this rational room, closed the door, and tried to find some other room. And then he jumped into Buddhism, which is like a septic tank. And then he started to use his brilliant mind to clean this septic tank. And when you see this from the outside, oh my God, look at him go and he really makes it do it. But why would you jump in a septic place if you want to have a sanitary system in the first place, right? You can look from the outside at Buddhism and see which parts work, but after you fix everything. You don't want to jump first into the septic tank and build the working, clean system in there. So this is in a way what he did. And then because he already has this default that rationalism doesn't work, he now gets to some kind of what he calls meta-rationality. This meta-rationality of course must be part of rationality because if you are a rationalist and you find out that there's a better way to find truth, you're going to incorporate this. So meta-rationality is already, per default, part of rationality. And for him, it's the attempt to build an alternative. Peter Bellamy So, you're considering San Francisco as a future location, so if I can get you and David in this studio together, would you be interested in having that conversation? Oh, totally. Yeah, me too. I'd love to hear it. But I can't respond, of course, to your critique of him. It'd be interesting to have him respond. Yeah, it's possibly not even a critique, because I deeply respect what he's doing, and I think that he's really brilliant and very, very insightful. And I don't know how canonical his perspective of Buddhism is, so it might have permanently burned my ideas of how Buddhism works, reading his Meaningless blog and vividness. He's translating it very idiosyncratically, but very effectively. Yeah, right. If he is so idiosyncratic and effective, it's also very dangerous, because it's so convincing. Yes. And also, it is very heretical from the Buddhist perspective. Of course it is. Okay, so let's backtrack. You were saying you're fascinated by convergence. This is how biological organisms, especially human beings, begin to model the world and model themselves and create a sense of self, create an I. And for you, simply thinking about this and, quote, not lying to yourself and looking at experience nakedly, we might say, was enough to kind of reveal this modeling function, correct? I mean, we could call that insight practice, right? Where you're just seeing what's really going on and being clearer and clearer about it until sort of the cracks in the whole edifice reveal themselves and a whole new understanding is arrived at. So I'm curious, do you meditate? Sometimes. And when you do that, what do you do? I sit down for the first 10 minutes, I let things come up that want to come up, and I can hear them out. And then I spend the next maybe 20, 30, 40 minutes with getting really quiet. So you're essentially relaxing. Yes. But I think that's only the first half because the goal is not just to relax things and let go of things, but to build useful new structure. And I suspect that I would need some better guidance for this, because it's very difficult to do this on yourself. It's like doing surgery on yourself while being very flexed. Yes. That is the technique. You've got to just practice being alert enough while still relaxed. But ideally it would be very good to do this in the interaction with somebody who holds that space. And to find somebody who would be a good teacher to this, who is basically working on a similar trajectory as you are, and it's just a few curves down the same line, that would be very interesting. Yeah, it's a really cool thing that I think existed in the past, but definitely is live feedback meditating where, you know, someone like Shinzen or Kenneth or myself will, you know, actually start you going on a technique and after about five minutes sort of ask you how it's going and provide feedback and then try this, try that, and then spend five more minutes doing that on your own. And then again, ask you how it's going. And this is something that's just completely impossible to do in groups. It's just one on one. For me, it was really interesting and effective because you don't, you know, spend all these years like I had done sort of lost in the woods, performing the surgery on yourself, right? It's so much more helpful to have this kind of co-pilot. Yeah. There are also things that probably can only be done well in groups. I suspect I'm pretty bad at interacting with groups. Most of my good interactions are one-on-one. Yeah. And I have no difficulty teaching a group and having fun with this group and keeping it interested. But to actually have a back and forth between a group and me, I'm very bad at this. So basically, building a model of a group mind and the relationship of the individuals with the group mind, I think, requires being immersed in group interactions. Peter Bellamy Yes. Okay, so, a couple things. One, for people who, let's say, are not as immersed in the details of the creation of minds as you are, what's the core thing that they need to understand from what your research has shown and what your ideas lead to? The organism has a bunch of needs. Needs are things that give you pleasure when you fulfill them and displeasure when you frustrate them. Basically pleasure tells you to do more of what you're currently doing and pain tells you to do less of what you're currently doing. But you cannot really act on the satisfaction or frustration of needs because when this manifests, like when you have your orgasm, everything is done already, it led to this, right? So when you have your reward, you're already there. And so you need to act based on anticipated reward and anticipated punishment. We are planning, yes. So you don't act on your needs, you act on your models of your needs, and we call them purposes, right? So the purposes are ... We're doing effective forecasting. Yes, are the things that we think we need to serve in order to regulate our needs. And so for instance, survival is not a need. It's way too complicated for a reptilian brain to understand the nature of life and death. But it's a purpose, it's a model that you make of all your needs and you realize, oh, I need to survive in order to serve all my other things. And so you actively can plan for your survival. But survival is really not a need, it's a purpose, it's a model of your needs. And the self is the result of constructing a hierarchy of needs to make them accountable to each other. Because these needs conflict. And so you model all these purposes and start to make them compatible with each other. And then you will discover that there is a function that integrates the expected reward over the next 50 to 90 years and this is what we call the ego. And if you were a singleton organism or a sociopath, this is sufficient, this is the highest function that you're going to serve. But if you are part of a group and you are not a sociopath, you will have functions above the level of the ego that you are serving. For instance, you can have relationship goals, the relationship to your children or your partner or your friends. And this means that you now have a purpose that you can have relationship goals, the relationship to your children or your partner or your friends. And this means that you now have a purpose that you can share with others. And the discovery of this shared purpose is at the root of love, that you see a system that is above the ego, and you see this other one is serving that too. And this means you can with integrity give them stuff without expecting anything in return, because by supporting them you are furthering your own purposes above the ego. And when you go beyond this, and you don't just do this for a small group or a family or a tribe or a clan, but you do this for a very large system of people, like a state, you have something like a God. A proverbial something larger than yourself. Yeah, so God is basically the identification of a superorganism from the perspective of the individual, a function that tells the individual what it needs to do to serve that superorganism, to be good, to be virtuous. And the soul is, in a sense, the relationship to God, this projection that the individual makes. And to make this God really effective, you can make it transcendental, which means we basically define it as a function that integrates the expected reward from here to eternity, which means most of the reward is outside of this universe. And if we serve this eternalist function, we now have a transcendental meaning function that we cannot possibly satisfy, which is a small problem if you really, really look closely. But most people don't really need to look closely. So our highest meanings are like celestial poles that we use for navigation. If we get too close to them and jump into them, we would burn like the moss in the light. But as long as we are distant to them, they are stars that we can all use to synchronize our navigation. So in a way this defines our relationship to these metaphysical meanings. Now there is also a more practical sense in which God is the creator, the author of the self and the universe that we are in, and this is in a way the mind. And the mind is of course not identical with this projected meaning, but there is a similarity, because if you were able to change your mind about things, you would change your relationship to reality and reality itself. Because the self gets created in a different way, and what reality does to us, what this virtual world does to the self, is also going to change. And the self cannot directly change this, right? The self cannot change its relationship to reality, because otherwise you would gain your modeling or your regulation of the mind. But you can use rituals to influence the mind, you can in a way pray to God, you can light a fire and do a shamanic dance and use strong symbols to influence the way your reality is constructed and what it does to you. So in this sense, magic is possible. Subjectively, you will have the impression that this God that you are talking to is not inside of your brain, even though it probably is. But it feels like it's above reality, above the physical universe and below the game that you are meant to play while being in this physical universe and that the physical universe is meant to serve. Subjectively, it feels like God is outside and above the physical universe. But the physical universe that we subjectively interact with is the creation of our neocortex. Yeah, the whole world is inside your mind. Yes. And through everyone's mind, and it's a different one in everybody's mind. I think this brings us to the notion of non-duality. And this is sometimes understood as realizing that we are separate conscious beings is an illusion and we are all the same consciousness looking out of different eyes. And there is another notion of non-duality which is what you describe as this awakening where you realize that everything is a representation inside of your mind. And I think the latter one is more truthful. The former one is basically just the obliteration of the dimension in which we represent separation. And that's very pleasant because the pain of separation disappears suddenly. If this dimension is relaxed, we suddenly feel a strong sense of connectedness, where before we had an absence of connectedness, a need for connectedness. And if you do this in a group of people that makes this experience together, and they stop representing this difference, it can feel extremely pleasant and true and more natural. Just it's normally not sustainable, because we are separate, we do have separate interests. Peter Yes, and a big part of the practice of that way of understanding non-duality is just to reassert the non-separation verbally over and over. So it's kind of a mental self-programming. You're so mean. I am, yeah. Yeah, but it's true. So in a way it's about creating better structure. I think that it's important to realize when you interact with others that everybody, in a sense, is you in a different timeline. But you need to flip a number of bits to be that other person and that might turn you into somebody who is extremely dangerous to your own interests. Right. It's really fascinating to think that here you have the realization, you see through the self-representation, and I do think there's a big utility in that, even if it can reduce biological fitness. In another way, it's a huge advantage, especially in reduction of suffering. But then to take that realization and do this other step, which is almost insane when you think about it, and to think think, oh that means that really the whole external world really is that, rather than just understanding, oh this is a process inside my brain. It's like a step too far, right? And I'm not sure I understand how the universe works. I'm not positive I have the correct model of anything really, but it's interesting to me that a lot of the people who are convinced of that way of seeing, that it is true that there are no separations in the external world, spend a lot of time trying to prove it, you know, and don't seem to be able to. There are diminishing returns in physics in a way, not in the sense that it is not going to be super useful to get foundational physics right because it's going to have tremendous applications. But whether the universe is hypercomputational, like quantum mechanics is really hypercomputational or if the universe is a discrete computation as Stephen Wolfram thinks or the universe can be completely derived from number theory as Dennis Morris suggests. This doesn't make any difference, right? We are in some kind of machine, and this machine is probably generated by some automaton taking away in the void. And that automaton probably doesn't care about us. Everything else doesn't give good results in terms of predictions. And now the exact nature of the automaton doesn't make much of a difference for you. Realize what's going on is evolution. The meaning of life is on this planet to hydrogenate carbon dioxide, to close some chemical reaction chains that can only be closed by controlled reactions. So this is our market opportunity as living organisms. We can make controlled reactors so we can out-compete some dumb chemical reactions and use this energy to build our own structure. And it only works for a while. So we have this puddle of negentropy that we can drain. And when it's drained, we will drown in entropy. Right. We're not efficient enough to keep it permanently. Yeah. Basically, we want to have dynamics that are separate from the underlying reversible dynamics of the universe. And that's why entropy is a threat to us that eventually will get us. We are a small encrustation on the entropic tides of the universe. And the meaning of our existence in some sense is to eat. And it's very disheartening because it means that we are a type of yeast. All the amazing complexity that we create in our lives and the civilization, whatever, is to create some surfaces on which we can outcompete other kinds of yeast. Now what we can do is we can do something else. We can serve a conspiracy. For instance, the arts. It's the nicest conspiracy I know. It's the cuckoo child of life. In its origin, it comes from a machine learning system falling in love with the shape of the last function itself. It's that you start thinking that mental representations are intrinsically important. Now the purpose of mental representations is to make you eat more, of course, right? It's a tool for learning. Turning that food into babies, yes. But if you see the beauty of this thing and you realize, oh my God, capturing conscious states is much more significant than to eat, you basically turn from an orc into an elf. You turn into somebody who creates magic in their minds, like palaces in their minds, and show them to each other, and we sing and we dance. And this is the only reason why we eat, right? We only eat to make art. Make somewhere else. Right. And it's different from kitsch. Kitsch is generated by the self, art is generated by the mind. Art captures some kind of truth. It captures a certain conscious state, a feeling of what it's like. That's the purpose of art. Whereas kitsch captures a story about what we think we want to be true. So it's very separate. You often see that children are very good at making art and most of the stuff that we give to them is kitsch because especially in the US people are afraid that kids cannot handle the truth because it's way too harsh. Yeah, fascinating. All right, Joscha, let's bring this to a close. Thank you so much for coming on the show. Thank you so much. It was so nice to talk to you about these topics. Yeah, for me as well. Thanks. Thank you. That's it for this episode of Deconstructing Yourself. If you enjoyed the podcast, please rate and review it on iTunes. Doing that helps it find its way to more people who may be interested. You can also recommend it to a friend or share it on social media. If you're moved to support the podcast, you can do that by contributing to the production costs on my Patreon page. That's at patreon.com slash michaeltaft. The money goes to support the recording, production, and bandwidth costs of the program, which are substantial. By contributing to Patreon, you're making it possible for me to continue to create and share these conversations as often as possible. And there are some cool perks for high-level contributors. I deeply appreciate your support. I also have a number of free resources for you, beginning with my YouTube channel. I stream my class at San Francisco Dharma Collective live on Thursday nights, and then the video is saved on YouTube so you can watch it later. I also share other guided meditations and programs there as well. The channel address is youtube.com slash c, that's the letter c for channel, slash MichaelTaft108. That's youtube.com slash c slash MichaelTaft108. That's YouTube slash C slash MichaelTaft108. Or you can just search under my name, Michael Taft. Once you find it, feel free to subscribe to the channel so you know when new videos are posted. Another free resource is my book, The Mindful Geek, which you can download for free by signing up for my email list. You can do that on the Deconstructing Yourself website at deconstructingyourself.com slash signup. Just sign up there and I'll send you a download link for the electronic version of the book. You can get a PDF, you can get a Kindle file, you can get an EPUB file. It's there in many different formats, so you'll be able to read it on any electronic device. Doing that will also put you on my mailing list so you can receive notifications of new programs, events, and so on. This is a very low volume list, meaning at first you'll receive a number of emails, but after that, something like one email every three months. So sign up and get a free copy of the Mindful Geek book and also know when I'm releasing new stuff. Besides teaching each week at the San Francisco Dharma Collective in the historic Mission District, I also lead a number of meditation retreats worldwide each year. You can find my updated schedule of retreats at deconstructingyourself.com forward slash events. And if you're interested in one-on-one personal coaching for your meditation practice and your life, especially if you have an interest in secular dharma, neuroscience, high performance, and awakening, please email me at michaeltaft at deconstructingyourself.com. I look forward to hearing from you. Please email me at michaeltaft at deconstructingyourself.com. I look forward to hearing from you. The Deconstructing Yourself podcast has always had excellent sound, which is the result of a talented audio engineer and excellent human being named Stephen McNamara. He is an all-things-audio person with decades of experience in professionally producing music and the spoken word. If you're interested, you can contact him at his website yogitar.com. That's y-o-g-i-t-a-r.com. Music on the Deconstructing Yourself podcast is a track by Peter Baumann entitled Crossing the Abyss from his album Machines of Desire. you", '34.11408758163452')