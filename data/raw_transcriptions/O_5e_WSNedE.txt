('<center> <iframe width="500" height="320" src="https://www.youtube.com/embed/O_5e_WSNedE"> </iframe> </center>', " Hey, welcome everyone. Today we have a conversation with Yoshaba and Stephen Wolfram about multi-layered systems. Welcome, Stephen. It's a pleasure to have you here. So let me just quickly introduce the speakers first. Stephen Wolfram is the creator of Mathematica, Wolf Alpha and the Wolfram Language. He's the author of A New Kind of Science and the founder and CEO of Wolfram Research. Yosha Bach is a cognitive scientist and AI researcher at Intel Labs with a focus on computational models of cognition and neurosymbolic AI, trying to figure out what comes after deep learning. So, Yosha will do an opening statement and then we will continue with the discussion. The chat is open to the learning. So Yosha will do an opening statement, and then we will continue with the discussion. The chat is open to the participants. Please feel free to ask your questions there. I believe we have James Boyd from the students team who will be helping answer some of the questions, and we might incorporate others into the discussion. Yosha, the floor is yours. Thank you, Tanya. Welcome everyone to today's discussion. I've always been fascinated by Steven's work and his perspective on physics and on computation and on the entire intellectual domain in general. I think he is a veritable one-person intellectual tradition in a way that he has very early on discovered in his intellectual career something that philosophy is struggling to discover. This is basically a paradigm change that happened in the 20th century from classical semantics and the notion of truth as it existed before to computational models. And so from my own perspective, it looked like, as Stephen has very early on in his career decided that mathematics is a code base that needs to have a new footing. And so he set out to work and write his own and turned this into his exopertix and as a tool for making sense of the world and integrating all this understanding and sharing that with the world as a platform to explore the universe in a more systematized fashion. And there's a very particular topic in Stephen's work that became recently more important and I think it has always been or for a long time been in the background, but I just stumbled on it. And there's a big issue when we think about the issue of why we are here, how life exists, how consciousness exists, and so on. And for me, the hard question is not consciousness. It does seem to be a solvable problem and not that difficult. The really difficult and jaw-dropping question is, why is there something rather than nothing? How can we overcome the steps? What is putting this machine into the void, this prime mover, how is that possible? What's able to overcome this debt? And in a way, the easiest explanation for this seems to be that maybe existence is the default. seems to be that maybe existence is the default. Maybe everything that can potentially exist does actually exist. And what exists, I think, is what can be implemented. That's a very particular perspective on existence that may be not shared by everyone, but it's one that has the benefit that I can translate it into a language, and I can only think into some kind of language. It's not necessarily English, but it's some kind of language that is able to form representations. And so when I think about epistemology and how we think and how we understand and observe the world and what the nature of an observer is, I have to think about the nature of languages itself and about semantics. And now when we apply this notion of a language in which the universe could exist, which could be comprehended, in which we can make sense of observations and translate them into models, the step that we say that everything that can potentially exist, basically means that the universe is something like the super position of all finite automata. And suddenly, we don't have to explain why something is in a particular way, but we have to explain why it's not in a particular way. Because if it's all the possible things, why is that some things do not exist, at least some of the time, and not everywhere? We basically have to explain structure by the gaps in existence. We have to think about why is it that a certain event cannot have all possible consequences, but only some? Why are there gaps in the wakes of the operators? But it's an entirely new perspective in a way. And then one of my friends alerted me to a text that Stephen put online last autumn in which he discusses the Ruliat. Basically, he calls it the entangled limit of everything, but it's basically the superposition of all automata. And this extreme is in some sense, from his perspective, or as a suggestion, we'll probably clarify this more, a possible perspective on looking at the foundational structure of the universe. And so we have to ask ourselves a number of questions. For instance, why are observers apparently classical systems? Why can we describe ourselves as Turing machines? Or is it that we cannot be? Is it that we only are simulacra of this? And instead, the actual causal structure is different. When we think of causal structure, causal structure is in the way in which it exists in our human mind, low dimensional and discrete functions that are compositional. It's algorithms. It's in a way a way to explain the state transitions of a system by a low dimensional and discrete function. And we can make a blow up the complexity of this function and then it becomes more and more intricate and beyond our comprehension. And there is this question at these levels where it eludes our comprehension just because of the sheer number of bits. Do we need to make the switch from the deterministic Turing machine to the indeterministic Turing machine? I got familiarized with the indetermterministic Turing machine as a student in computer science, and there it was introduced as an arcane concept to compute the complexity of algorithms that can basically not be implemented. And it turns out that the inter-terministic Turing machine, the one that is not just going from state to state, but is going from a state to all possible states, it can reach the same states. But the description of this machine is a different one. So the resulting complexity of the programs of the automata definitions for a non-deterministic Turing machine is different than it is for the deterministic one. And if you take this idea seriously, this of the non-deterministic Turing machine and use it as a vehicle to describe theories. It could be a new paradigm in the way in which we think about things. Stephen has written a very insightful, interesting article about this at some point, where he describes the ideas of antiquity and the theories of antiquity as static structures in which we reason about static situations. And then the mathematicians of the 16th century discovered differential equations and ways to describe the universe as a moving continuum in which geometry plays out over time and changes in this geometry. And what we saw in the last century was the switch to the computational revolution in which we described the world as state machines that can be implemented as computational models. And much of this revolution was lost on philosophy when Goethe discovered that the notion of truth that existed in classical mathematics leads us into contradictions. And we don't have a difficulty when we make mathematics stateful, but the old notion of stateless and continuous mathematics has changed in a way. And the physicists had checked out this code base for mathematics before the updates that happened in the last century towards constructive mathematics. And for the most part, it doesn't matter if your geometry and high-level abstract models of Newtonian mechanics are not strictly computable and you can only approximate them. But when you think about the foundation of the universe, the foundation of the universe cannot be approximated, it must be in a particular way. So in which way is it? And maybe we now get a paradigm with which we can get there closer. can get there closer. So when Stephen writes in this thing that this century is about to see this new revolution that we describe the world using multiphase systems, we can apply this to not only physics but also to biology and economy and maybe the social sciences at some point. It's also interesting to me, can this be applied to the mind? Is it possible to describe our mind as a system that is not just going from state to state, but intermittently to all possible states before the branches close each other in more narrow state sequences. So these are some of the thoughts that I would like to explain or to explore us today. Cool. That's a very interesting path through a collection of ideas. Where should we start? We can start on perhaps on talking about, well, gosh, I think one feature of consciousness as we tend to experience it, is that we believe we are persistent in time, and we believe that we follow a single thread of experience. And that's a very non-trivial thing to believe, because it probably, it isn't true of the universe. It is simply a way that we choose to sample the things that happen in the universe. In other words, you, and I think that has potentially some significance for thinking about how brains and minds and so on work. In other words, the I mean to let's let's pull it back a little bit to perhaps a simpler thing to start talking about, which is to what extent is our kind of perception of the world, our belief about what the laws of physics are, to what extent is that determined by the way we are, so to speak? And so in a couple of- If you don't mind me interjecting. So this, and please, if you don't want to be interrupted, just tell me. No, no, no, I don't know what your favorite- Let's have a conversation. So this, it seems to me that we don't have a choice about putting the world together in this way, because subjectively, when we string together the universe, the putting the world together in this way, because subjectively, when we string together the universe, the states of the universe into worldlines, we do this by observing that some states of the world look to us as if they contain the memory of past states. And this way we construct our worldline or a sequence of states to the universe, our trajectory through the universe. If there is no information carried forward or some of this information is lost on the way, you will never know, except if you are able to reconstruct the generation of the universe from first principles. But from the perspective of the observations alone, we cannot see that information has gone missing because it will be drained out of the universe, right? We will have lost it. And so the question is to me, if we live in a non-deterministic Turing machine, as opposed, for instance, to the Minecraft universe, which is entirely deterministic, what, it looks different. Is there any difference for us as an observer, then we would live in a non-deterministic Turing machine running Minecraft? than we would live in a non-deterministic machine running Minecraft. Quantum mechanics. That's the difference. The fact that we observe, I mean, the first level of difference is, I think, quantum mechanics. So, you know, I mean, maybe I should explain a bit about what we now think about how the actual universe is constructed. Because that's to get to the point where we can discuss how minds interact with physics, we have to understand something about physics. I think there's a quite different conversation which is once we understand the paradigm that we get from thinking about physics, what does it mean about thinking about the mind even independent of the physics of the mind, of the brain so to speak. And I think there's an interesting conversation there about to what extent you about to what extent conscious thinking, unconscious thinking, to what extent these things correspond to single threads of experience versus multiple threads. But let's start off with physics and then go to things which don't require sort of the infrastructure of physics, but you do use the formalism that we seem to have developed for physics. So if we start off with physics, one question is, so what's our universe made of? And that's a question people have been wondering about for a long time. I think we now have a very definite answer. And the basic answer is everything in the universe is made of space. And what is space? Space is something which, unlike what has been kind of assumed for the last couple of thousand years, which is space is just this background where you can put things anywhere you want. Space has a definite structure. Just like a fluid like water, you might say it can flow any way it wants, but actually it has a definite structure made of molecules and so on. And so we think it is with space and that space consists of essentially atoms of space. And these atoms of space, they aren't like physical atoms with protons, neutrons and things, they're just elementary points that have the feature that the only thing we know about them is that they exist, and that different points are distinct. And then what we say is the way that we kind of that we construct the universe is through relations between these atoms of space. So there are sort of atoms of space and they can be there, they are connected to each other. We can think of it as forming a hypergraph. We can think of it, some generalized graph, basically a network where every atom of space kind of is connected to neighboring atoms of space. There's no notion of coordinates where these atoms are because there's no sort of background space. All we have is this connectivity information about how these atoms of space are connected to each other. So- So the atoms of space are locations and the space-time that we normally think of is the set of all trajectories that information can take between the locations. And locations are places that can hold information. They don't hold a lot of information. They're just, all they are is, you know, think about them as things with a UUID. That's all they are. And the representation of the state of the universe is a great big collection of, let's say, n-tuples of things with UUIDs. So what holds the state changes? The connectivity between the locations? So, okay, so let's say the state of the universe is this hypergraph, which is a bunch of atoms of space which are just UUIDs, with certain relations between them. So then we say, let's have a rule that says, whenever we have, for example, let's say, x and y are together, x and z are together, related, x can be anything, y can be anything, et cetera, then we make a transformation that x, y, x, z goes to, I don't know, z, x, you know, x, y, z, y or something. Okay, so it's just a transformation that says, if you have a, think about it as a graph transformation. If you have a little piece of graph that looks like this, transform it into a piece of graph that looks like that. And you say, let's just apply that transformation wherever we can to this hypergraph that represents the current state of the universe. Now, I'm sort of, I mean, so that's the idea, but now you've got, so the space is kind of this layout of all these atoms of space with all the relations between them. Time and the progress of time is the progressive application of these computational rules. Now, what is, for example, non-trivial is that the rules just say, when you have a piece of network that looks like this, transform it to one that looks like that. There may be many different ways to do that. There may be many different threads, different paths of history that correspond to different sequences of rewritings that lead you to different sequences of states of the universe. And that's where we get, for the universe, that's where we get our multi-way graphs from. In the simplest form of multi-way graphs, the nodes of the multi-way graph are states of the universe and they are a given state of the universe is connected to potentially many possible future states of the universe that corresponds to the different ways that you can apply that underlying rule. Now that's a it's a very wasteful data structure because every node in that graph is a complete state of the universe. And the difference between two next states of the universe may only be a couple of connections between atoms of space somewhere in the corner of the universe, so to speak. And yet we are restoring in that way of thinking about it, we're sort of restoring the whole universe. And that's sort of an inefficient way to think about it, but it's a useful way of thinking about it, we're sort of restoring the whole universe. And that's sort of an inefficient way to think about it, but it's a useful way to think about it. So what we've got is we've got this graph that represents the evolution from one complete state of the universe to several complete states of the universe that can be branching from one state of the universe. We can branch to multiple possible next states. We can also have merging, because it can be the case that two states of the universe, we can branch to multiple possible next states. We can also have merging, because it can be the case that two states of the universe that were distinct end up being able to transform to something which is in fact the same state of the universe. So we have this graph that branches and merges and every path through that graph is a possible history for the universe. Okay, so now the question is how do we experience that graph? And this is where things get kind of funky because one of the key features of this model of physics and one of the things a little hard to grasp is the fact that we are observers who are embedded within the system. So we don't get to say, oh, we're looking at it from the outside. We can see, although these branches and mergers and things like that, our minds are branching and merging too. So our perception of what's going on is determined by, you know, how does a branching mind perceive a branching universe? Okay. And this is the sort of real kind of brain twister, which I think is the sort of key brain twister of the difficulty of understanding quantum mechanics. Because I think quantum mechanics is really a story of how a branching brain perceives a branching universe. And so just to, just to kind of fill in that there are many levels of this but but an important piece just has to do with. The extent to which the laws of physics are determined by our perception of them. And there's a sort of simpler case in the quantum mechanics case, very simple case in in statistical mechanics and thermodynamics. So you have a bunch of gas molecules bouncing around in the room. And we know that the second law of thermodynamics, for example, says when you start with an orderly collection of molecules, the chances are they'll all randomize and look and be sort of disorderly and spread out around the room. But the fact that we conclude that the second law of thermodynamics is true is a consequence of the fact that we conclude that the second law of thermodynamics is true is a consequence of the way that we observe these molecules. If we were down at the level of individual molecules and we were able to trace the motion of every molecule, somebody might say, oh, entropy increases the second law of thermodynamics is true. We'd say, what are you talking about? All we know about is, you know, this particular molecule does this definite thing based on this collision, et cetera, et cetera, et cetera. The fact that we perceive there to be this kind of this overall law, is a consequence of the fact that we are large-scale observers who are not capable of disentangling all the computation that happened at the level of individual molecules. To us, we just say all those individual molecules, they seem to be doing kind of random things. Not the thing which would ultimately be at the molecular scale correct, not there are all these computationally irreducible processes going on with these molecules that correspond to a very sophisticated computation, we're saying we are computationally bounded observers, who just say we can't understand all of that detailed computation, we're just going to describe it in terms of this bulk thing of the overall density of the gas or whatever else. So the fact that we conclude that we can talk about gas laws and we describe the universe in those terms is a consequence of the fact that we are observers of the kind that we can talk about gas laws and we describe the universe in those terms, is a consequence of the fact that we are observers of the kind that we are. If we were observers who were computationally, arbitrarily sophisticated and operated down at the level of molecules, we would describe the universe in different ways. A more extreme version of this is the description of space. The fact that we believe that there is a continuum, that space is a continuum, is basically a consequence, well at the first level, it's a consequence of the fact that we're very big relative to the atoms of space. Maybe atoms of space, the elementary length might be 10 to the minus 100 meters. Well, that's really small compared to the 10 to the, you know, that makes us very big compared to that. The universe is 10 to the 26 meters across. So we are much closer to the maximum size than we are to the minimum size in that estimate. But so, the thing that, the other critical thing about our perception of the universe is that we believe that we are persistent in time. That is, even though at every successive moment we are made of different atoms of space, it is our belief that we are the same us at the next moment as we were at the previous moment. And that- I can see that it's not true, right? As an observer, at least. The question is, of course, how you define an observer. I understood computation long before I just began to understand mathematics, because I grew up with computers. And to me, space never made sense as a continuous substrate. And you have to make something that looks perfectly like space or good enough like space in a computer game. But this notion of the continuum that you can fold up into stuff or where you could put stuff in made no sense to me. And I later realized that it also doesn't make sense from a constructive perspective because you cannot construct a continuum. What you have is too many parts to count. So geometry is the set of operators that my brain can compute efficiently in the limit. In some cases, when you look at too many parts to count, you can find operators that converge. But basically the outcome of your computation is very similar when you use a few trillion or a few billion elements. And so in this sense, circles form in the limit, pi forms in the limit, but nothing in the universe contains pi, nothing in universe relies on having known the last digit of pi. This is just something that it would be like if it was continuous, which it is not. Well, okay, so there's one slightly confusing thing, which I've actually recently kind of sort of thought about a bit, which is the fact that we believe that we are persistent in time implies a certain continuum. Because if you believe that you have a consistent existence at the next moment in time, between every two moments in time, you are still there. And so in a sense, this belief of persistence in time is I think what drives our perception of the continuum. That is... I think that the universe is not learnable if there is no information preservation. So if information is not carried forward between different states, between different observations, I'm not able to generalize over observations and form any kind of model. The same thing if there is no functional continuity between my mental states, I will not be able to be an observer. But I do notice that my own status as an observer is only an approximate thing. I notice that I'm not always present. I notice that there are gaps in my memory. I notice that there are things in my own thinking that I cannot perfectly reconstruct. And that might be due to my inability to record things. It might also be because these things are actually missing and never existed in the first place. So my own models of me as an observer are very approximate thing. And then you say observer, that of course, many notions of observer in physics that are very different things. And when you say observer, what qualifies as an observer? What is the boundary between you and the universe? And to which degree are you actually existing or only approximate? Well, so I think the thing, and this is something that we are just trying to study is to sort of make a kind of a foundational theory of observers that is like the foundational theory of computation. We haven't done that yet. So the question is, when you look at all these different measuring devices and so on, literally I was just before this looking at some measuring devices related to chemistry and looking at individual molecules. And there's a lovely automated chemistry lab that's based on Wolfram language technology, which means that I can do, I can be a chemist just writing Wolfram language code and physical experiments get done. But you know, so that's a, the question is just like we have, for example, Turing machines as a convenient idealized model for the computational process, what's the right idealized computational model for the computational process, what's the right idealized computational model for the observing process? And at a qualitative level, what is observation? Observation is you take all those details of the world and you somehow sort of contract them to be the things that we experience, to be experiences that we can describe as experiences, for example. And so, you know, some part of that goes through our human senses. We can see things, we can hear things, and so on. As we build instruments, you know, all sorts of chemical, analytical chemistry instruments, we are, in effect, those are transducers that go from some feature of the physical world, to things that we can see, hear, whatever else. And so, for me, kind of the the observer is ultimately the kinds of things that register in our brains, which is certainly a slightly vague thing to say. But that's, you know, that's ultimately what an observer operationally is. And as we build out science, we are essentially constructing technology, we are essentially extending the transduction from the real world to what we perceive in our brains. But we can start off by asking the question, if we are interested in the things that we can more or less directly perceive in our brains about physics, how will that work? What kinds of things, you know, for example, talking about the individual molecules in a gas, we don't get to perceive those things with our actual bounded computational power, et cetera, et cetera etc, etc. So, therefore, our description of the gas is according to laws that work for us as observers. We could imagine some alien somewhere, you know, in a very different way. There's some alien intelligence somewhere that could perceive completely different things about a gas. They could say, you guys talk about pressure and temperature, that's completely stupid. You know, what we've always talked about is, you know, causal graphs of correlations between this and that and the other. That's what really matters. You know, what you guys have identified is stuff, well, you care about it, but we don't care about it. We built our technology stack on something utterly different. And that's a, I think that our view of the universe is, the view that we have of the universe, certain aspects of that view depend only on very coarse properties of us as observers. In particular, that we are computationally bounded and that we believe that we are persistent in time. There's an additional thing, which I think is slightly independent, which is we believe that pure motion is possible. That is, it could be the case that you take an object and you move it around and it's no longer the same thing. It's because it is made from different atoms of space and it could just be different. And even in traditional general relativity, if you move an object around and you are very close to a space-time singularity, that object will be shredded and that object will not be the same object in any reasonable sense of sameness as you move it very close to the space-time singularity. But the fact that it is possible to have things that are persistent, that we perceive as persistent in time. Now when we move an object around, it is made of different atoms of space. So we could say oh it's a different object, but we don't. For us at the level of observers that we are, we just say oh that was the same iPhone that just got moved to that different place. But this is how we define objects. This is right, an object is that thing which remains constant when the perspective changes. It's a certain way of coarse graining the universe. We do know that objects in the way in which we perceive them are constructs. They are somewhat not arbitrary divisions that we impose on the state vector of the universe to interpret our observations. It's not arbitrary because it's based on whether it gives us a useful description, this decomposition. But we know that for instance, if you take, say, a vortex of cigarette smoke, that you've asked for the air, that this is at the boundary of whether it's an object or not, right? At some point, the treating this as an object is no longer meaningful. And there are other objects which are more solid, which are more persistent, and so it's more natural to treat them as objects. Let's go back for a moment to this notion of the observer. Let me say something about objects. It's a good, I mean, you know, when we think about what is an electron, okay, in our model of the world, there's nothing in the world except space. It's just this big network of atoms of space. So what is an electron? An electron is some persistent thing in that network of atoms of space. So it's- What is executing? If space is the substrate, your graph, what are the semantics of the links in the graph? They do what holds the state. Is the set of atoms constant or does it change? No, no. And what's operating on it? It's a rule that simply says, if you've got a cluster of things that looks like this, turn it into one that looks like this. It's that rule. So the first way of thinking about this, you just say, pick a rule. It's a particular rule. Okay? We can go to another level where we're talking about the Ruliad, which is a different level above that, a little bit harder to understand. But the first level is there is a definite rule, and you're applying that rule everywhere you could apply it. Yes. Where does the rule come from? What specifies that it's this rule and not're applying that rule every way you could apply it. Yes, where does the rule come from? What specifies that it's this rule and not another one? Well yes, then you're going... And what executes it? You're descending into the rabbit hole. Yes, we have to, please go. That's interesting. Right, right, right. No, I think it's very interesting, but it's just, it's worth, let's just hold for one moment on what electrons are before we descend into this rabbit hole because this rabbit hole gets pretty deep. By the way, I just know it. I asked Dali to render what the inner structure of an electron looks like. And it came up with something that looks like out of a Gundry movie. Okay, okay. Very beautiful. I have no idea what text it's, what tagged images of the, in current physics, if you say what's inside an electron, people would say, in previous physics, I should say, people call modern physics, the physics that was invented a hundred years ago. So there's, I don't know what we should call our physics, I should say. You know, people call modern physics the physics that was invented 100 years ago. So there's, I don't know what we should call our physics, but it's the physics beyond modern physics. It's the physics a century beyond modern physics. So in any case, in our sort of, in our previous physics, you know, you say, how big is an electron? People will say it's a geometric point. It has no size. There's, it's some, and so to say what's inside an electron, there won't have been a way to say that. I mean, in quantum field theory, it's more, slightly more complicated because there are these fluctuations that cause there to be virtual photons around an electron, blah, blah, blah, blah, but basically an electron, and it's in the intrinsic blah, blah. But basically an electron in the intrinsic theory is like a zero size geometric point. Okay, so in our model, an electron is something more like a vortex in a fluid. That is, there are underlying molecules in the fluid, but there is a collective motion of those molecules that corresponds to a vortex. And that collective motion is persistent, at least for some period of time. So the vortex behaves like an object, as you were describing it, and can have an identity that moves around. Now the molecules that make up the vortex are continually changing, and when you say, oh, tell me exactly where's the boundary of that vortex, it might be hard to say that. But what we can say is, as a practical matter, if we want to describe, you know, that airplane has wingtip vortices or something, there's a definite notion of a vortex there and there's a definite object that will, you know, fall through the air when it peels off the wingtip of the airplane or whatever. So we can describe it as an object. So when we talk about electrons, our belief is that what's happening is that electrons are kind of like vortices, not specifically, they have some topological features that may be like that, but not in terms of visual appearance or anything like that, but they are conceptually like vortices in the sense that they are persistent kinds of structures in this hypergraph that represents space. They are structures that survive for a certain time. Now, one thing about electrons is it seems like every electron is the same. Whether that's really true is not clear. For example, black holes. There are things we know from general relativity about sort of the fact that black holes, it only matters what the mass and spin of a black hole is, more or less. But inside, there can be a, you know, a great civilization that was in some solar system around a star and the whole thing collapsed and that's all been crushed into the black hole. There can be lots of different things inside black holes, but to the outside, they always look to only, they only expose certain things. And it could be very much the same of electrons, but there could be a very close analogy between black holes, which are structures in space time and electrons, which we also think of structures in space time, both sort of made of space. And it's a little disappointing when we think the following thing, that the vast majority of activity in the universe is concerned with the knitting together of the structure of space. And all the electrons and things we care about and so on, there's some tiny little piece of froth on top of the main activity in the universe, which is kind of knitting together the structure of space. That is, the main activity in the universe, which is kind of knitting together the structure of space. That is, just like in a fluid, the vast majority of the activity is collisions between molecules that maintain the idea of a gas with pressure or a liquid or whatever else, rather than the things, the little tiny effects that make collective motions like vortices and so on. And so it is, I think, with the universe. But- So the electron is a pattern in the is, I think, with the universe. But- So the electron is a pattern in the graph and this pattern is the property that it's dynamic and that's- Sorry, say that again. The electron is a pattern in the structure of the graph, a characteristic pattern. Yes. And this characteristic pattern is the property that it is, unless it collides with another pattern that dissolves it, it is persistent and it's dynamic, and it is progressing through this graphical structure of space. And it is occupying a certain region in a particular way. And when it dissolves, it gives rise to different patterns. Yeah. Right. This is a way to look at it. And I think that makes total sense. If you go back, step back to the observer, I'm not sure if an observer is the pattern in the sense it's, it is a certain pattern, but it has certain functional properties that can be made out of multiple materials, because it's a computational abstraction. It's a, it's slightly more abstract than the electron. Yes, that's correct. The observer is an abstraction of this. And I don't think we fully understand yet how to think about that. Exactly. So at some point of the observer that we would need to ask is, where does it end? What is not the observer? And so, for instance, when I conceptualize myself as an observer, there are several layers. For instance, there is consciousness, and consciousness is not the observer. Consciousness, in an interesting physical sense. I think that consciousness is part of a fiction that my mind creates to make sense of itself. So I'm a virtual character in a virtual world that is generated by my brain to explain the sensory data. But something in the functionality that my brain is part of implements an observer. That is a thing that is able to observe patterns and memorize them and abstract functions over them to make them explainable. And what I noticed is that when I observe quantum mechanical phenomena, when I measure the spin of a particle, I can never observe a superpositional state. The superpositional state is something that I do not directly observe. It's something that I construct in my mind. Of course, the other one is also something that I don't directly observe. It's something that I construct in my mind to make sense of these patterns, to classify them. But the collapse of the wave function is special because when I make an observation, it is a classical observation. It's one where the universe it is a classical observation. It's one where the universe is in a particular way. And when I look, it's always in a particular way. And the fascinating thing about this collapse of the wave function is this a point in my past, between, beyond which I cannot pretend that the universe is classical, because I cannot reconstruct a classical description of the universe. Is the boundary of me my skin? Is it my nervous system? Or is it this measurement? Is it this instrument by which I measure the universe? Right. I think that this has been very confused by the traditional formalism of quantum mechanics. Because in the traditional formalism of quantum mechanics, one has this idea of sort of, there are in a sense a superposition of possible states. In our description, it's a multi-way graph. And then that's all fine. And we've got good mathematical formalism to describe that. It's existed for a hundred years. But then there's this kind of mysterious thing that says, well, actually we have to go from all those threads of history, we have to say, but we experienced just a particular thread of history, so something has to come in and collapse all those threads of history and take us down to just this one classical thread. And in the traditional formalism of quantum mechanics, it's just, you know, and then the hammer comes down and you've gone from all these threads to one thread. And the description of that hammer is not present. That is not part of the theory. It is just there is a hammer and it has certain characteristics. And what we need to do to understand what's going on and to understand, for example, things like whether we can really expect to get sort of a quantum advantage in a quantum computer, those kinds of things, is to understand more about that hammer, to take the hammer apart. And for that, the feature of the, you know, to the universe in a sense, from the sort of God's eye view of the universe, from outside, so to speak, what you would see is all these threads of history. You wouldn't see a single thread of history. You would see all these threads of history, but we see a single thread of history. Now that's analogous to the fact that we see all these gas molecules bouncing around, but all we see is the pressure of the gas. So what's happening, I think, is we are coarse graining, not in physical space, but in this, what we call branchial space, the space of quantum branches. We are, we exist, our minds exist as branching things in this multi-way universe, and we have an extent in branchial space, just like we have an extent in physical space. So just like we're coarse graining, we're not looking at every single atom of space, every single molecule in a gas, we're just aggregating a bunch of these together and that's our experience of the world. So similarly, when it comes to quantum mechanics, we are aggregating clumps of paths in branchial space. So we have an extent in branchial space. What is that extent? So is it? No, what is, what belongs to it? What is part of it? What is not part of it? Is it a sequence of classical memories? So it's something where we basically select in our own minds a part of the branch of space, the one that we can reconstruct and construct ourselves from it as our own model of what we are as the observer, or is the observer anything beyond that? No, I think it's more or less that we're constructing something from it. So the big question, the big physics question is this. Let's say we have all these threads of history and we simply say by FIAT we are going to consider these threads of history to be the same. We're going to say they're really all the same, they really all did the same thing. You can think about this in terms of theorem proving. We can have completion. We can have critical pair lemmas and things. There are a variety of ways to think about it. But basically, what we're doing is we're conflating different parts of history. We're saying, for our purposes, we're just going to consider them the same. Just like in the case of molecules in a gas, we can say there's some detailed motion of molecules, but we don't care about that detailed motion. We only care about the overall pressure of the gas. So similarly, we are conflating together many detailed paths of history. Okay, so the big question is, is it consistent to do that? So what would it mean if it was and wasn't consistent? Let's look at in the case of the gas. What it means to say, it's good enough to just say there's a lump of liquid here, for example. The reason that that's good enough is because when we look at the time evolution of that system, it's still just a lump of liquid. It could be the case that that lump of liquid does, when it time evolves, the position of every single molecule in the lump of liquid matters in how it time evolves. It's sufficient to just say there's liquid and it's then, it has some overall form. We know the overall structure, we can predict the overall structure in the future, but it might be that we need to know that the different configurations of molecules in that liquid would determine its future, would determine the overall aspects of its future. That is, that it would be, in a sense, the way we describe this is the process of shredding. That is, that you think you've just got a description. Okay, I'll give you an example that we've looked at recently in metamathematics. You think you've got the Pythagorean theorem, okay? But you now say, if you try and base that on deep axiomatic structures, there are many different ways to formulate the Pythagorean theorem. Many different definitions of the real numbers, many different kind of detailed axiom systems and so on. But each one of those, we just bring those together and say, it's just the Pythagorean theorem. So what allows us to do higher mathematics is that we can say we've got the Pythagorean theorem, now we can deduce something else just from the Pythagorean theorem. But it could matter, that deduction could be affected by which model of the real numbers we'd used in formulating the Pythagorean theorem. If that was the case, we would no longer have this kind of, you know, aggregate thing that we can think about. We'd be shredded down to the level of the very detailed sort of, well, atoms of existence, so to speak, that make up the ultimate sort of metamathematic structure. So it's the same thing in all these cases, there's the question of can we maintain the fiction that we can coarse-grain things? In other words, does the coarse graining fall apart because of the actual time evolution of the system? So it could be the case that instead of those molecules in the gas staying more or less the ones that were together before that make a certain density of gas staying together and a second later also making a certain density of gas, it could be that, oh, if the molecules were dancing around in this way or that way, then at the next moment, they will have something which, you know, where the gas is separated into two pieces or something, where even at an aggregate level, we can no longer, we can't describe it, you know, there's no simple description of it. So the fact that the simple description that we make, that we as abstracting observers make of the system, the fact that that can be transported forward in time, that's a fact about physics. And that might not be true. I mean, for example, it could be the case that the thing we make up, you know, has gravitational collapse, leads to a mathematical inconsistency if we're doing it in meta-mathematics. Lots of pathological things could happen that would prevent us from being able to kind of take our aggregated description and move it forward in time. But I think that the notion of the observer is, it is essentially the fiction that there is an aggregated description of things. The observer, the operational thing the observer is doing is choosing to make an aggregated description and there is an underlying thing viewed from the outside, so to speak, and there are an infinite number of possible aggregated descriptions you can make. The thing that is non-trivial and the place where the science really bites is that if you make certain assumptions about the observer, very coarse assumptions, you can immediately deduce things about what the observer can observe. For example, if you say the observer is computationally bounded, believes they're persistent in time, it then follows that space-time must follow Einstein's equations for general relativity. It also follows, we think, that the multi-way graph for the universe must follow the Feynman path integral rules for quantum mechanics. That's a very interesting thing, because quantum mechanics and the non-deterministic Turing machine are traditionally not defined in the same way. The multi-way systems that you describe are not exactly the same formulas, and it seems to me as physics uses for quantum mechanics and quantum computers are not the same thing as non-deterministic Turing machines. How do you define it? Do you think that quantum mechanics is literally the multi-way space? Yeah, yeah. And I mean, you know, we can, okay. So it's a little, there's more technical detail here. So the one feature of quantum mechanics is we have this notion of quantum states and amplitudes for quantum states. So the one sort of confusion of quantum mechanics is people say, oh, there's a certain amplitude and that amplitude is a complex number, okay? I think the bundling of the magnitude and phase of those numbers together as a single complex number is very confusing. And I didn't realize this until a couple of years ago, but I always believed that. I mean, I learned quantum mechanics when I was a kid and I sort of always just assumed that's the way things work. And so here's the description roughly. So we think about this multi way graph that has all these different. All these different threads and each thread corresponds to a quantum. Well, essentially, a quantum that a full quantum state is a slice across this multi way graph and so a superposition is just saying we're going to consider together two threads in this multi way graph. And then the question is one question is when we when we take this multi way graph and we make a slice across it what, how do we lay out the threads in that slice? So all we've got is just this graph, and it's got threads coming out of it, but can we lay those out in some kind of space? And we talk about this notion of branchial space, and the idea is a simple way to construct that, it's just to imagine that every pair of ends that have a common ancestor, every pair of states that have a common ancestor are connected. So you make a graph of just that common ancestry. We call that the branchial graph. The limit of the branchial graph is what we call branchial space. Just like in physical space, the limit of our hypergraph of relations between atoms and space we think of as a map of physical space. So, okay, so we have this branchial space, it's a different kind of space than physical space, and it is defined by these entanglements, by these common ancestries of different states. So, what we believe is that essentially position in branchial space is quantum phase. So as you move around in branchial space, you are effectively changing the phase of a quantum amplitude. And we think that the magnitude of the quantum amplitude is just the path counting of how many different ways are there to reach a particular place in branchial space. So for example, destructive interference, where you have, you know, photons can go through two slits. What's happening there, we think, is that those two photons, or those two ways of them going through one slit, the other slit, those two possibilities end up at opposite ends of branchial space. Now, why does that mean there's destructive interference? The reason is that no observer will knit together those two completely separated pieces of branchial space. Now, why does that mean there's destructive interference? The reason is that no observer will knit together those two completely separated pieces of branchial space. The observer is of bounded extent in branchial space. So to the observer, the photon just disappeared. It didn't, there wasn't, because the observer can't, doesn't, you know, the observer will not, will not sort of conflate together these things that ended at opposite ends, that ended up at opposite ends of branchial space. So this picture of multi-way graphs and branchial space and so on, so one thing to say is that we can compile like quantum circuits that people use in, you know, quantum information theory and so on, you can compile those to multi-way graphs. We have a nice way of doing that. And you can even do nice quantum circuit optimization using essentially theorem proving methods on multi-way graphs. So it's kind of a proof by compilation that it really is the same as traditional quantum mechanics. So would that also work on phonons? For which? The quasi particles that we can use to describe the movement of sound to solid objects, for instance. Well, which aspect of this? So, the... In, I mean, insofar as one has a... I mean, okay, so... In so far as one has a... In quantum information theory, people usually talk about gates. Gates are not Hamiltonians. You make a gate, it's kind of a complicated limit from taking the step-by-step in time Hamiltonian of evolution for a quantum system and turning that into a gate. So I don't know, in the case of phonons, the traditional methods for making, you know, what people call quantum computers, I don't remember one of those being related to phonons, although as I think about it, I don't see why you couldn't do that. I mean I think that the main issue with phonons is that, you know, the thing that is, so phonons, you know, normally they're just going through a solid but then there's this thing, the ump clap process, which is this non-linear scattering process that leads to interaction between phonons, and that's what you'd have to use to get, I mean, it's no good to just have a bunch of independent bits. That's not what you need. In order to make something which actually does a computation, you need to have interaction between those things. And I don't see why one shouldn't be able to. I mean, one of the things that has come out of my earlier science is you can make computation out of almost anything. And this is undoubtedly, you can make a universal computer out of almost anything. And this is undoubtedly, you can make a universal computer out of phonons. I don't happen to- Now the question is, would phonons, for instance, be better described using multi-way systems? Well, look, any, I'm thinking about that. And I, you know, the thing that is a little bit, we're not quite there yet, is quantum field theory for multi-way systems. So let me explain. So in, you know, what I was describing before is multi-way systems in which every node in the multi-way system is a complete state of the universe. Okay. That's essentially a story of quantum mechanics. Quantum mechanics has limited number of, where you're talking about a complete state of the universe. Okay? That's essentially a story of quantum mechanics. Quantum mechanics has a limited number of where you're talking about a complete state of the universe. In quantum field theory, you're also talking about space as well as this. You're talking about things laid out in space. So, for example, Feynman diagrams from my former friend, Dick Feynman, were, you know, are space-time diagrams representing kind of the, not just there is an electron, but there's an electron moving through space and time. And so that, the formulation of, so a quantum field, when in quantum mechanics you're rolling things up into a single state of the world. This is the state of the world. In a quantum field, you're saying there's actually lots of degrees of freedom in that quantum field that should be separately considered to be at different places in space and so on. You're not packaging it all up into saying there's just two possible states of the world. So what happens in our multiray systems, the thing that I describe where you're just packaging the universe into each node of the multiway system, that's like quantum mechanics. It's a deeply wasteful way to think about things because those two different nodes in the multiway system, they only differ by a few bits. They're in the corner of the universe. Now, in order to not have that happen, in order to be able to bring those together, you have to be doing quantum field theory and there's sort of a collection of different formulations of multi-way systems. We have things called local multi-way systems and glocal multi-way systems and it's something which is, I mean, just to explain, you know, why are we not going faster? I think we've gone pretty fast actually, but why are we not going even faster? The fundamental problem is the mathematics that we need to use to describe these things is in the natural course of the development of mathematics hundreds of years in the future. So it's the, you know, the kind of thing, for example, a very typical issue that we have is these hypergraphs, they are not, their limiting structure does not necessarily correspond to integer dimensional space. But calculus is built only for integer dimensional space. When you learn multivariate calculus, you might learn, you know, calculus of one, two, three variables. You do not learn calculus of 2.6 variables. And there isn't a formulation of that. There's, you know, we're trying to build one based on our models, but you need that sort of a thing that could have been built. Well, it probably couldn't have been built, actually, when calculus was invented 300 years ago. But we kind of have to build a structure like that to be able to describe our models in a way that again it's sort of an interesting thing because we're trying to bridge the underlying computational model with a thing that we can understand with our brains, because this is a, you know, this is in a sense story of my life is kind of, you have the raw underlying computation, that's very powerful, and then you have what we with our brains can understand. And, you know, my main life activity is building what's now Wolfram Language, which is, you know, a computational language that is a bridge between what we think about with our brains and what is possible to do computationally. And so... And do you think we will hand this task over to the machines? When do we hand over this task to the machines of constructing these mathematics? When you say that the BCP scratched the surface of mathematics with the formalisms that we discover, mathematics is the space of all possible simple games, right? And in a sense, human mathematics is the set of simple games that you can discover with something like a 12-layer network that runs algorithms that are more complicated and clever than the ones that we've came up with so far in AI. But ultimately, it's quite limited, and I suspect that future AIs will love to get drunk. So they are only coherent over 12 layers and look at the universe that looks to them like it looks to human physicists, and they find this very amusing. I think that we are at this threshold of building systems where we humans don't need to tinker anymore, is discovering the consequences of building certain simple systems. But we can automate this exploration beyond what Mathematica is doing at the moment. The question is, what's the point, though? Because the fact is, I can run my favorite cellular automaton. It's full of interesting computation. The fact is, I can run my favorite cellular automaton. It's full of interesting computation. Most of it is not something that right now in history, I care about. Now, it could be, when I first started thinking about computational irreducibility in the early 1980s, I thought of it as a limitation for what you could study scientifically and so on. Then somebody figured out you could use scientifically and so on. Then somebody figured out you could use it for proof of work for blockchains, not a thing that had ever occurred to me. So in other words, we're taking this thing plucked out of the computational universe, in that case a very core phenomenon in the computational universe of computational irreducibility, and we're saying now we've got a use for it that we humans care about. So I think the point is that, you know, yes, at some fundamental level of computation, the AIs can do, you know, can do cellular automaton, can do wonderful computation. Even in mathematics, we've just made this big study of mathematics and sort of the space of all possible mathematics and so on, there's amazing richness there. What we can actually plot, we've actually got pictures of this, is you look at the space of all possible mathematical theorems of a certain type and you say, which are the ones that we humans have given names to, little dots here and there in this giant space. And so the question is, the whole thing is computationally there. The whole thing is absolutely accessible to a computational AI, so to speak. The issue is, it's like observing in quantum mechanics. The issue is, there's lots of stuff going on underneath, but for us to connect it to what our brains deal with is a thin wire, so to speak. So, in other words, we can say, you could say the ultimate future of science is you're just computing all these things. But that ultimate future of science is already happening. It's been happening in nature forever, so to speak. But the problem is the connection of that to us as humans is the thing that we care about. Now, if you say, well, you know, nature is doing what nature does. You know, the weather has a mind of its own. It's doing all the amazing things it does. And, but the part of it that is relevant to us is the part that we can describe, we can experience, et cetera. So I think it's, you know, it's sort of a fallacy to think, when we make the AIs powerful enough, they'll just go off on their own and discover all of science. That's almost a triviality. The issue is to make a bridge between what we care about. And one of the things I think is interesting about the course of history is that as we, we didn't yet talk about this notion of ruleal space, but the notion of sort of the space of all possible rules, but as we progress, as we understand more concepts, as we build more measuring devices, the set of things out there in the world that we care about gradually expands. So, you know, there was a time when we didn't notice the microscopic world at all. Then microscopes were discovered, invented. There was a time, I think the key thing in quantum mechanics is when electronic amplifiers were invented. We could take a small signal and amplify it. And I think that was what, I haven't completely traced through this history, but I'm pretty sure that was what led to the invention, to the discovery of quantum mechanics. Is that, so in other words, there are features of the world that we were currently unaware of. So, for example, the big feature of our world right now, you know, talk about the gas molecules again. People may say in the future, gosh, I cannot believe that all those guys noticed about a gas was its pressure and temperature. That was really dumb. They should have noticed all these other things which are of computational importance are now entrained in technology and so on. I mean, it's been the same, you know, the sort of the noticing of physical effects that we then entrain in technology and end up caring about, that's in a sense the story of the progress of sort of the paradigms of science and of technology. And so I think it's the idea that, so you know, one of the questions would be, is there a way to take sort of the world as it is and find those words for describing the world that we should have noticed but didn't. Like let's say protein folding. You know we know proteins make alpha helices, beta sheets. Okay, maybe there are five other motifs that we should have had names for but we don't. And that's why we found protein folding hard, is because we didn't notice those other motifs that maybe aren't visually very obvious in the way that we usually look at pictures of proteins and so on, but which are perfectly recognizable if we sort of select them in the right way. And once we can describe, you know, that protein has a frobulous, you know, leaf or something, then we can immediately say, oh, it's going to fold this way or whatever else. And that it's kind of a frobulous leaf or something, then we can immediately say, oh, it's gonna fold this way or whatever else. And that it's kind of a, that there are certain key descriptions of the world. I mean, you take your average image identification network, for example, and you look in the middle of it, and it's made all kinds of distinctions that we don't currently have words for, and which there may be some things which we can identify in the world. So one of the points is that there's sort of a question of what things are useful to identify in the world and where can we build sort of technology stacks on top of those things that we identify in the world. Yeah, this is the point. I think that it's about agency. This V is a very problematic notion. There's already a similar phenomenon going on as you saying, why should I care about what the AI is thinking if I don't understand what the AI is doing anymore and I cannot connect it to anything what I'm doing? I've heard physicists say the same thing about you, right? This mathematics might be right, but why should I care? Because I cannot connect it to anything that me or my community are doing. And so in some sense, you're already occupying a stratum between human physicists and superhuman minds. So your V is a very special one. It's a very particular pluralist by a status that you're using when you describe the perspective of us on the universe and what we are working on. It's not what the community of physicists are working on. It's not what the community of physicists are working on, it's not what humanity at large is working on. There's a certain projection that you're making when you say we. And I agree with this we because I enjoy your perspective and I think that it is part of a larger perspective. It's one that is very multi-veined and where there's a branchial space of, and many of these ideas work in a super positional space where they don't touch each other until the branches merge eventually again. And I suspect that a similar thing is going to happen with artificial minds, that there will be at intermediate steps that we don't get until we bend the branch back and ask the AI to explain to us what the AI has discovered. And the AI is going to model our mind and explain to a child that it understands how it operates or understands the mental state of the child, but it's able to outmodel us and to translate this into a language that we understand to the degree that we understand it. And I suspect the universe is mostly intelligible. It's just, you have done sometimes have difficulty to make these ends meet, But ultimately what matters is what can you do with it? What changes can you produce in the universe? An agent is a system that controls the future, right? And we build systems that can control the future by themselves. They are part of us and we are part of them in a way. But, you know, one statement you made that the universe is intelligible. I think that the intrinsic, you know, we didn't, let's talk for a second about this Ruliad concept, just so we make sure we touch that, because people, I think, will enjoy that. But, you know, this idea that the universe is intelligible, the universe as we observe it, you know, it is a non-trivial fact that the universe as we observe it can be intelligible to us as observers. It might not be true. It might be the case that with our methods of observation things would always get shredded. But it seems to be the case that with the the level of description that we want to give to the universe that we can be successful at describing the universe consistently at that level of description. But it isn't the case that the whole universe is, you know, given any kind of observer, humans, aliens, AIs, whatever, given any kind of observer, there is going to be a type of description that that observer can give. And it is not self-evident that that will be a consistent type of description of the universe. That's essentially a big result of physics that there is, and it's a big result of what we've been trying to do, is that there is consistency in that. But let's go to this Rooliad thing, and then I like your analogy of, you know, I consider that we are, you know, we're going off in a Roolial spacecraft, so we can explain, you know, that's our activity as we move, as we try and expand the domain of knowledge, we can think about ourselves, you know, as we go and explore physical space, we're moving and, you know, we're expanding our domain, you know, a few astronomical units away from where we are in physical space. Let's talk about this Ruliad thing and then we can talk about expanding in Rulial space. And then I really want to come back to the minds and AIs and branchial space because I think we can have an interesting chat about that. But Rulial space, so you had asked before why this rule for the universe and not another, effectively. Justify why is it that rule and not another. I have to say I was very confused about this for a long time. But what I then realized was, just like we say there's a particular rule and you apply it everywhere where you can, why don't you just imagine that you apply all possible rules everywhere you can? And so you might have thought that's just going to be a complete mess. There's going to be no structure. You apply all possible rules everywhere for an infinite time. What are you going to get? Well, in fact, that thing that you might think was completely structureless is full of structure. And the real reason for that structure is that two rules that are different will branch out, but then those two rules might lead to something which is identical. So you end up with getting, but because of this notion of equivalence, which ultimately ends up being an observer related notion, but the fact that you conflate things, you could just say let's let everything that is even nominally different, even two graphs that are laid out differently, even though they're isomorphic graphs, even just because they're laid out differently, let's consider them to be different. But instead, what we're saying is that, you know, equivalent things are equivalent, equivalent things are considered the same. And so that object that we have, which is essentially the object that you get by looking at all possible computations, let's say all possible Turing machine rules, run from all possible initial conditions for an infinite time. That object is the entangled limit of all possible computations. And it has a limit of all possible computations. And it has a, you can slice it in many different ways. So for example, one slicing involves looking at it, progressing through time. That's the typical slice that a physical observer takes. As you say, we are localized with respect to what rules we assume are being used. And we are slicing it, we're looking at successive slices through time. And again, another thing that's confusing is we are slicing it, we're looking at successive slices through time. And again, another thing that's confusing is we are not fully localized. We don't know, with any finite number of experiments, we cannot determine which particular rule the universe is using. There's a limit, there's sort of an uncertainty led as a result of the fact that the finiteness of scientific induction. With any finite number of experiments, there will always be a cluster, a cloud of possible rules for the universe. But the next fact is that there are many things that we can say, which don't depend on exactly where we are in real space and how big that cloud is. There are things that we can say that are general facts about multi-computation. And those general facts turn out to be very, have very specific statements about the way physics works. But essentially the way we can think about it is we experience the universe with the particular sensory systems we have, with the particular ideas we have for describing the world, we are experiencing this Ruliad in a particular place in the Ruliad. Just like we exist in a particular place in physical space, we exist in a particular place in Rulial space. And our friendly extraterrestrial aliens, so to speak, in addition to being, living in a different solar system can also live in a different place in real space. And so what would that look like? Well, that looks like their description of the universe is utterly incoherent with ours. So what we consider to be important feature of the universe, oh, you've got a planet there. They say, we don't care about the planet. What we care about is some features of the universe, or you've got a planet there, they say, we don't care about the planet. What we care about is some detail of the correlation between the electromagnetic field in this corner of this, even if they describe it as an electromagnetic field. So it's- So there's also a mechanism that we use to describe the brain, this particular kind of control hierarchy that we discover in the universe where atoms control elementary particles or are the result of control hierarchy that we discover in the universe where atoms control elementary particles or are the result of control of elementary particles and cells are the result of the control of molecules and organisms are the result of the controlled interactions between cells and so on. And minds are the result of the models that organisms make. This would be different from them and they would discover something that is entirely orthogonal to this. And that is because they inhabit a different part of the rudial space. Yes, I think so. I mean, the question of what the question of what those other parts of rudial space are like is a very, you know, I have a hard time thinking about that because what that's asking for, you know, one talks about paradigm shifts in human science. Every one of those paradigm shifts is a little tiny move in real space, little distance away and in turn little change in the way we describe the world. If you say let's jump all the way to the aliens, so to speak, that may be a very long way. That's like the equivalent of 100,000 human paradigm shifts, let's say, and people have a hard enough time, we all have a hard enough time with one or two in our lifetime, so to speak, to make the jump, you know, 100,000 paradigm shifts away. That's that is a, it's a very difficult thing to conceptualize what you land up with. And I seem to be constraints in our world that depend on how we operate. For instance, if I imagine you were made out of knots and somebody would put you in a four-dimensional space, you would unravel. If you would end up in a two-dimensional space, there couldn't be any knots in the first place. Or more relevant to our existence, there could be no planetary surfaces in 4D because there can be no stable orbits in the way gravity works, right? So that we discover that beings that live on planetary surfaces is contingent on living in a subset of the Vouillet space that can be described as a curved 3D universe, right? So there are other areas in this space probably, but the question is could they have observers? And there can of course be many solutions that are different from ours, but observers in ways that could not be translated, that don't form the same mathematics ultimately, that cannot be, where you do not find any shared language. Okay, so that's the question. It's like motion. So motion, you can take an object and you just move it around incrementally in space. That's pure motion. We're all happy with that. Another possibility is, if you want to get from here to there, the only choice is to use a Star Trek transporter, so to speak, where you go from your initial form, you are completely deconstructed into some, you know, elementary things, and then you're reconstructed at the other end. The fact that when you're describing, you know, how do you get from one place in real space to another, the question of whether there is pure motion there is a non-trivial question. I mean, that's something where, now, to say, make one comment about this. So, with certain assumptions about us as observers, we're computationally bounded, we believe we're persistent in time. The good news about that is that those constraints already give us some pretty big pieces of physics. We only need those constraints. You know, qualitatively, to understand why something like that might be true, if you think about the gas analogy again, we have all these molecules bouncing around, we have, they could be air molecules, they could be water molecules. Air molecules and water molecules have very different characteristics, yet the equations of fluid dynamics are the same for air molecules and for water molecules. And it's kind of the same thing with the equations of general relativity and quantum mechanics, that even with different underlying stuff at the level, at the collective level that an observer like us can observe them, they have certain characteristics. Now, I think what you're, I mean, one of the things you're perhaps getting at is how, you know, one question would be let's say we have a, an automated sort of rule all transporter, you know that a place in real space, and it is doing the translation back to, oh let's deal with, you know, interpreting that for those humans who have only these kinds of concepts. I think one of the issues there is that, you know, certain things about physics, like gravity, things like that, will be translatable. But other things, it's like, well, we just don't have a word for that. In other words, you can try to describe it. You know, there is going to be a translation, just because, you know, everything is in the end operating as a universal computer and you can in principle write an interpreter, write it between one universal computer and another. But the question is, is there a pure motion-like interpreter where you take big concepts in one thing and move them into big concepts in the other thing, or do you have to grind it down to the level of the machine code and then build it back up again. And I think the really the challenging thing is to see how do you go from, but perhaps the same thing even applies to AI systems today is to what extent, we've got a system and it does what it does. And the question is what, and we have a certain way of thinking about things. We have a certain cognitive framework, which is not just induced by the structure of our brains, it's also the history of the development of our science, etc, etc, etc. We have a certain way of describing things. Is that way of describing things? What is the way of translating what's going on inside the neural network to our way of describing things? And it is, I think, not self-evident. I mean, it depends what you care about in the neural net. If what you care about is whether it sees cats or dogs, well, we've got a good description of that. If what you care about is something more detailed, it's something where it's not obvious that we'll be able to get a description language which is a youthful and faithful description language that also connects to us. But I want to come to this question of minds and the multi-layer modelling of the things. That's crucial. First of all, if we translate ourselves with a space, the question is, what is preserved? I don't have an identity as such. When I wake up in a lucid dream, for instance, I'm not remembering usually in which city I live, and often not what my name is or what my body looks like. It's basically a system of meaning constructed from the computational primitives in my brain that is autonomous, that is a new one. And when I'm lucky, I can carry some memories over into the other self that forms a different configuration in my mind after I wake up. And I can interpret them, but I don't know what they actually mean and why they made sense before and which way they make sense. And to the degree that I can construct a continuity because I have a similar configuration as a self-reflecting observer that tells a story in the same terms using similar concepts, similar relational primitives and so on, I'm able to transport myself between the dream self and the self and the day, or also between the selves at different times in my life, at different ages in my life and so on. They don't have an identity beyond that. It's just a projection. So this identity would also not exist when I project myself through the Rouliat. The only thing that would exist is a translation. And then there is the question, are the underlying rules so similar that we can identify what is being translated? Because we would have to deduce it from first principles, I think. Well, okay, so one question is when you have your cognitive model of your life, the question is, and you say you're going to make a translation from one sort of level of one type of cognitive model to another, the dream model versus the waking model, the, you know, the 30 year old versus the 40 year old, whatever it is. It's about the language in which I write the model also. Basically the language of thought from which the model is constructed doesn't have to be the same. Well, right. I mean, okay. So, to pull it back to something that, a very practical thing that is this whole notion of computational language that we built to Mathematica, Wolfram language, et cetera, et cetera, et cetera. This is the, what are we trying to do there? What is the point? The point is what we're trying to do is we're trying to have a thing that takes all those infinite, that infinite ocean of computation, and we're trying to identify lumps in that ocean of computation that are relevant to us humans at this time in history. And that's basically, you know, that's in a sense the activity. It's a, it's a, it's, it's like, you know, it's a, it's a some kind of artist-like activity where we're trying to abstract from this ocean the things that are significant and important to us humans. Now what we're trying to do there is to make a computational language that cuts across a decent swath of different use cases of humans, et cetera, et cetera, et cetera. When you get to be more detailed, you can say, well, really, there's a computational language for the 30-year-old me. There's a computational language for the 40-year-old me. There's a computational language for this and that. We haven't seen those fine, you know, we haven't built those fine distinctions because it's more useful to have something that cuts it, that allows you to kind of merge between those kinds of things. But I think that that's this question of what does it look like when you go from the global computational language down to the sort of the dialect, so to speak, for the 30-year-old you versus the 40-year-old you. I think that's an interesting question. I would also like to say that I think in terms of the way that brains work and so on, and the way that we sort of conceptualize what we that brains work and so on, and the way that we sort of conceptualize what we're thinking about and so on. There's a lot of things I don't really understand very well yet in terms of sort of multi-way systems and multiple paths of, you know, our brains are full of, you know, a hundred billion neurons that are all firing and doing all kinds of things. Yet we have this perception that there is a definite thread of attention, consciousness, whatever we call it, a definite thread of experience that we go through. That's not really what's happening in our brains. It's what we construct. We have to, because otherwise it would not be intelligible. It has probably a feature of the languages in which the mind describes itself, that it has that nature. But the interesting question is, how is that language implemented? So for instance, we recently had Jerome Bussemeyer as a guest, among others. And Jerome had this insight that our mind and our mental states are best described using the formalism of quantum mechanics, not because he believes that our brain is literally a quantum computer, but because of the superpositional states in our thoughts and mental representations that then collapse into definite representations. Slightly different perspective that we could take on this is that we don't see the brain as a set of circuits like transistors that get us in a definite way from state to state and every of these states corresponds to an execution state in a symbolic language, but rather that the mind is a multi-way system in which we go through a multitude of potential states and then collapse. And this notion of the collapse is super important and interesting. Is this just the states where the branches merge in the branchial space or is there something more going on? No, I think that's an interesting and reasonable view of what's happening in the mind and the sort of the unconscious versus conscious, you know, in the unconscious, so to speak, there's all this stuff bubbling around, all these different paths being followed, and somehow our thread of attention picks out this one path and how that happens and you know what mechanisms, in other words the mind, I think it's probably a reasonable thing to think about it as it is like a measuring device that is going like a quantum measuring device that is somehow taking these different threads and conflating them together. Now I don't know, I haven't thought this through, you know, what, look, I think with, you know, we were having a conversation with a neuroscience friend of mine a little while ago. It's, there's a, actually, it's a, it's probably a long conversation with Terry Sinofsky, but somewhere on YouTube. The, and Terry and I were talking about And Terry and I were talking about the intermediate language of neuroscience. That is, there is the description of individual neurons firing and there is our computational language trying to describe at a high level what the overall import of our thoughts is, so to speak. But what's the intermediate language of neuroscience? What does it look like beyond the level of saying, oh, there are 100 billion neurons firing at a time or a billion firing at a time or whatever it is, versus what is the intermediate description language? And how best is that set up? And I think, to me, that's an obvious next frontier of neuroscience that goes beyond, yes, you can record from single cells, and yes, you can do sort of overall experiments about psychophysics and so on. You know, there's this intermediate language description, and I completely agree that these multi-way systems are a very interesting way into that question of what, you know, what is the intermediate language, and the idea that the intermediate language is, you know, transition from one definite state to another, that's probably not the right picture. I mean, it's probably much more of a multi-way picture and I think that that, you know, one of the challenges in a lot of fields is that, you know, physics has been, you know, a very successful formalized field. It's ingested lots of fancy mathematics. It makes use of all those things. Most other fields have not done that. And most of the people who work in the other fields really don't know that there's a big tower to climb in sort of the formalism of existing mathematics. I was looking recently at immunology, for example, where there are a whole bunch of things that I think are probably quite accessible, but they require a formalism that really is not the same kind of formalism that you would learn in kind of elementary mathematics and so on. And it's just, it's this question of the population of ruleal space by humans, so to speak. There are different parts of it, and sometimes you need to travel from one part to another. I think you were commenting on the fact that the things that we've been doing with our physics project and their relationship to physics that people have cared about before. One of the things that's been very pleasing, not entirely expected, although in retrospect it's not so surprising, is that there've been a lot of towers of mathematical physics that have been built in the last 50 years. Many of those towers have not really known on what foundations they should be constructed, but the towers have been built quite high and quite well. What has happened is that our physics project seems to provide foundations for many of those towers. And so even though people didn't, you know, might say people can see the attachment between the tower they've built and the stuff we have, and that makes it meaningful to them, even if they don't necessarily see all the way to the center of the earth, so to speak, and understand the full story. For example, you can use our methods, as I mentioned, to do quantum circuit optimization. You can use our models to make models for numerical general relativity, for simulating black hole mergers and things like that. One can do that without ever believing in our models. One can do that by just saying this is a good numerical method for studying black hole mergers without ever talking about the full ontology of our models. So it's sort of an interesting dynamic of that. That's the way that you attach sort of things people care about to, you know, as you change the paradigm, so to speak, there's an interface that you can create. And this is a kind of interface that I was not particularly, I wasn't particularly expecting that interface, that you can take the tower and you've got a new foundation for the tower rather than you have to build a new tower. And that's, and so I don't know. Yeah, I mean, I think in the case of neuroscience and AIs and these questions about sort of AIs thinking about themselves and these questions about sort of how one maps the notion of observers onto our experience of consciousness and so on. I'm rather enthusiastic about what this kind of formalism that we've built can let one think about. Okay, one of the big cheats in what we're doing is that we get to use physics. That is because our formalism applies to physics, we get to use the giant tower that's been built in the history of physics and we get to import the intuition from that giant tower to all these other fields. Yeah, but these fields are separate towers, right? That's an interesting thing that our towers are not built on a foundation for the most part in our intellectual traditions. And that's in part because the foundations were destroyed in some areas that never existed, but the Christian civilization radically destroyed our ability to construct a rational model of reality. And in some sense, our science started out with fake news. And also our societies, Lukyanov and I just wrote another book in which they describe that social media and their perspective has permanently destroyed the ability of our societies to make coherent models of reality. And there is... That's an interesting claim. after the end of modernism and then became a post-modernist society in a way, philosophy stopped having systemic models and looking for systemic models. And the sciences stopped having systemic coherent models. So this project of building this joint tower of Babel in a way was given up. And instead we just have lots and lots of different towers that are built on rubble. And they exist next to each other and they're often very similar. For instance, there's a lot of overlap between econ and computer science. And many of the interesting algorithms that econometrists have discovered are rediscovered in AI unbeknownst to each of the fields. Sure, control theory, reinforcement learning. Yeah, and Q-learning and things like that. Basically what AI is doing at the moment, for the most part, is to reinvent statistics on a different foundation and automating it. And there are other fields which have invented their own tools to deal with statistics and also physics in a way, also AI and neuroscience. We have tried to bridge between AI and neuroscience by sometimes locking these people into the same buildings, but they're still building separate towers there that are largely incompatible. Right. So how do you think that your ideas could be used as a foundation to towers that even don't talk to each other? Right. Well, I think that's the great thing is that first computation and now the Roulard are very radically kind of, sort of, you know, integrative forces. Because, you know, the whole idea of computation, the fact that we're building a computational X for all X, for all different fields, that's a very radically integrative move. The same thing happened 400 years ago, like when mathematical notation was invented, when mathematical science started off. There were lots of fields which, I mean, the integration was not nearly as big as it can be with computation. But I think that between, you know, computation leads to lots of integration. I think these multi-computational ideas lead to another level of integration. The thing that's particularly interesting about multi-computation is that whereas, with computation where you're going from one state to the next to the next, this phenomenon of computational irreducibility kind of limits certain kinds of things you can say. The big surprise to me in multi-computation was, that when you have an observer observing this multi-computational process, you end up being able to have kind of predictive things you can say, which correspond to, which are the transported versions of the core results of physics. But you know, coming back to your your statements about kind of the long arc of history of science, it is interesting that a lot of things that we're now looking at were thought about by theologians and philosophers 500 years ago, a thousand years ago, a couple of thousand years ago. And you are right that science basically gave up on some of these kinds of global statements. I think what happened is that the particulars of mathematical science were so successful that they kind of whizzed off into, you know, out ahead. And, you know, things which ended up being a discussion of sort of why does the universe exist or these questions about, you know, the platonic view of mathematics, these kinds of things. People didn't care about those things because they were off, you know, building steam engines using traditional, you know, using the tower that was being built from mathematics. And I think that that, I mean, I think it is very interesting to me, at least that the kinds of questions that we're addressing with even computational irreducibility and more so with multi-computation and so on, are questions that people have, you know, talked about 500 years ago and then stopped talking about. And so, you know, I do think the thing, you know, computation is a very integrative force on science and thinking. Multi-computation is another big integrative force which has the additional oomph that it gets to use a lot of the results we've got in physics. And so that, you know, I think that that's something very kind of powerful and valuable that, again, the fact that there is a common underlying framework that potentially goes across so many fields, lets you have interplay between those fields. If you don't have that common underlying formalism, underlying framework, you can't say, oh, I'm going to take something from physics and apply it to economics. I'm going to take this understanding that I have in meta-math physics and apply it to economics. I'm going to take this understanding that I have in metamathematics and apply it to physics. But if you have the same underlying stuff, then you can make those kinds of connections. I think that's the exciting thing that we have now. The fact that there is a, I mean, to me, just as, just as a pure sort of human doing all this stuff, the, you know, at some level, one's descending into a great level of abstraction, but I've been fortunate enough to have worked in a bunch of different fields, and so I have some level of understanding, not as much as I would like, but some level of understanding of lots of different fields, and so it's actually possible to see, given the common formalism, I actually have some chance to see how that sort of plays into these different towers. We're just starting this. We're in this strange situation because this sort of formalism has kind of exploded in potential applications. And so the current problem is, how do you organize that? Because I have a company that's been for the last 35 years successfully doing sort of very energetic R&D and creating lots of kinds of things. And I understand that ecosystem of how you make a company that innovates and makes lots of things. I think we got that one. After 35 years, maybe it took us 20 years to figure out how to do that, but we finally got to that. What I tried to do in the physics project, for example, is to apply the same kind of innovation methodology to basic science that I've tried to apply to technology development, and it works great. The only problem is that we've now got this kind of huge expansion of our product line in a sense that we're seeing, you know, oh, this applies to chemistry and economics and linguistics and so on. And so we're just launching this Wolfram Institute construct to try and have a vehicle for having sort of organized exploration of all those different kinds of things. So we get to kind of, you know, we get to live the Ruliad, so to speak, if we've got, you know, by, you know, understanding the, you know, the connections between these different kinds of things. Very briefly, an organizational question. We did plan to have this until nine minutes ago and I'm super happy and fine to spend more time. But what is your schedule like? Do we want to go until the hour? Another thing at the top of the hour and I really need to eat my dinner before that. That makes sense. So this means that we should wrap up in a few minutes. Yes. Yes. First of all, thank you so much for your time. I very much enjoyed this conversation. And what I'd be interested in, maybe is this question of what does it mean to make the measurement? Does your mind continue to be in a superposition state? It's just that your recording of it that you deal with and that you as an agent constantly used to interact with the universe is not doing this. Are you basically confined to a branch because you are constructing that branch or are you subjectively confined to a branch that actually is not a branch but it's still the branchial space? Yeah, I think that's an interesting question. I do not know the answer to that question. I mean, I think that that's a, that's, I mean, this, this question of whether clearly our brains have definite structures that try to, you know, maintain attention, that try to have a, you know, that try to sort of single threadify things. I mean, that's a, and, you know, that try to sort of single threadify things. I mean, that that's a, and, you know, in a sense, that's the story of attractors in any kind of system is you go from, from the many possible states down to the particular attractor states and so on. And, but, you know, to what extent that is a subjective phenomenon, and to what extent that is a, oh, you could make measurements of the individual, neuron firings to deduce that, I don't entirely know. And I think that there's a, as we work towards a more of a sort of a general observer theory, my guess is, well, okay, so as a practical matter, and we you know, part of my way of doing science these days is doing it in a sort of, in a radically open way, so we live stream a bunch of our, you know, research working meetings and things, so people can, if people are curious, you can see all the wrong turns that we've taken, so to speak. But one of the things we've been looking at is, OK, so in Wolfram Alpha, we have the world's most complete collection of units that people use to measure things. There are about 10,000 kinds of units people use to measure things. And we also have a good inventory of measuring devices, about 1,000 measuring devices. We know their characteristics. And so the question is, that's raw material for making a theory. Now we have to metamodel what we have there. You know, those 10,000 units, those thousand devices, what's actually going on? And a typical thing that's actually going on is let's say you're measuring pressure. There are a lot of little molecules bouncing around. You've got one paddle that's moving, so to speak, or one manometer liquid surface that's moving. And so this is a kind of a story of turning lots of degrees of freedom of the molecules into this one, you know, sort of more, you know, larger inertia degree of freedom. And so that's, but I don't know how that generalizes. And that's kind of the thing that we'd like to understand is what, you know, we've got the raw material to understand, you know, sort of what kind of a thing might measurement be. Now, for example, also when you look at quantum computers, there's a question of, you know, what's inside the quantum computer? You know, is it an ion trap? Is it neutral atoms? Is it, you know, some squid type thing with superconductors? What is it? And then how do you measure it? And what is the actual process? I looked at this embarrassingly long time ago, early 1980s. I looked at some quantum computing kinds of things and was interested in then, this cascade of measurement, you have a small quantum effect, you have, you know, this sort of big amplification of that, what's really going on? What's the qualitative story? What's the Turing machine analog that is the thing that sort of lets you kind of talk in generality about the measurement process. So anyway, I'd better go have my dinner because I've got to be ready for a discussion about something completely different at the top of the hour. Well actually, the question is how it's about metamathematics and the question is how completely different is it really? The answer is not as different as one might think but in any case. Thank you so much, I wish you a wonderful evening and thank you so much for the time that you spent with us today. It was quite inspiring and I hope that we both got some ideas out of it. I certainly did. It was a good conversation. Yes, very nice conversation. Thanks. Have a wonderful evening. Bye bye. Okay, bye. Also, I'd like to thank everyone in the audience who was here today. My apologies that we didn't get around to taking questions from the audience. I'm sure many of you had some, but I was not able to simultaneously listen to Steve and read in the chat. Is there, I think we are close in a minute, but is there any interesting point or question, Tanya, that you saw in the chat that we should be bringing up before we close? Oh, let me take a look at the questions. So there was a number, actually. Let's say, let me just go through them in order. One, I'm just looking through the questions. So what kind of predictions can we expect from this computational model was one of the questions. And I think that Steven partially covered it very nicely with the explanation of how the limitations of, or assumptions about the nature of observer imply the types of physics we're going to discover. But it would be nice to think about other predictions that can also be made. I suspect that the most important problems from the perspective of physics is not just how to find new data that we can explain, but how to explain the existing things. So how can we explain how relativistic physics emerges from quantum mechanics? Or what is it that quantum mechanics emerges over? Why is quantum mechanics the way it is? Why does it appear to us as observers the way it is? And these questions do not have conclusive answers in physics. There are just some vague candidates for these answers. And I think that what Stephen Volcram is attempting to do and what many others are doing in different departments is to identify these relationships, to identify ways to model them, to find answers to these integrative questions. There is a difference between describing the world as a multivariate system versus as a deterministic Turing machine. And by the states that are reachable, I think, are the same. At least, there are. And according to the normal definition of non-deterministic Turing machines versus determin the normal definition of non-deterministic Turing machines versus deterministic ones, the non-deterministic Turing machine is basically going into all possible states as once, which means that the rules by which you specify it specify constraints rather than the complete description of how you need to go from state to state. And this means that if you are free to ignore how long it takes in your substrate, how much complexity you can put into your substrate to go through all these states simultaneously, if you can do this in the same amount of time, then the number of steps that you take from A to B is going to be the same. But you're going to discover trajectories that you couldn't have discovered otherwise. Or another way to put it, if you want to describe physics or the rules of the physics of the computer game that you are in, and the computer that you're in is a non-deterministic game, then it's going to be a much shorter program, because you only need to describe the constraints of going from state to state, rather than covering the entire state transitions. Right. Another thing I was thinking about as I was listening to Stephen was, I wonder what the implications of this theory of multi-computation are for learning, specifically AI learning. So Stephen touched on this idea of not having a word for something and how the frameworks that are located in different parts of the ruleal system can require hundreds of thousands of paradigm shifts to get to. And so the question is, well, what is the nature of learning? Is this an additive process? Is it a process that necessarily implies that we lose something as we acquire a new distinction? How do we mathematically define it within the paradigm that he's working in? As a thing that I noticed about Steven's work, that he is acting as if he is giving a new foundation to the sciences, but the sciences are not acting as if they're taking it from him. And I think that's regrettable because I think he is doing excellent work. Sometimes I think that he's being treated unfairly because people compare him to the whole of physics that he is trying to displace with his work and not to individual physicists. I think that as an individual physicist and thinker he is extremely prolific, but one man, even with the help of a few hundred people that he puts into his company and directs to do things can only do so much. And it's, I think, regrettable that there is no direct link and interaction and entanglement that can produce a back and forth between his ideas and what's happening. Nonetheless, I think that the ideas that he is discovering, even to the degree that they're not being adopted, are also being discovered by other people. And I'm not sure to which degree our mind is a multi-based system. And if it is, it's probably a leaky one, because there is only so much complexity that you can store in the activation states of neurons. And so if you see your brain as something like the surface of a pool in which lots of waves propagate. And these waves from certain perspectives can be interpreted as particles carrying typed information and can be interpreted. And you can have a multivariate system in this way, to some degree, as an approximation. You could have a multitude of possible states existing and coexisting in parallel, performing multiple types of threats in parallel, that you just then interpret from a certain perspective of a local mechanism that exists in the brain and then translates it into speech or into a mental language, thereby collapsing the state space. But all these activation patterns, there's a certain self-saturation that you can have in the activation of the neurons. There is a certain information content in your brain at any given time, and that is bounded. And the multiverse systems are only bounded by the underlying mathematics that is, depending on the rules that you give, the state space grows or contracts or stays stable. But for the most part, it's growing. And in our mind, it's not growing. It has to remain stable. There is a boundary. So I think that we will eventually end up with different descriptions. Our minds will also only approximate multivariate systems if there are multivariate systems. Just a question, what is a better approximation? I had hoped a little bit that we could get even deeper into this question, but on the other hand, there is not everything that we can cover. And I would also invite people in the audience to link some of Steve's posts on multivariate systems, on the Voolyad, and on the preliminaries. They're very helpful to understanding what he means by the branchial space. That's an extremely crucial and useful concept. Yeah, so those links were in the description of the event on Eventbrite, and they will be added to the event program once it's on our website. Many of the questions were actually very, very helpfully answered by James Boyd, who joined us from Stephen. Oh, thank you, James. Yes, I don't know if he's still with us. I think he already left the call, but that was most excellent. So I think many of the questions have already been answered. Do you want me to pick up any more or should we wrap up for the day? Okay. Let's take one more and then wrap up. Okay, great. By the way, this recording will be made available on YouTube and you can find the link soon on our website. So here's a question from Jay. What is the most pertinent meta-analysis slash methodology to understand emergence? Potential as a state of reality seems to be crucial, and even the first state of anything. So how things emerge from potential and all the in-between states are modeling the reality. How logic allows slash structures things to emerge from potential seems to be what we can slash need to explore with our tools at a fundamental level through mathematical theorem like Bayes theorem, for example, because how prediction performs might be the meta solution to understand the architecture of things. So that leads to what is the necessity that brought things to existence? And what are the necessities of emergence? These are, I think, two separate questions. Not all philosophers would agree, because emergence is a very contested topic in philosophy. But rather than giving you the rundown, I take emergence to be a relationship between description systems. So you have a level of description, for instance, where you describe physics of your computer, and then you have a description in which you describe logical gates, and then you have a description in which you describe logical language being executed by the states of the gates as they are switching. And the relationship between those is a relationship of emergence. It's the becoming visible of patterns from a different perspective, from a different level of resolution. And these emergent systems that you are seeing, they are not real in the sense that they actually make up the ontology of what exists. They are only real to the degree that they are implemented by the ontology of what exists. They are only real to the degree that they're implemented by the things that ontologically exist, and they exist as abstractions in your own mind. So for instance, when you think of mental states, they do not exist on the level of individual cells. The individual cells interact with each other in a pattern that is coherent, because this coherence makes the organism more functional, and they evolve to be coherent. And coherent means that you can describe a low-dimensional function to characterize the behavior of this whole system. And this pattern that you discover, that is much, much simpler than the activity of all the cells, part of that is the mind, the mental states. And mental states are in their nature, physical laws, very specific physical laws, in the same way as software's physical laws. Software basically says, if you arrange matter in this particular way, for instance, as an iPhone, then the following things will happen. Every time, regardless of where you are in the universe, as long as these boundary conditions are met, right? And this is the nature of a physical law. So when you ask yourself, does the text editor by which I write this thing exist, what kind of object is it in physics? Well, it's a law. It's a lawful state. There is stuff in physics and you can describe and characterize what's happening there using these laws. But laws themselves do not exist as objects. They are the result of the way in which things are. And then this leads us to the second aspect of your question, the hypothesis that Stephen Balfrond advances and that I also find plausible is that things exist because everything that can exist exists. That's the easiest explanation because now it allows you again to describe the universe with a single bit or with none. Right, so it's the most efficient explanation of why we exist. And not everything can exist because it would have internal contradictions. Right, so the things that cannot exist are those things that can be described without leading to contradictions in any kind of language. And what we, for instance, discovered in the 20th century is that many of the notions that existed in classical mathematics, like stateless truth and continuity, lead into contradictions in the languages in which we describe them. And Gritter has shown that some of these contradictions cannot be avoided in any way. And the way out of that is to go to a slightly different realm than before, the finite automata. And it turns out that mathematicians never used anything but this when they computed and described things. And so the idea that Stephen Wolfram logically has is everything that exists is, in some sense, the interaction of all the finite automata. And this resulting system, this resulting structure that he chooses to formalize as a graph, or rather as a hypergraph. Hypergraph is like a graph. A graph is a set of locations and connections between them. In a hypergraph, those connections are not binary predicates over pairs of locations, but they are predicates over n locations. So they're over sets. At some level, they're equivalent, but many of the nice graph algorithms don't work anymore because they become very hairy. But by and large, it's the same thing. But it's a general formalism. You can describe almost everything with it. It's very powerful. And you can use this to take this as the foundation of your notation for the universe, and then in some sense describes the evolution of the universe as the evolution in these predicates over sets of the atoms of space, the locations. And the transitions that exist are all the possible regular transitions, all the possible rules that can exist in changing these things. And sometimes these regular changes lead to interesting patterns that will propagate with this hypergraph and to the formation of local order in the hypergraph. So you have something like a dynamic fractal that emerges. And the idea is that we live in some reason of a region of this dynamic fractal that has the necessary property to contain observers to give rise to them. I hope that makes sense. I think you're at the top of the hour. Yes. And I thank everyone for their attention. And I hope to see you all again soon. Thank you very much, Tja, for the organization. Thank you, everyone. All right.", '58.44674015045166')