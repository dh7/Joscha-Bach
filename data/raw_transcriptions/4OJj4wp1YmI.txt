('<center> <iframe width="500" height="320" src="https://www.youtube.com/embed/4OJj4wp1YmI"> </iframe> </center>', " All right, good morning everybody. So as you remember, Joshua in his first talk deferred a lot of questions forward in time. So in some sense this is the moment where they all collide back with us in the second talk, where the wizard of consciousness, as he has been called in the UK version of psychology today, but of course, the question is, whether it's the wizard of his own consciousness or the wizard of someone else's consciousness or the wizard of our understanding of consciousness, but we're gonna find out today. I'd like to read this article and find it out myself. Yeah, exactly. So, the wisdom of consciousness will today tell us really about his idea of how the architecture of mind, or of AI, of artificial general intelligence, which is one of the ambitions that Joshua has, what that architecture is all about, and how it's going to explain mind, brain, behavior, and consciousness. So all about, and how it's going to explain mind, brain, behavior, and consciousness. So Joshua, take it away. There's a problem in psychology, there. When you try to make a theory with many figurables and you perform an experiment, you're very likely to overfit, right? And this might be one of the reasons that psychology, when it decided to become positive with science, became atheoretic and no longer has overarching theories. So that now we have this big disconnect between theapeutic psychology and experimental psychology, where the therapist has to have theories with many free variables and how the mind works and experimental psychology is not delivering any because there is no theory there. Thinking is not a word in psychology. And it was one of the reasons why AI and the field started and later on cognitive science was started because when we make computational models we have an additional constraint beyond conforming to an experiment. The thing needs to be actually working. And so if we are able to reproduce a certain set of phenomena, we know that we have found a function that is able to reproduce that set of phenomena, which means a model of that thing, which means that eventually it's part of the theory and can explain how the mind works. And for me, when I got into AI, one of the biggest questions was, how is it possible that the system can think, not just think, but how is it possible that it feels? What does it mean for a system to have an emotion at all? So this leads up to the question, what is emotion in its very nature? What is experience? And what is the relationship between that, what is experience and what is the relationship between that what is experienced and the experience itself. Imagine you want to build a robot like data and Star Trek and you want to give data something like pain so data can feel something. How do you do this? You could start out with giving data information. So data cuts in looks at this hand, I have cut my hand. This is information about that fact, it's accurate and so on, but it's clearly not an emotion. So maybe you want to attach a balance to this. I've cut my hand, this is very bad, it's going to cost $1,000 to repair. It's also not an emotion, right? There's something else going on, which you need to do to turn this into an emotion. And I think what is happening is a global state change, a configuration change in data. Data is going to change in many dimensions. For instance, data is going to have a change in arousal. It's going to go way up in resolution level, which is going to go way down. It's not going to look at many details in itsousal. It's going to go way up in resolution level, it's going to go way down, it's not going to look at many details in its environment anymore, this thing is going to become the center of its universe. And this is also something that leads to a reinterpretation of the things around him. So for instance, the knife that was on the table and before was an implement for cutting cake now suddenly becomes a weapon and is dangerous. And he tries to get away from that state, which modulates him with negative reinforcement signals and so on. Pain tells you do less of what you're currently doing, right? So data changes into another agent. And this change that data goes through, this is, this configuration change, reaching from state to state, this is what we mean by these configuration changes that we call emotions. We would always be in the same state without modulation. We probably wouldn't call it an emotion, right? So it's about dynamic changes in the system that configure its cognition, and as a result, configure its relationship to the environment and to itself. So it's not a parameter inside of the system, but it's a parameter modulating the system on a global level. So I'm going to talk about which architecture we need to give it emotions and what components we need for this, how we model emotion in my own architecture talk about motions in general in AI models, and how we could use this to start modeling personality. So the basic perspective of general AI is that the mind is best understood as a kind of a machine. A machine is a computational system, and computation simply means that you can describe the system as being in a certain state space, and you have a transition function that tells you how to get from state to state, deterministically or probabilistically. And universal computation is the set of all those computable functions that can compute all computable functions and given enough resources. It's a totally fascinating concept because it contains itself a set of computable functions very easy to make a universal computer. So we are probably in this class of universal computers of course with very abounded resources, but the interesting thing is that we can also run particular kinds of programs. It's very trivial to build a universal computer. It's very difficult to turn it into a mind, because the mind seems to be in a class of systems that can make models of a very wide range of environments, possibly all the possible environments over which a computational system can make models when given enough resources. And our access to the universe is given by discernible differences. When we interact with the world, what we get is not matter or energy or color or sound. What we get is information, and the meaning of information is its relationship to change and other information. Intelligence is the ability to make models. And the purpose of all this modeling is usually a regulation to maximize rewards for the system. And this is where emotion and motivation come in. For a long time, AI was mainly focusing on handcrafted architectures. The classical cognitive architectures came up with a lot of boxes and arrows and tried to explain how the whole thing interacts. And there's a slightly different perspective where you think about the mind not being constructed like clockwork because there's not that much information in the genome that can define the very intricate clockwork that is our brain eventually. But it's probably more constructed like a cappuccino, which means you take a number of relatively generic ingredients and you mix them in the right order in the right regions, and then you have to mostly calculate until it forms the structure that you want. So basically you have a much simpler generator function with a lower level of complexity that eventually gives rise to all the architecture with all its details. So people think about general principles that you would need to build such a mind. It could be that what you need is a general recursive function of the docs and makers, plus a suitable reward system, where the rewards kick in in the right order, and form all the necessary complexity in that thing. So if you think about attention-based learning as a paradigm for setting up our mind, then differences in innate capacity of different minds are probably best understood as differences in innate attention. Schmidt-Huber and Kutter and a few others have a very radical perspective. So they think about very simple, very few principles that would be sufficient to generate the mind. And then you look at something like us, you see that's probably somewhere in the middle, so it's some hybrid perspective, which means, yes, the way our cognitive columns link up and the way our brain links up is mostly generated according to simple general principles, but there's also an enormous amount of biasing and pre-biasing of the whole thing to make it converge in a reasonable amount of time in your childhood, and into very similar results of convergence across many different individuals. So evolution has biased the genesis and generation of this particular kind of system. If you think about cognition, you can roughly structure it in the form of a layer, a reactive layer, a deliberative layer where we make plans and consider things, and a reflective layer where we optimize the whole system by looking at what we've done and what we should be doing instead. You can also look at columns of cognition, like a perceptual column, a cognitive processing column, an action column, and if you do this, you get to something like a grid, right? If you overlay both of them, which means we have reactive perception, we have reflexes and reflexive action. We have deliberative perception, planning and reasoning, and deliberative action. We have reflexive perception, meta-management, and the management of our actions. All right. And this idea has been generated by Aaron Sloman, who came up with the following architecture that he suggests would be a good perspective on how the mind works. He calls this cog path for cognition effect, and age cog path for how cognition effect works in humans. So you have a bunch of reactive processes and variable attention filter that decides whether something goes into the deliberative domain and becomes available to the attention, and then you have meta-management on top of this, and then you have your perception and action columns, which emulate desires to interact with each other. And they interact with logical memory, the activation of motives, a set of alarms that can interrupt the whole thing to make it possible that you get shocked or a tiger comes to interrupt whatever you're doing and reorient you. And you have a model of yourself, a personal self model and so on in this architecture. And for me this has been a struggle to think about these things, but then I realized that these pronouns are actually not nicely separated. Every precept perception usually involves actions because you might need to move your head or change your position in space and every action tends to involve perception because you need to reorient yourself and collect data from the environment to make these things happen. And the stuff in between actually are a lot of perceptions and actions that take place on mental representations. So in a way, the whole architecture is a lot more mixed up in itself. And if you want to split this up into different areas, you find that there are probably something like 50 different areas of the cognitive domain that might roughly coincide with the brain areas that you find in the neoportex. So if we want to understand how this works, we need to look at all testable architectures, not at isolated components. We need to find universal representations that are able to express the complete model of the environment with the value of reason about it. We want to have something like a single universal problem solving set of mechanisms that allow you to learn, plan, reason, to form analogies, to control your actions, to reflect on them, and so on. And you want to have a universal motivation system that can give rise to arbitrary goals. And maybe you want to have emotional affect in the system. So, what does it mean to have universal representations? Well, you want to have something like a spreading of activation thing that allows you to build hierarchical and distributed representations that in extreme cases can be local. So it becomes sufficiently discrete and low dimensional that you can apply analytical operators on them and you can perform symbolic reasoning. You need to be able to have pointers on this so you can organize them into plans and change these plans into other order where you can perform language on them. I'm sure you like my remote control. You don't have to walk with it. Yeah, that would be amazing. Why didn't you give this to me last time? I was laying here on the desk. Okay. Well, I thought you needed the exercise, you know? Yeah. So that's their dongle, you have to stick it to your computer. Now inside the, at the bottom of it. Okay. And on the side there's a slight switch to turn it on. Mm-hmm. Something happening? Something is happening. Yeah, okay, good. And the green button there in the middle, that's your pointer? Okay. Okay. What I don't like is that there's a battery so it won't blink. Let's see if I can... We have more batteries there. Okay, good. So this is... Let's see how this goes. Exactly. Okay. more about the research. OK, great. So this is just how this goes. Exactly. OK. So you have a bunch of operations that add to these representations that allow you to implement learning and categorization of planning, reflection, and so on. And then you want to get perceptual data from an environment. You want to also be able to perform actions. And you want to have a feedback loop between action and perception. And this feedback loop we typically call the environment. And then we abstract the stuff from which we act and which we perceive into a model of the current situation. And we translate the situation model into past situations, some kind of protocol memory that we can use later on to learn from that past, to generalize, and to frame the situations. And part of that thing is our self-model. So the self-model is the stuff that we always carry with us, and that is instrumental in producing our actions and perceptions. And other things that we have to find in this thing is the declarative memory, which is basically object abstractions that we gain by observing the world, and procedural memory that tells you how to do things and how things pan out in the world, and a frame that allows you to interpret the current situation as a particular kind of context which you're in. Like right now, I'm in this kind of tutorial situation where a bunch of people is listening to me. I'm expected to deliver a lecture that people pretend to follow. So this is a frame that allows me to predict the future and make sense of it, of the present. And I have an expectation horizon that tells me how the next one hour or so is going to pan out. We have plans that take place within this expectation horizon and if you generalize this, you basically have a work model along to a memory and a mental stage on which you can execute possible works. And then you generalize this, you basically have a world model, a long-term memory, and a mental stage on which you can execute possible goals. And then you need some action selection that allows these representations and on our environment. And the action selection needs to be informed by a motivational system, which selects motives and makes decisions. And the motivational system itself is directed by a number of urges which in turn correspond to drives. And based on the strength of these urges and drives and the situation of the environment that you measure, there's a bunch of modulators like the arousal, which tells you how much action readiness you should have versus contemplation. When the arousal is high, you want to turn down the resolution so you are faster in your cognition. If you want to do complicated planning actions, you want to turn down the resolution, so you are faster in your cognition. If you want to do complicated planning actions, you want to turn up the resolution. This parameter tells you how much cognition you should spend on your updating on the environment versus on internal things. If you have an environment that is changing dramatically and these changes might potentially have a big impact on you, you want to spend more of your resources on updating the environment. And if you are setting up a startup company and your programmers are meant to spend most of their cognition internally, you don't put their backs to the doors and you make sure that nobody walks through, right? So they don't need to update the environment very much and don't feel threatened by it. Are you claiming that these are components you have to explicitly represent or can some of these be implicit? I think it makes sense to represent them somehow. And usually the best way of doing this, it will be through this explicitly. In our architecture as we see, there are rather explicitly represented, which means that different signal types, different neurotransmitters, which correspond to many of these parameters. We also have the selection threshold, which basically tells you how much your motor should be stable at any given moment. And there's a bunch of famous cognitive architecture, like SOAR and like RH, which are classically cognitive architectures that tend to focus on cognition as something like an isolated problem-solving capacity, and they don't look at this modulation, or they don't look at the connection between age and environment very much. And so if we want to explore these things, we need to build an architecture that allows this. And I've built such an architecture and written a book about it, which is based on the psi theory, the theory originally by Dietrich Donner, German psychologist, who tried to come up with a cybernetic reinterpretation of psychology. And unfortunately, most of his work, never bothered to publish this in AI, and also didn't do it in English. And I found that especially his theories on emotion and motivation are super useful for AI, so I took it on me to translate them into our context. So basically, we wrote an architecture, it's a project which took place over many years, there were several dozen people involved over the years and we implemented agents in it which put episodic learning in all direct behavior and emotional modulation, and top-down, bottom-up perception, simple planning, and the execution of hierarchical plans. There was a toolkit that people could use. Originally, we started in 2003, so it was all Java and XML and plug-ins to the Eclipse IDE. And we did load-out perception because they had to connect this to cameras. And we did control and simulation experiments and see how the emotional changes and so on happened out of the time of poking electrodes and spreading activation networks. And then we had different kinds of simulations, for instance, genetic simulations, where we would read the agents for having suitable parameters for a given environment. Or where the agents learned to make sense of their environment and communicate each other about strategies on how to survive there. He made experiments with expressing their emotional states in computer animations, and he also used this to control simple robots. And it came up with a number of simulation environments in which these agents lived. And then at some point we decided, okay, let's do this again, but better. So we wrote this, because we did this in 2012. Everything was done in browser interfaces, and we wrote the architecture in Python. And now we have a company in Berlin which is called MicroSci Industries, which is run by a number of students that were involved in the original effort, and we've written new tools to work with this that can work with very large representations, and we use this now to control industrial robots. Yeah, so most of our port is still open source that you can download if you look up Microsoft Industries. So let's go to motivation. If you want to model motivation, you must think about how do goals come from human beings. There must be a general mechanism that gives rise to all possible goals that a human being can have. And obviously we have a large multitude of goals, so you cannot enumerate all the possible goals and when you are born into this world you usually don't know which goals are attainable and available, right? So when I was born into this world I didn't know that computers would be available at some point if the goal of learning Python or Basic or something like this was not present in my brain. And in order to get interest in such things there need to be more fundamental things that give rise to such highly concrete and specific goals. So what is the general system that can give rise to all these interests that we have? There's a difference between motivation and emotion. Motivation is what reflects our needs. It gives rise to goals and what are our behavior. And it does not have to be associated with emotions. You can have a motive without being emotional about it. You can say, I'm hungry and I want to eat something, but I don't have an emotion, I just do this. An emotion is something else. It's a modulation of perception, cognition, and action. And it perceives its valence, whether something is good or bad, or what it feels like to you, from the motivational state. And it receives the objects of the emotion from your cognitive system. So when you're jealous, it's a negative effect that is directed on a particular kind of mental representation, namely that you may or may not have a partner that may or may not be going astray with somebody else, and so on, right? So it's a very particular kind of representation that you need to construct in your mind in order to have this very particular kind of negative affect. And the emotion often also leads to an affective expression, so it's something that can be recognized from the equivalence of the hedonic states of the body by other agents and by the cell. So if you look at the motivational system, all our goals are to satisfy or avoid the frustration of one of our needs, which are demands of the system that we are in. And these needs manifest as urges. And that has to do with the selection of one of the motives that is associated with satisfaction or avoidance of frustration of a need. And once we have selected one of these motives, it becomes an intention. An intention is a motive that we have raised to something that we want to, that we committed to satisfy. And our drives are physiological, social, or cognitive. Physiological drives are things like hunger and thirst and pain awareness and rest and cold and worms and so on, and hundreds of them. Even things like hunger and thirst can be decomposed into hunger for salty things and sweet things and so on. And they are active to a different amounts at different times and they give rise to basically urges to make certain things in the environment real. We have similar, actually, a bunch of social urges which structure our interaction with others, and we have cognitive urges. The physiological drags kick in when the autonomous regulation of your body fails. So, for instance, when it gets very hot, you start to sweat, and maybe you're done, right? Maybe you get cool enough again. And if that is not sufficient, you might get an urge to move into the shade. And the physiological drives to that, that lead to your physical survival, survival itself is not an urge. It's way too complicated for this, right? It's the emerging result of all these basic drives. So if you manage to eat, to avoid pain and injury, and get enough rest and so on, you do tend to survive. If you look at the social drives, one of the most important ones in most people seems to be affiliation. Affiliation is the need basically to belong, to get okayness signals from your group, to tell you, you're one of us, you're part of this thing. This thing is decreased affiliation need, satisfied legitimacy signals, basically when people tell you that you're part of the group or give you signals like smiles or cuddles and so on, and it's decreased by the opposite, by anti-legitimacy signals. And this allows in a group for non-material reward and punishment, you don't have to give this individual actual resources to reward for cooperation. You can use virtual currency like smiles and frowns, right? So without diminishing the fitness of the group, you can reward or punish people depending on their degree of cooperation. And there is an external legitimacy, which is the acceptance by the group. There's also an internal legitimacy, which kicks in and nobody is looking. And people call this, for instance, honor. So you have an internalized sense of what you should be doing in order to be normatively acceptable. And the conformance to these internalized norms is what we call internal legitimacy or honor. And the other drives, for instance, dominance, the desire to get to a higher status, nurturing, the desire to reduce the suffering of others, and romantic affect. The cognitive drives are competence, uncertainty reduction, and aesthetics. In our model, competence is the desire to become more powerful, to become better at satisfying your needs. And things like learning how to play an instrument is largely driven by competence. It feels good if you become better at something, if you become more powerful. And competence can be a standard, so it's related to a particular task or problem. There's the general competence, which is how good you are in general to solve your problems, how many risks you can take in a particular task or problem. There's the general competence, which is how good you are in general to solve the problems, how many risks you can take in a given environment because you are able to cope with it in general. So this is your unspecified coping potential. And there's something like an effect-oriented competence. You see this in small children that may throw down the lamp in delight at the fact that they were able to create such an amazing effect, large-scale effect on the environment. And it's probably the same thing that makes grown-up babies delighted in fireworks and Jignazkar races and explosions. It's just the ability to perform a huge change on the environment gives you a sense of competence, and it's intrinsically rewarding. And there is uncertainty reduction, which is a need for exploration. It's not exactly the same thing as novelty seeking, because if people were intrinsically novelty seeking, everybody would be doing mathematics like crazy, because mathematics is an unending source of novelty. The reason why most people don't do this is because they don't anticipate to be able to reduce uncertainty when they do it. Most people have learned that when they do mathematics, uncertainty will increase. And there's a frustration of that need. And the mathematicians are exactly that subset of the population which have learned that when they go to mathematics, there will first be a new source of uncertainty which they will then reduce. And then they find new uncertainty which again they can reduce. So it's an unending source of pleasure. Also, aesthetics plays into this, and there are types of aesthetics. Basically, one is stimulus-oriented. There are certain stimuli, like certain body schemata and so on, and certain harmonics that we find intrinsically pleasant because we are by it, too. And then there is something like absolute aesthetics, which is about finding better representations. So whenever we discover a better representation of something and this is eventually what most aesthetics, which is about finding better representations. So whenever we discover a better representation of something, and it's eventually what most of the music is about. So when you listen to the late Beethoven string quartets and so on, the aesthetic that you get to see there is very similar to aesthetics in mathematics. It's structural discovery. You listen to this music and you suddenly see the structure and the music plays out and you see oh my god it's so high stakes is he going to is he going to make the right decision is he going yes yes this is how it works but in order to get there you need to build all the structure and it's very similar to mathematics in mathematics is completely discovered in music you have more degrees of freedom so you construct more, but eventually both are about fractals. Okay, so all our possible goals correspond to at least one demand. And from our needs we get urge signals, which kick in as soon as the need gets strong enough, and they lead to a craving. So for instance, when we are hungry, and suddenly things that are edible start to pop out from the environment, from our occupation. We have many vivid memories of edible things and so on and try to locate them in the environment and construct plans. It does help for learning, so it's useful for directing your attention on certain things and then perform attentional learning on them. And of course, it frames our decision making. So there's a strong direct memory perception and action for all of these. The important thing here is pleasure and distress. A change in one of your demands is reflected in the pleasure and distress signal and the strength of that signal is proportionate to the amount of change per unit of time. So, for instance, when you are not thirsty and you drink a little bit of water, you're not going to derive a large amount of pleasure from this. But if you climb a whole mountain, and you're very sweaty and very, very thirsty, and you get something to drink on top of this mountain, and you have a huge delta in the satisfaction of that particular need, it feels extremely pleasurable. So the strength of this pleasure signal is proportional to how much distance you cover in that, between target and current value in a certain unit of time. And the purpose of pleasure and distress signals is that they give reinforcement values for your behavioral procedures and episodic sequences. And so you can learn from them and define goals, which are appetitive goals that you want to obtain, or perversive goal situation that you want to avoid. So you have, for instance, if you take this first example, you have something like a tank. This tank has a target value, which is achieved when this tank is full, and you have a current level, and this distance here is basically your urge indicator. The larger this distance is, the bigger your urge to drink becomes. And this allows you to learn to create an association with the goal, right? Your beverage of choice or the situation, and you also create negative associations with situations that you should be avoiding when you're thirsty, like going out to the desert. So the goal is a situation or an action that affords to satisfy a need. An immersive goal is one that moves frustratingly, and all behavior is directed on satisfying an appetitive goal, avoiding an immersive goal. And the needs are predefined, but the goals are learned. They depend on your particular environment. So physiological needs, we talked about them already. They have survival as an emerging property, social needs, and cognitive needs. And for each of those, we have this target value and the current value. We have this earth strength. And the change in your need gives you a pleasure signal or a discomfort signal, depending on which direction this change happens in. And there's also basically this thing tells you how long you have until you are dead or until the window for satisfaction closes. And this is your urgency. So it's the difference between the urge strength, which is deviation between the target value and the current value, and between the current value and the tank being completely empty, which tells you how urgent is it that you satisfy that need. So, we're looking now at constructing a simple learning system, so we basically have here now our demand indicator, which is given by this urge, and then we have a change indicator, which tells you how much this changes over time, and when the change happens in a good direction, you get this positive valence indicator, which is a pleasure signal. Or here you have a displeasure signal. And then you create an associator that for the positive valence indicator creates associations to both situations. And here for the negative signal, you create an association to the aversive situation, right, to those situations that you want to avoid. And you don't only learn the association directly to the situation that's situation, right? To those situations you want to avoid. And you don't only learn the association directly to the situation that's currently in your log model, but you can also create strengths in the connection of that thing to previous states in your mind. So basically you learn a chain of sequence, a sequence of events that tend to lead to the goal situations. And this gives you nice automatic scripts, especially if you overlay this over many, many situations. You start to generalize over these scripts, and this allows you to construct simple plans. And you have many of these automatisms, and they don't even need conscious intervention. So sometimes you might write a paper or listen to music or whatever, and suddenly you find yourself in the kitchen in front of the fridge. You ask yourself, how did I get here? And you just followed an automatism because you became hungry. And even though it was somewhere below your attention threshold, it triggered a sequence of actions that you were not properly aware of. So whenever we have an urge, there's an autonomous regulation. And this one doesn't leak in or doesn't work. We need to have a deliberative mechanism that chooses the goal out of the goals that you have. And then it follows through on that. So it works basically by if the need becomes active, the low autonomous regulation is possible, you trigger this urge signal. And then you try to satisfy this urge opportunistically at first. For instance, I might be working on something, and my wife sneakily puts a sandwich next to me while I sit on my table. And at some point, I look up, and the sandwich is gone. Because I got hungry in between, and I satisfied this urge opportunistically without disrupting what I was doing. And if that sandwich wouldn't have been here, probably some mechanism would have come in which would have disrupted my work and made me go to the kitchen and make myself a sandwich, right? So if no opportunistic satisfaction is possible, then we need to make a decision, right? And we make this decision by looking at how strong is the urge, and we subtract the current suppression, which basically a bonus that the current active urge has, because it has some significance by itself. We check if this is larger than the strength of the current leading motive, the thing that I'm currently doing, that writing a paper. And if the urge strength is nice, the suppression becomes stronger than the strength of the leading motive, then I try to recall a strategy to satisfy this urge. And when I find such a strategy, I calculate my motive strength as the expected reward for this action multiplied with the urgency, multiplied with the competence, and divided by the cost of the strategy. So the more costly it is to do this thing, the less effective reward I will get for this. And this will weaken the strength of my motive. If I don't find a strategy, then I will try to construct a plan, which takes more deliberation. And if no plan is found at all, I increase the need for exploration in my given environment so I can find such plans in the future. And once I've done this, I turn the strongest motive into my leading motive, which is my current intention, my current leading intention that governs the majority of my behaviors. So why do I need to pick one? It's because I have only one body, and most of the actions that I perform in the environment go through this bottleneck that I only will be able to perform one action at a time, which means I have to commit to one leading strategy, even though I have many others in the background. Now this is a simple algorithm that I can directly implement in my cognitive architecture and see where this gets me. The needs are characterized by a bunch of parameters. There's the strength of the need, which is the relative importance compared to others. There's the decay, which tells you how often you need to replenish this need in the absence of things happening. So for instance, from you how often you need to replenish this need in the absence of things happening. So, for instance, from time to time you need to sleep again, or a lot of people need a lot of affiliation. So if you're an extrovert, you have a stronger need for affiliation, and you need to replenish this more often than when you were an introvert. So you seek out social stimulation more often if you're an extrovert. Then you have the gain, which is the effect of the satisfaction, how much do we get out of satisfying this particular need, and the loss, how much do we lose when this needs gets frustrated. And all young people have differences in this principle, this vector of affectation, some people get a very strong pain signal when they fail in social interactions, others get a relatively weak pain signal when they fail in social interaction. Some people get a very strong pain signal when they fail in social interactions, others get a relatively weak pain signal when they fail in social interaction. Some people get a lot of satisfaction when they succeed in a social interaction, but don't feel much difference in this. And this basically leads to people that are more or less abrasive and their social interactions are more or less introvert. So a different configuration of the need parameters leads to different personality traits. We don't act on the needs themselves. What we act on is the anticipated needs. Because when you get the pleasure or pain signal, the action is already done, right? When you feel very satisfied after having eaten a sandwich, the sandwich is gone. When you have an orgasm, all the necessary actions have taken place in the past. So the thing that motivates you is not the reward signal itself, but the anticipated reward. We act on models of all rewards, right? And these models of all rewards, we could call them purposes. So our purposes, in order to make them accountable to each other, need to form a hierarchy, because otherwise we are not going to reach our goals and satisfy our needs. It's an important thing. You might, for instance, decide to become slivered for the summer so you're on your eat and you're not that fat and ugly and you also want to eat chocolate and these are two different behavior clusters that are somewhere in conflict and you need to make them accountable to each other in a certain way which means you need to organize them into a hierarchy and the degree to which you're successful in organizing your needs into a hierarchy is what you could call internal integrity, right? And this hierarchy of purposes doesn't have a single solution. I remember when I met Marcel in my younger days, I was very unsatisfied with reading him because this famous hierarchy of needs that he comes up with, this pyramid of needs, didn't convince me. First of all, our needs are clearly not in a hierarchy. They are all on the same level even though they have different strengths. It's not true that you first of all eat before you do a revolution. Sometimes you do this the other way around. So sometimes you do the self-actualization before you do a more base thing or the other way around. It depends on the current strength and opportunity, right? It's not that there's a strict hierarchy that allows you to work on one level, then go to the next level. This is not how it works. And the other thing is, the things that you put into this pyramid are actually not needs. So self-actualization or survival are too complicated to be defined as needs. The basic needs are much more simple. And now I realize Maslow's pyramid or hierarchy of purposes, of needs is actually a hierarchy of purposes. And you need to construct such a hierarchy of purposes in your neocortex as a model of your needs, right? Survival is a purpose. Helping your children is a purpose. Helping your society is a purpose. Helping your children is a purpose. Helping your society is a purpose. And you make them accountable to each other and you form a certain structure. And this structure doesn't have a single valid solution, there are many possible solutions. Some people do art to eat, and some people eat to do art. They might end up doing the same things in the same proportions, but for different reasons. And this hierarchy of purposes controls the way we interact with each other, much more than our personalities, because when we interact with each other, we do this based on shared purposes, not on shared needs. Okay, so this anticipated reward is what determines our actions. That's probably implemented via the prefrontal dopamine system. And the actual rewards determines the reinforcement. So this determines future anticipated rewards. So this is the learning signal, and this is the action signal, in a way. And the innate reactions are not only caused by the present rewards, but by these anticipated imagined rewards. If you expect something to happen, this also can give you pleasure and pain and direct your cognition and action. So when you want to implement this, basically it is something like that. So it's a particular type, whether it's physiological, social, or cognitive. It has value at a given time point. It has an initial value in the architecture. Then it has the strengths of the corresponding merge, and the urgency, which is how much time you have left to satisfy it. The pleasure signal that is associated with this particular need, the pain signal associated with this particular need, and then we move on in time. Here you have the weight, which tells you how strong it is relative to the other needs. And then the decay time, how often do you need to replenish this thing, your gain and loss, how strong do you react to satisfaction and frustration, how strong do you react to imaginary satisfaction and frustration. So when you imagine this as an anticipated thing, and then, for instance, for social urges, when we imagine we will give an amazing presentation and everybody will love us, this might give us more pleasure than when we imagine that we will have a good meal later on and this will make us less hungry, right? So you will not satisfy your need for hunger very much by playing games in your mind, but maybe you can satisfy your social needs by playing games in your mind to some degree. Then we have the sensitivity to the pleasure and the sensitivity to the pain. And we have the time for the pleasure takes to decay because the different types of pains and pleasures that we get are implemented in different ways chronologically. And we have the sensitivity to the pleasure and pain for immediate satisfaction. We get the urge as a function of the wait and the change in value at a given time point and we get the urgency as the wait and the remaining time. The value depends on what this thing was before, then how much this value decays over time automatically, and how much gain we have at a given moment, and how much loss we have at a given moment, based on our interactions with the environment. And the same thing for imagined gain and loss. The pleasure is a function of the change in a given amount of time at a given moment, and likewise the pain. And then you have the pain from depletion. If your meat is almost depleted, you tend to get increasing pains, and also when you get very hungry, this creates a particular kind of pain by itself. But then if we want to implement this in an AI agent, we also need to define an event. An event with respect to a motivation is related to a consumption. Consumption means that a need is satisfied or frustrated. And this gives you a particular reward, and it happens with a particular kind of certainty. And then you have a particular amount of skill to deal with this event, to achieve the consumption. And there is something like the remaining time, or it could be also distribution, which tells you when you expect this event to manifest. And the consumption itself is related to a need, gives you a particular reward per unit of time, gives you a total reward that's summed up. So when you eat, you have a certain amount of pleasure that you continuously have at every moment, or in discrete events, whenever you swallow., you have a certain amount of pleasure that you continuously have at every moment or in discrete events whenever you swallow, and you have the total amount of pleasure that the meal is going to give you. And you have the duration over which the meal takes place, you have a maximum reward that the meal can elicit, that's probably a cap, how pleasant the meal can be, and then there is a discount that you put in depending on how far this is in the future and how much this decreases your expectation of this being a thing that manifests in your life. Let's not go into all these details. I can go on to the publication where we document all these things. So this tells you how you generate this reward signal. The reward signal is typically something that plays out as some curve that reaches a duration. There's some S curve going on, typically, when reward manifests, because initially, you have a lot of satisfaction. And then if the satisfaction flattens out, then your need is almost satisfied. And you need to calculate when you consume something how much of that you consume at every time point, what the delta is for that. When you deal with anticipated needs you need to project them into the future, so you need to have a discounting function based on your certainty of the distribution of the expectations of the things in your future and how much less interested you are in things when they are further in the future because they are less likely to manifest due to possible branching expectations in your environment. And you have an expectation that you will eat in 10 years from now. Yes, you have that expectation, but there are so many things that can happen in the next 10 years, they should probably discount that meal accordingly. So this is roughly what you need to implement, motivation in cognitive architecture. Let's go to emotion. For me, most of the interesting studies of emotion started with the work of Paul Ekman. Ekman had discovered that there are some people which are super good at detecting lies, like pretty supernatural lie detectors. Many of these people are detectives, policemen, judges, and so on. So people that are used to looking at faces a lot and correlating this, with whether these people are lying or telling the truth. And so he wanted to know what is it that these people are doing that I'm not able to do, and he started filming these interviews with high-resolution cameras, and he was looking at the facial expressions of these people in a lot of detail, and he saw lots and lots of micro-expressions, which are only there for a very small instant in time, and then go away to realize that people have difficulty controlling their micro-expressions and there is a logic in which they do this and he could reverse engineer this and then he started studying the emotional expressions themselves and he put electrical clamps to his face to simulate all the facial muscles and took pictures of them and classified the facial muscles and when they were in which emotional states they would be excited and why not, and came up with a system to code facial expressions based on the muscular innervations. And there's a very interesting thing that he discovered in this, is you can decompose faces into some basic components of the expression, and then you can add them on top of of each other and you find that you always get a valid facial expression. Facial expression is basically a sum of particular expression dimensions. So you can for instance increase a pain variable and you can increase an arousal variable and there are certain correlates of this in your facial expression and you will see that along these two dimensions you always get a valid facial expression that people are able to infer. And this is basically culture invariant. There is not that much fundamental difference between cultures, but there is difference in which emotions different cultures seem to be appropriate to express and how useful it is to express certain emotions in a given culture. But the basic emotions can be recognized across cultures. So people may make very similar interpretations when they look at a particular facial expression. And it also holds across species. So other primates have very similar emotional expressions to our own. And you don't even need to have something like a biological agent, you can also recreate the stiff robots or computer animations. So how does this work internally? There's a bunch of models which are called appraisal models which have originally been developed by Martha Arnold and Richard Lazarus. And the idea is that emotion is a competent appraisal of your relations to your environment and your motivation and your cognition. You basically have a mapping between certain states of your motivational system and your environment and the relationship between yourself and the environment and map this to internal states which are these emotions. And Klaus Scherer has tried to make it more systematic and came up with the stimulus-improvisation checks. So you have several stages in these checks. You have an innate sensory motor check, which is pre-attentive and automatic. Then you have something that is learned on top of this, and then you have a deliberate thing where you actually reason about the situation and adjust your emotional state accordingly so these changes take place, and then you go from the relevance of that thing to the implication of that thing and how well are you able to cope with the situation and what's the normative significance of this, how is this going to play out for you in a social environment. These things are evaluated one after the other and lead to different components in the emotional response. The thing that was missing in my room from Klaus-Jeris's work is the nature of that internal thing. So basically, this is a black box, which is a mapping from stimuli to results. So you have a certain number of criteria, like you learn that your grandmother has died, your grandmother was important to you, this was a very sudden change, you were not aware of this and so on, you will need to take care of her estate and all these things, you tick them in the box, in the questionnaire, and you have strengths of these stimuli from one to five, and then you have an emotion that corresponds to this. But what happens when you don't have that emotion? What means you tick all these boxes and you feel, oh, there's nothing. How would you represent this in this model? Right there, it's possible that something else entirely happens, and this cannot be represented because it does not represent this model, the functional implementation of the emotional state, right, and the actual architecture that's behind it. Emotion is not just a mapping of environmental stimuli to a particular thing. An emotion is a process that takes place inside of you and that you classify as a region in the space of positive configurations, right? So if you look at the conceptual analysis of emotions, or Tony, Paul, and Collins have written a classical book about this, and they say that emotion is a valence reaction to the consequences of events, to the actions of agents, or the aspects of objects. And you can classify our normal emotion terms according to this. So if you look at the valence reaction to the consequences of events, you can be, for instance, displeased or displeased with the event. And you focus on the consequences for others. If it's desirable for others, you are happy for them, or you resent that they get this. If these actions are undesirable for others, depending on whether you like the others, you might be gloating or feel pity. And then you focus on the consequences for yourself. When the prospects are relevant, so it's directed on the future, you have hope and fear. If the prospects are relevant, you have joy and distress. And when your prospects, like hope and fear, are confirmed, you get the satisfaction or the confirmation of your fears, respectively. If your prospects are disconfirmed, you get relief or disappointment. Then you look at all the actions. You manage your action to the actions of agents. You can approve of those actions or disapprove of them. When you focus on yourself, you feel pride or shame. This is when you are this agent. When you focus on another agent, you feel admiration or reproach. And then we have a combination of this well-being and attribution. So we get to gratification and rewards or gratitude and anger. And then when you look at the Venus reaction to the aspects of objects, you have liking of these objects or disliking. And so you have love and hatred. This is obviously American. Germans don't love objects. But we don't love Coca-Cola, because I think in our language, love means to experience a sense of shared purpose. And I don't have a sense of shared purpose with Coca-Cola. Yeah. Yeah. Well, you might, but where's your celery? With a particular drink. Mm-hmm. Right? No, I completely objectify the Coca-Cola, and I disagree. Relationship there, it's not a moral subject to me, right? So I'll get to this in a moment. In the PC theory by Dietrich Doerner, he starts out with an affective space, which I think is much better to express what happens internally in an agent. And this affective space is a dimension of valence, which tells you the appetence or aversion of that particular state that you are currently experiencing. Then you have the selection threshold, which tells you how dominant your motive is, how stubborn, intense you are on it. And then your arousal, which is the equivalent of your unspecific syntactic syndrome. And this is based on a theory by Wilhelm Wundt. It's very similar dimensions. Wilhelm Wundt is one of the original psychologists before behaviorism kicked in, and he already did sonic experiments, so it's not psychoanalysis stories. It's relatively solid stuff, and he put people into a lab and measured them to detect emotions. And this theory, these dimensions that Wundt came up with, have been rediscovered by at least half a different, I have a dozen different psychologists in the last century, independently of each other. So, you have this pleasure-displeasure dimension, attention-realization dimension, and it comes from also dimension in William Brunsberg. And these are not all the dimensions. In obscetheory you have at least six dimensions. You also have this resolution level, which tells you how deep your focus is on things, but it's shallow. Then you have narrow versus wide, and you have the securing rate, which tells you whether you check your environment or your internal cognition more. And basically these three are attentional dimensions, and these are the valence and and the RASL dimensions. And your affective state, the state in which you are in a photo-emotional state basically, is a configuration of the system with these six dimensions. And so the modulators are RASL selection, special security, special resolution level, then also you add your estimate of competence and certainty, which tells you how well you can cope with the environment, and how anxious you should be, and the pleasure and distress you feel of the valence. And your affective state is an emerging property of these modulators. So you don't have to put in anything additionally. It's just emerging over these modulators. If you build a cognitive system that is modulated to think like a browser, it's an actually special resolution network, and has competence and certainty needs and so on, you automatically get similar emotions as you would have in humans. And if you implement different modulators, you will still have something that an observer will interpret as emotional states, even though they're not completely human emotional states. And we see this when we observe animals, we see they do have emotional states, but they're not necessarily human emotional states. We're able to make that distinction, right? So the affective state is an emergent property of the modulation, and our higher-level emotions are directed affect. There are affective states that, in addition to this, have an object that is given as the content of our cognition. And the purpose of the emotional modulation is that they control the widths and the depths and the biases of our mental operations, and they control how our mental representations are formed and selected in the given situation by shifting us in a particular direction and priming us, and thereby they modify our memory perception, our memory, our recall, and our planning and actions of action. And the purpose of the whole thing is to make us more efficient, right? It reduces the complexity of cognitive processes. And this leads us to the question, does AI intrinsically need to have emotion? And this depends on how much they reduce the complexity of the cognitive processes. If this is a linear reduction in complexity that you get by applying these modulators, maybe you don't need it, because we can afford to buy a computer that is linearly faster, but we cannot make a brain that is N times bigger than the brain that you're currently having. Right? It's also a trade-off because of these emotional things. If you increase your arousal and reduce your resolution level, there are certain answers that you're going to miss. You get faster to these answers, but you're not going to get all of them. So you train, for instance, a firefighter to not be emotional when the fire breaks out because you want this person to be in full deliberative mode instead of reacting based on impulses that are very short-sighted, right? So for the kind of environment that we are in, we typically want to avoid most of the extremes of emotional modulation, because we are no longer living in an ancestral environment, the tigers are coming all the time. So these modulators that we implemented in the SIDIC model, and you could play around with this, and the things that we implemented in the microsite is these primary modulators allow us to build what we call aggression, which tells you the type of lag response, how much you approach this thing in your environment or retract from it. And then you have the attention modulator, so resolution, level, suppression, and secure and right. These modulators interact with each other. So depending on the strength of all your needs, this influences the arousal and the suppression. This leading mode, if it's very strong, increases the suppression. So if you have something like a very strong urge, like you're very hungry, you are unlikely to do something else before you have eaten. This avoids motive oscillation. And the strong leading motive also leads to a lowering of the securing rate. So when you're very hungry, you focus on getting to food instead of focusing with a lot of environmental permission. And your general competence is very high, so you're generally good at satisfying your needs. Your suppression gets increased because you can afford not to check your background very much, and your aggression gets increased because basically you can afford to assume that you'll be fine when you address the thing that audience is not going to buy. When your competence for the current task is high, then you should also check, lower your securing rate. When you look at the urgency of all your needs together, it increases the arousal. The urgency of the leading motive increases the suppression, so you focus on that thing exclusively. When your exploration need is high, you increase the securing rates. You check out the environment more, and you decrease the suppression, because you don't know whether the thing that you're doing is the right thing. And when the obstacle prevents satisfaction, you might also increase aggression, so you get rid of the obstacle. And the browser itself reduces the resolution level and increases the suppression. So these are the dynamics of the modulators. It's basically a cybernetic system where these parameters influence each other. Each modulator has parameters that are individually different. So it might have a baseline. For instance, you might have a baseline for your valence. How much pleasure do you feel when you're being left alone? And you have a range. In which area does your valence fluctuate? And a volatility, what does it take to make you fluctuate a lot? And then the duration, how long does it take to get back to baseline? And these parameters form your temperament. So for each of these modulators, you can in principle have these parameters or the equivalent. It can be implemented in various ways in the organism, but practically it's usually done with particular neurotransmitters. And these modulator parameter configurations lead to different temperaments in people. Temperament is slightly different for personality. So let's look at emotions as direct effect of modulation. For example, fear. Fear is characterized by anticipating aversive events, this gives you a negative valence, plus arousal. And anxiety is that it's different from fear, because anxiety is not the anticipation of the aversive events, it's an uncertainty about the future, and this gives you the negative valence, plus the low competence, which means you're not sure that you will be able to deal with the uncertain events that are going to happen, right? So anxiety feels slightly different from fear and has a different implementation. Anxiety can turn into fear as soon as you get a concrete object. As soon as this uncertainty is reduced and you know that this bad thing is going to happen, anxiety is going to turn into fear. If you compare anger and sadness, anger is an emotion where you have a perceived obstacle, usually an agent, that prevents you from reaching a motivational or relevant goal. And you cannot really get to this goal anymore, this gives you a name of convenience. And you have a sanctioning behavior, so you basically make sure that this agent doesn't do it again. And the relevance of this goal is basically redirected into the sanctioning behavior. And you have high arousal at low resolution level and high action readiness and high selection thresholds. You become very stubborn. And you might be doing things because of these modulations that are against your own best interest, right? You're modulated into a particular thing, but you're more action-ready and more aggressive than you normally would be. Yeah, I mean, you are mapping folks' psychological categories of emotion into these systems. How do you know that's the correct map? Maybe there's a better mapping if we understood the right thing. There is no correct emotion. The emotion there's a better map being understood. There is no correct emotion. The emotion itself is a perceptual gestalt. So the emotion categories are formed in every culture by pointing at stuff. It's not that anger is a natural kind. It's not that you have a particular kind of anger model in your brain. When you say that somebody is angry, you point at a region in their space of motivations and behaviors, and say, for instance, Tom could not hand him his paper on time because he was so angry. Or Tom handed his paper in much earlier than everybody thought because he was so angry. This is a four-dimensional space. What we mean by this is this is a person that had high arousal and there was something in front of reaching one of their important goals and this gave them higher aggression than they normally would have and so on. So in this sense these folk psychological concepts are what we are talking about, it's what we agree on when we say anger. But the practical implementation can cover a very wide range of possible states. So what you're describing is a high dimensional space. Yes. Where there may be some attractors. Yes, basically regions in that space. When people talk about an emotion, it's a perceptual gestalt that they form over a region in that modulator space. And the emotion words that different cultures have are different. So there's this famous thing that Germans have the word schadenfreude, and which is a particular kind of emotion about the misfortune of others. But when Americans discuss the word schadenfreude, they usually don't say, oh my God, these evil Germans. The reaction's more like, oh, there's a word for it. And I mean, and- And the evil Germans invented it. And I mean, in the And the evil Germans invented it. Yeah, but the Americans have bloating, for instance, right? But for instance, Jewish has a word called the pride in the achievements of your offspring. There's a particular word for that. And it's a category that basically every other culture is knowing too, but they don't, might not have a particular word for it. So basically, you can't take this area in your motivational and emotional space, in your modulator space, and say, okay, let's find a name for this particular category and cluster it. So these emotional terms like anger, it's a clustering that takes place. What about, let's say, something like arousal? Is that a...? I don't think that arousal is an emotion, at least in none of the cultures I know, it would be used as an emotion. But is that one of the dimensions of your...? It's one of the dimensions. So what you could say, if you want to liken it to particle physics, that is stuff that is made from simpler things, so there are emotions which are the combination of several more basic emotions that are put together. And then there are emotions that are, these basic emotions, you can take them apart into things like arousal and valence. But arousal and valence themselves are not emotions yet. Right, they are below this, so they are like quarks. They don't occur independently as emotions. But arousal is probably itself an emotional property of the intellect. Well, arousal is a modulated property, it's not an emotional. In fact, arousal is at least three different things. If you look at it in more detail, because we have adrenaline and noradrenaline, and, what was it, cortisol. So there are three different types of arousal that determine how alert you become, how action ready you become, and how bad it feels in your stomach. So the arousal that we feel is a compound of this. And we didn't resolve it in that detail in our model, because it's very difficult to do this, and you would have to do a lot of empirical work. But when you want to actually model how people react to a given situation, of course, we might need to take arousal apart into these components. The literature on arousal is really quite confusing. There's no general consensus that there is one kind of arousal. Yeah, in this model, it's, the ascending reticular syndrome. Now, I think the point that Josh is making, which goes back to these traditional models, is emotions are just points in this case a six-dimensional space. Effective states, right, which are the elements of emotions. So if you want to understand them, you must understand that the dimensions are the regulator. And I think now what George is doing is just placing the specific emotion in that high dimensional space. Yeah, it's basically to give you an idea on how this maps out. We don't need to agree on exactly how every culture does this, right? But I think this culture is mostly what you and me would agree on, what anger is. If not, speak up. So sadness is about the manifest prevention of all conceivable ways of reaching your active, relevant goal. But there is no relevant obstacle anymore that you could remove to get there. So for instance, your child has died and there is nothing you can do about this. There is nobody you can sanction for it and so on. So in this situation you can only retreat from the situation, you have low arousal, you have high negative valence, and you have decreased action readiness and you might seek support from the environment. Let's look at pride. Pride is basically a situation of high competence, which leads to a low securing rate, high internal legitimacy. And blackmail coincidence is high external legitimacy, because it very often happens when somebody just prays to you. And joy is a state of high arousal, with a high perceived reward from satisfying a demand. And bliss is a high perceived reward signal from satisfying a demand, but low arousal. Difference between joy and bliss is mostly in the arousal dimension. And this is related to, for instance, you often get joy when you do something that is connected to physical exertion. So you want to race, stated you're in, it's probably not bliss, but joy. And you listen to some live poetry, you have low arousal because you need to have high resolution to do this. So the situation is probably not so much joy as bliss. But if you want to implement this, you want the data as a minimum and maximum to define the range. A particular level is in at a given time, and the baseline, that is, it's normal range if you leave it alone, and a certain volatility at a decay time. a certain volatility and a decay time. And we define how this changes. And we do this, I have the combinations of this. The variance is a combination of all the different pleasure and pain signals that you receive in a certain moment or over a given time. The implementation of arousal is done by combining the urge and the urgency in the right way. And the aggression and regression is implemented with the general competence, which is the task-specific competence that you have for the currently active goal, the general competence, and a combination of them. Then the viewer would basically visualize the emotions in real time. a combination of them. Then we built a viewer that could basically visualize the emotions in real time. So here we have the physiological needs, here we have the social needs, here we have the cognitive needs, and this is how they interact to form the different modulators. These are the compounds, so this outer ring here is the valence, and in here we have the urge strength, so the general urge strength. And here we have the urgency. And all these things interact to form the configuration of the agent at a given moment. So now we can go and model personalities. We can take the motivation parameters to model different personalities. And we can take the motivation parameters to model different temperaments. How would you go about this? So a model for personality that we have in psychology is the big five. The big five model has been derived by taking a lot of words that describe personality-shaped properties in people from a dictionary, and then organizing them, and realizing that it can be organized roughly into five dimensions, and these are openness, conscientiousness, extroversion, introversion, agreeableness, and neuroticism. So what this roughly means is, openness is your appreciation of art and your ideas and your curiosity, it's also somewhat correlated to IQ, conscientiousness is how much you are rule-following and disciplined versus chaotic and spontaneous. Exaggeration tells you how much you tend to seek stimulation from your environment versus avoiding it in your introverted. And the agreeableness tells you how likely you are to try to please your interaction partners in a social interaction of conversation and your writing system tells you how stable you are and how robust you are against failure. So we can model this by the person with a high need for evaluation would score higher in openness and extroversion and agreeableness and a person that is higher in competence would have lower agreeableness. For instance, that's a person that is higher in competence would have lower agreeableness, for instance. That's a person that gets more out of winning an argument than about pleasing the other in that argument. And so it looks roughly like this. Imagine you take your physiological, social, and cognitive needs, and for some reason psychologists ignore the physiological ones. There are probably very interesting differences in whether people are hungry all the time and this affects the way their cognition works, or are extremely high in libido. But most of them have these social and cognitive urges that we measure with our questionnaires. And then basically each of these is characterized by the gain, the reaction to satisfaction, by the loss, the reaction to frustration, and the decay, how often you need to replenish this before it has run dry by itself, and the relative strengths, compared to the others. So neuroticism can be modeled by having a stronger experience to negative emotions and having a strong loss on competence when things in your environment don't go according to plan, and uncertainty reduction, and also maybe a strong decay on these things. Conversely, if these things are low, you will have low neuroticism. If you look at extroversion, that might be modeled by having strong gain from affiliation. So you get a lot out of the social interaction. And also a strong decay on affiliation, so you need to replenish it often. And maybe also a weak negative reaction to frustrations in your social interaction. So you don't get a lot of pain out of a failed social interaction. And if you have the opposite, if you basically have an extremely strong loss in affiliation, maybe a small decay in affiliation, you will tend to be more of an introvert. Openness can be modeled as strong gains, especially on the cognitive needs, and agreeableness is the result of a strong positive and negative reward for evaluation and a lower gain for competence. And conscientiousness might be the result of having an extremely strong loss of competence when something doesn't go according to plan. If you are a person that gets a lot of gain in the competence when things go to plan and don't have a lot of strong loss on competence you get bored easily if you follow through on plans. So my wife has extremely high conscientiousness, she wants to plan the world out and make out the future, make sure that things happen the way they were planned. For me it's the opposite, I get terrified when this is the case. So a nice thing in the Big Five we one free variable, which is much nicer, right? It's much faster model. Why not just one free variable? Why so many variables? And the reason is that, of course, there's a big five model, there are many things that are difficult to model. For instance, there is a difference between shyness and introversion. A shy person is usually not somebody who's intrinsically an introvert. It's a person that would want to get something out of the affiliation, but doesn't dare to because they have such a strong loss on affiliation if something goes wrong. And maybe also a stronger loss on competence if something goes wrong. So there is a stronger anticipated pain in the case of a failed interaction, but there is also a strong frustrated need for interaction in a shy person versus an introverted person wouldn't get anything out of the interaction in the case of a failed interaction, but there's also a strong, frustrated need for interaction in a shy person, versus an introverted person wouldn't get anything out of the interaction in the first place and would rather want to stay at home than interacting with people. And if you do this with a single variable, you cannot resolve this difference. So the idea is that the big five are not natural kinds, they're just clusters that you get when you have a reasonably configurable motivational and emotional system, and then you vary the parameters within normal ecological spread, and then you start clustering your individuals and then you get your big five. How can we evaluate such a model of motivation? One solution is games. So, interesting games where you construct something like this, or start out with Space Invaders, but these games don't give you many opportunities to branch, right? It's mostly about avoiding to die. Such a game, and you want to have a game that is more open-ended. So, something like this. Space Invaders was roughly the same time as the first multiplayer dungeon adventure, and later on you get much more advanced multiplayer dungeon adventure, and later on we get much more advanced multiplayer dungeon adventures that have also been designed to satisfy many, many different player types, personality types. So the goal is to offer something for everyone in these games, which allows us to study different types of behaviors in the same game, right? And the first larger work was done by Richard Bartle. He took people in such a multiplayer game, 700,000 of them, and compared their strategies and behaviors and he decided that there are different clusters of people and the dimension that he came up with is that there are socializers, which mainly play this game to interact with other players. Then there are killers, which also like to interact with other players, but largely in a competitive way. And then there are the explorers, which want to see as much as possible of the environment. And then there are the achievers, which try to maximize their skills. Right? And if you ever played such a game, you have found similar traits in other people and maybe in yourself. And now the interesting thing is we can map this into our design model. So in this dimension, we have affiliation. How much do you want to interact with others? How social are you? And here we have uncertainty reaction in this dimension. This is exploration. In this direction, we have competence. So it's pretty natural. So we used this model on a number of different games and we found that it's possible to classify people based on what they do in multiplayer online games. Into socializers, supporters, killers, gamers, explorers, and hedonists. So depending on whether you are into aesthetics or exploration or competence, into dominance or nurturing or affiliation, you get different clusters in your preferred strategies in the game if you evaluate the behavior of the players over a long enough time. of the players over a long enough time. So how does the self get influenced by our emotion and motivation? In the last talk I talked about how we derive our models from sensory patterns by organizing them into precepts and motor scripts, and the precepts into more complex features and these are abstracted into objects. Eventually we have a globe that is made from objects and processes and maps and they are combined into mental simulations. So we live in this world of the mental simulations that are generated in our brain. And over these simulations and objects and processes and maps and water actions and complex features form concepts. Concepts are basically address space of these things. So we can manipulate them and recombine them into new things. And then you can also learn a symbolic language which hangs in the thin air between speakers. And the problem of natural language is to take this conceptual domain, which is something like a hierarchical, fuzzy distributed graph, and map it into a discrete string of symbols with a stack depth no more than four. And the solution to this is probably the space of all natural languages. Right? So there's an evolutionary paradigm in which we can develop and learn languages and start sharing these concepts. Where does the number four come from? That's an experimental thing. Basically, when you think about how many relative clauses you can process reliably, you probably can do seven. But you also have to talk to other people. At some point, they will look somewhere else. When you talk to them, you notice this, you would use the stack depth of your sentences. So this is a very rough number. But basically, you only have a very limited stack of parsing these grammars. That's the idea. You want to minimize that. Sure, but the point is, what's internally generated is again compressed in terms of expression, right? So you might have in that sense different stacks that you're looking at, not necessarily just collapsed into one. Yeah. But okay. Yeah. So we have this particle conductor which performs the affine relation and modeling and it maintains the short-term protocol things and procedural memory and the biographical memory which are derived from the short-term protocol. And when you think about what did I do in the past, this is composed of entries in the short-term protocol which are transferred into this long-term protocol. And what happened in the world is all the things that you abstracted from your short-term protocol, things that you read in the news, things that happen every day, that you put into a procedural memory of what happened in the world, which you generalize into sequences. So this is an election cycle, this is a season, this is the year, and so on. How years can pan out. So we have a primary model, this is the agent and its environment. We have a secondary model, which is about the interaction of that agent with the environment. And we have a tertiary model, which is the functioning of that secondary modeling. How do we make that model? It's typically what we call the self. And consciousness in this paradigm largely serves as a model of our attention. And the control, the self-regulation depend on the learned function representations in our cortical structure, and we have a number of biases on what we pay attention to. For instance, most of us are extremely good at recognizing faces. And I had two colleagues in my career who could not recognize faces. They were cognitive scientists, they were highly functional people, one of them is an excellent musician, not cognitively impaired, but not able to tell students apart by their faces. So they have to do this by their hairstyle, by their voice, and their height. And they also don't pick up on facial cues. They don't realize when they talk to the students about how to generate lattices, that the student is long tuned out because they don't read their facial expressions. And I think the reason for this is not that they have a particular brain defect, but they lack a particular brain defect that all the others of us have, which means an extraordinary amount of attention to faces. If you have a bias that rewards us for looking at faces in particular, then you walk through a crowd, you obsessively look at faces, more than you think about sex. It's crazy. And as a result of looking at all these faces all the time, we form very intricate models of what these faces are expressing. And what we see in these faces is not really the face. One of my students told me she has a superpower. She can see faces at power outlets. And I said, well, it basically happens to most of us, right? And she said, oh, there are no faces in power outlets. And I told her the dirty and dark secret. There are no faces on people, right? There's only geometry. The fact that you see a thing with an attention state, an emotional expression, and so on, that's a major trick. Semantic information overlaid on this perceptual state. It's really cool when you think about it, right? There is no face on a person, it's only geometry. And the face is very distinct from geometry. And you don't see the actual emotion of that person. What you see is the state of your emotion model of that person superimposed in this direction when they're looking at you, right? So you don't see whether this person is grim or happy or something, you see your model of the state of that person superimposed on that, right? Fascinating to think about this. Also, I suspect that emotion expression haven't evolved as a convenient readout to our emotional states, why would they do this? I think something slightly more nefarious has been going on. When we are social agents, we want to model others, we will use cues to model their internal states, of course, right? So we look at their posture to gather information about their arousal. We look at their gaze direction to see what they attend to and if their cognition is internal or external and so on. We look at facial cues to see what their valence is, whether they experience pain or external and so on. We look at facial cues to see what their valence is, whether they experience pain or pleasure and so on, and then we gather what kind of emotional cluster they're in. And it doesn't stop there. This other agent knows that we are looking at them. Evolution figures out that we are looking at them. So they evolve tricks to gain your perception of their emotion. So suddenly, they know they expect you to show a particular thing, and it's not conscious. It's basically what happens in the course of a notion of trajectory in a social species. So they evolve something like a default readout for emotional states that you are meant to think that they are in. So now you train to look for the differential between the default state that you would expect them to be in in a given context and their actual expression. And you start resolving this one, this small delta, and this leads to a co-evolution which leads to a differentiation of the emotional expression. So I suspect that emotional recognition, and especially with respect to facial expression, is a result of an adversarial evolution of emotional deception and emotion recognition. But this is very hypothetical. I don't know how we could test for this, but probably we can with sufficient simulations. So attention is a mechanism for directive learning, and the experiential access happens via an intentional protocol. And the structure of our self, of our internal regulatory hierarchy, determines how we experience our emotions. So to which of these affective states do we have experiential access and what is the relevance of that experiential access? This determines how we experience our emotional state. And the object of the emotion requires a representation and relevance of that emotion. For instance, you cannot be jealous if you think that your partner making out with somebody else is not relevant, right? You also cannot be jealous if you don't think that you have a partner who is making out with somebody else. You need to have these two things, right? If one of these components is missing, you cannot tell us. So in order to have these elements, you need to have the correct social urges for the social emotions. So you need to have abbreviation, and romantic affect, and libido, and dominance. And if you don't have that, then certain social emotions will not be present. And present, there are people which are aromantic, people which are incapable of falling in love. This doesn't mean that these people don't love or don't have libido, they just don't fall in love. And typically these people are incapable of jealousy. So this fixation on a single partner seems to be the result of romantic affect, which is a particular dimension of social emotions that are not all people have. Similarly, there are people which are asexual, these are people which can often fall in love, but they don't have any sexual arousal when they think about other people, and are not sexually attracted to other people. It's not that they are repulsed, it's just absent, it's an absence of a particular kind of drive, and affects a small percentage of the population. So the existence or non-existence of these particular needs is something that is different in different people. And because on the social urges, the selection pressure is not as strong as in the physiological urges. If you're never hungry, you probably won't have offspring. But you don't need to mate very often in your life to have offspring. Social emotions don't have the same selection pressure, so you would expect more variants in them. If you think about love as opposed to romantic affect and libido, there's something else going on there, right? So when I say I don't love Coca-Cola, I mean Coca-Cola is not sacred to me. When we talk about love as we truly mean it, it's about discovery of the sacred and the other. Now that sounds very voo-voo and romantic, right? But it simply means the sacred is a system of meaning above the level of my ego. My ego is a function that integrates expected reward over the next 50 years or so. And there are things that I do in the absence of expected reward in the next 50 years or so. And this is typically what we associate with values, right? A value is what makes you go for stuff in the absence of expected reward. You do this anyway because it's the right thing to do, which means it serves a purpose that you put above your ego. It's a system of meaning that is more important than you. And when you see somebody else serving that system of meaning that is more important than you. And when you see somebody else serving that system of meaning that is more important than you, you can help them without expecting anything in return and not be confused. If you only have your ego as your top level function, which means if you are a sociopath, like about 5%, 6% of the population are probably sociopaths, then you can only have transactional relationships. In order to give something to somebody, that thing, this action to be rational, you're not being confused, you need to expect something in return. And often you get something in return, but it means you have to maintain a reputation system and suitable incentives. And the problem is reputation systems don't scale above a few hundred individuals, right? About 150, 160 individuals, you lose track of who did what when. Which means if you have a tribe that you organize only with a reputation system, then this tribe is not going to scale beyond 150 households, right? After that, it falls apart. The cooperation becomes very weak. How do you organize a tribe into something that is non-transactional? How do you get non-transactional relationships? You do this by having purposes, regulation goals above the level of the individual. And for instance, religion are tools to create shared purposes, to make purposes converge above the level of the individual, right? So that is the discovery of shared purpose. It's the discovery that somebody serves a purpose more important than their ego, and it's the same purpose as you are serving above your ego. So if they want to do something to serve that thing, you should help them. Because where they want to go, this is where your universe wants to go, too. It's now suddenly very natural and very easy to do this, right? And love depends on that other one not being corrupted. The other one serving that purpose truly and honestly. Corruption means that they actually serve something else. That you are not serving. So love is basically the emotion that allows a lot of transactional interactions. And love requires shared purpose and an implementation of this need for internal legitimacy, the performance to internalized norms. So there is a theory by Robert Keegan, psychologist from Harvard, who looked at personality development as something like a succession of reverse engineering your own mind. And I don't think it's very accurate as a developmental theory, because I have different kids and they didn't develop exactly in the order as he suggests, but I think philosophically it's a very interesting theory. So it starts out with this observation when you have an infant. What they experience is pleasure and pain in a very pure sense. It seems that when this baby cries, everything is pain. There is no anticipation of future pleasure, it's total. And this baby is joyful, everything is joy, everything is beautiful, and the whole universe is pleasure. There is no anticipation of future pain. And it changes quite abruptly, right? And at some point, this small mind starts to generalize and integrate this and realizes, oh my God, there is a succession of pleasure and pain, and my pain will at some point be over, and my pleasure will at some point be over, and they get less excited about these things, and more based on their anticipations. And then they learn that pleasure and pain are not the universe, but they are aspects of the things that they encounter. And then later, they realize, oh no, they're not aspects of the things I encounter, they're aspects of my reaction to the things that I encounter, right? So you learn pleasure and pain is a property of the self, not of the environment. And then they learn I am not pleasure and pain, in the experience of pleasure and pain, I am the thing that wants to get pleasure and pain or wants to avoid this, so they identify with their goals. And when they do this, they're typically two or three years old, and then they cannot reach a goal, they throw a tantrum, they get extremely excited. And it's because they cannot identify with anything beyond this goal. Basically, subjectively, they feel they're dying and they don't reach that goal, because this I is the index of the currently active behavior program. And they don't have the behavior program trained that could switch between behaviors. Instead they have a behavior program that wants to reach that goal, it cannot let go and if they reach it then this behavior program can die down, go to sleep and something else will emerge. But if it cannot reach it then it becomes super urgent because it's really afraid of dying. So it's not small children testing the patience of their parents, it's really afraid of dying. So it's not small children testing the patience of their parents, it's really small children not being able to let go. Even if that thing is physically impossible. It's very interesting to observe this in your kids. And so at some point you realize that goal is not what I am, goal is what I have, and I can have different goals. And then at some point you make this inference, other people have goals too, and I can change them. This is what Keegan calls the imperial phase, when your baby starts directing others and push them around, age three and four and so on. They make others do their bidding to the largest extent that they can. And then they realize, oh, so I'm not, my goals, I have them, what I have is beliefs. What I am is beliefs, so there is a certain way the world works, and there are different kinds of beliefs, and there are beliefs that are right, beliefs that are wrong, and how do I pick up the right beliefs, I need to look at my environment. So my peers have beliefs that are more right than mine, and when I'm able to understand the beliefs of my peers, especially those that are high ranking, so we say this in this regard, it's basically how much weight should I assign to their beliefs in case of conflict. Then I'm done, I'm done when I'm able to emulate the beliefs of my environment. And this is what Keegan calls stage three of the development of the self. This is basically when you are able to approximate the beliefs of your environment and think that the right beliefs are given by your peers. And this is the stage that most people are in. And only when you discover epistemology, you discover, oh, there are laws or ways to discover truth, and the weight of the confidence must equal the strength of the evidence. And this is completely uncorrelated with what other people think to be true. You get agency over your beliefs, right? Whether mathematics is true does not depend on what other people think to be true, you get agency over your beliefs, right? Whether mathematics is true does not depend on what other people think. Whether your country will crash or whether the apple store will go up or down is completely independent of what other people think is true. There's an interaction with their actions, of course, because of their beliefs, but objectively whether this is true or false is not related to whether it's right or wrong. And then you realize, oh my God not related to whether it's right or wrong. And then you realize, oh my god, people mostly live in the right-wrong algebra. And you should be living in a true-false algebra instead, right? And right and wrong and true and false are very distinct categories. So once you go from right-wrong to true-false, you make a step where you get to Keegan 4, you become self-authoring, because you now have agency over what you think is true. You know why you think something is true. And you can make a decision about whether you should continue thinking that that thing is true or not, right? And it doesn't stop there. The next thing is that you disidentify from your values. You realize that you are not your values, but you have your values, and different people have different values. And if they have different values, it means that completely different behavior can logically flow out of them. So suddenly we realize that history is not the struggle of large groups of good people against large groups of bad people, and you, God's good graces, have been born among the good ones, but rather it's a struggle between people with different systems of values, some of which are more or less sustainable than others. Right? And so at this point you become self-modifying because you get free to choose your values to understand the values of others. I had a discussion with Bjorn Merker who unfortunately is not here anymore. He felt that it doesn't really stop there. At some point you can also make decisions about the structure of yourself. So basically transform the type of mind that you are. Okay, but I think I'll leave you here and stop this lecture for now because my time is more than up. That's it, thank you very much. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. All right, okay, another question. Thank you very much. I was wondering, how do you deal with conflicts between the two types of drives? So what happens really when you have a particular drive, say you are hungry, and you make a decision that you want to go to a shop to buy something to eat and on the way from the shop you get very thirsty and at some point the thirst becomes normally stronger than the hunger so you drop what you're doing you go back home because you realize in my fridge I have something to drink. This is not a good strategy right because it means that you now wasted your effort of going to the store, at least half of that effort and you should not be doing this and that's why we introduced this suppression thing, which makes you more stubborn based on your current goal, which means you give a bonus to the currently active behavior once you've committed to it. And this is an adaptive thing that you learn in the course of individual development, how stubborn you should be to reach most of your goals. Right, it's a small heuristic that makes it possible. And otherwise, you basically go by, in our model, by an expected reward thing. So how much do you get out of satisfying this particular need, multiplied with the cost, which makes the reward smaller, the effect of reward, and the risks involved, and the opportunity cost that you lose basically by giving up and the opportunity cost that you lose basically by giving up on the other things that you could do in between. This is roughly what you want to approximate in any positive architecture. Jordi? A couple of others. In your models, how to abstract these into more general and more abstract needs or processes that can be used for this way, but concatenation of different needs or predictions of future needs that are not just the basic ones? Yeah, so the basic ones are the physiological, the social, and the cognitive needs. And right now, what we came up with is a set of needs that seems to be authorable to us and is sufficient to explain the different behaviors. And what you should also be able to look at is lesions of this. So basically, do people deviate in their goals systematically in a way that would suggest that there's a particular need dimension that is absent in them. And you can find this, for instance, in aromantic people versus asexual people. These are different needs that are absent in them and you can explain it by really one need not being implemented. you", '48.70968747138977')