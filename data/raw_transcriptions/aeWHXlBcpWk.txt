('<center> <iframe width="500" height="320" src="https://www.youtube.com/embed/aeWHXlBcpWk"> </iframe> </center>', " While everyone gets seated, I have a nice anecdote to start on your next panel, which is actually, I mean, has this very narrow, I would say, defined title, what is intelligence? I mean, if you ever wondered, you will learn now. And while you are getting your seat, there are things going on kind of beneath you. So if you have used an airplane recently, you know there's a new announcement. They are always cluttering more things into the announcement. So the announcement is, if you drop your phone into the inaccessible part of your chair, please don't try to get it yourself. Call the flight attendants. And that's exactly what happened to someone. So someone's phone is down there, and Aki is now crawling inside and tries to salvage that. But that might, of course, ruin the technology, so cables might be... That's not my phone. Someone has here, that's a brand new, that's an iPhone 10. If someone wants it. Well, I will keep it. So don't wonder if things kind of get astray here. Nevertheless, we will start because time is precious and we have only one hour, which is a short time. Could we have the slides, maybe, to start? Maybe give people also time to sit. There's plenty of seats in front. Come in. Telephone. So, our session, which I feel really honored to moderate, has the title, What's Intelligence? And something with a Spaziergang, which is obviously a word that's hard to translate. And with me are two incredibly, I would say, esteemed practitioners and scholars in that field that I'm totally amazed to have the chance to talk to. So first of all, there is Josh Bach. Josh is both a computer scientist and really one of the leading philosophers in cognitive philosophy at MIT Media Lab and others. I will give him the chance to say more about himself. Second is Chris Mansfield, who is a practitioner, comes from the game development side and is dealing with the physicality, if I may say so, of what we might think of being intelligence. So I mean, intelligence might not just be software, it might be much less like a simulacrum, a simulation that runs, which is probably what we will be arguing with Josh about, or it might be much more, it might be really tied to our physical being, the body, as people call it. I think that's the first interesting thing. So I mean, the idea that intelligence can be somehow tied with into machines is quite old. I mean, this quotation that I put here, the firm famous psychologist Skinner, I haven't that I found in a book that was actually by Wittgenstein. So it's really old. But it's an interesting question. I mean, it is actually not so interesting if machines can think it's rather much more interesting. And I totally agree with that, if people can. So next slide, please. Let's see if that works. Let's see if that works. I mean, Jean-Pierre Dupois is known to many as being kind of also this contrarian, dialectic philosopher in Stanford, and clearly criticizing that what we are doing is all wrong because what we try is to find mechanized models of the brain, kind of the automaton, rather than thinking of what would a human machine actually or an intelligent machine actually look like. Ben Evans from Andriessen Horowitz, here at the Mechanical Turk. What we do now is actually totally unrelated to artificial intelligence. What we actually do is we use people to make machines simulate quite boring behavior that people are very good at. For example, facial recognition. I mean, that's behavior that people are very good at. For example, facial recognition. I mean, that's something that people are really brilliant at. People recognize faces, computers are bad at that, so we use people to teach machines, which is far from being anything like intelligence, is the argumentation of Evans. While Reed Hastings has a much more positive view on the development, in his view, Netflix in 20 years will not so much be any longer concerned by entertaining us, but rather our artificial children. And by that, I would really start giving the panel to the people who actually have to say things on that. I mean, the simulacrum idea, is that important? Is it something that we should worry about? Is it really true that we might find ourselves being caught in a simulation and that becomes now apparent through AI? Maybe Josh? Okay, I'll start, I guess. First of all, I don't think that I'm a leading philosopher. Philosophy is a weird field. Maybe the last good philosophy that needed to be done was done by Darwin and some interesting things happened then at the intersection between mathematics and philosophy with Turing. But most of the philosophy is perhaps already done or maybe this is the reason why philosophy as an academic discipline seems to be less important. I think that it still might be important to work on it but maybe the field field itself is not well-equipped to wield the tools that would be needed to make progress, which actually require us to understand mathematics quite deeply. And it took me a long time to discover mathematics in my own life, because in school, it's largely taught as an extension of numerosity, the ability to intuitively meddle with numbers into accounting. And then there is some really arcane mathematics that uses Greek hieroglyphics that is done by some experts out there. And to understand that mathematics is just a very different thing, it's the domain of all languages, I think. And the mathematics that we are using in computer science is mostly talking about things that our mind is already doing. So for instance, when you see a toddler, and this toddler folds a sheet of paper and pushes a pen through it, this toddler is proving properties of embedded surfaces in Euclidean spaces. And the toddler doesn't know how to talk about it, but the toddler knows what they're doing, because they find themselves embedded into a three-dimensional space and want to discover its properties. And they have a hypothesis, and they test it by pushing this pen through. It's mathematics. And mathematics is a way to talk about these things, to basically build a second-order model in which we know what the first-order model is. And that first-order model, we experience this as direct reality, as our embodiment in a physical world that is directly given. But it's not. It's constructed by our brain. And this is the main thing our brain is doing, is to produce this perceptual embedding, this perceptual construct, this idea that we are in a three-dimensional world. And physics now teaches us the world that we are in is actually not three-dimensional. It's something else. But three-dimensional patterns are the best structure that we discover at the level at which we exist. It's what our brain is constructing to explain the space of photonic interactions. So reality is not given. It's a simulation that is generated in our brain, this three-dimensional space, res extensa, as Descartes called it. And ourselves in it and the ideas about it take place within this simulation. And I think this is the correct interpretation of this Buddhist philosophy, that we live in a dream, that is dreamt by a mind on a higher plane of existence. It's actually true. We live in this dream. And the mind of a higher plane of existence is in physics. It's the brain of a primate that roams a physical world. And we are in it. And it's basically the solution to this conundrum that puzzled our culture much more than other cultures for a long time. And I think that AI helps us to understand this. There's other things that we are doing besides perception. For instance, reasoning. Reasoning helps us to correct errors in our perception, because perception goes for coherence, for consistency. When there's something that we see, that we perceive to be inconsistent, then our mind gets drawn to it, and our reason will try to make a proof and to debug that thing. And also, perception and reasoning is not all there is. There's also the domain of feelings, right? And feelings, I think, is a way of a part of your brain that operates in a non-symbolic way and evaluates reality for you and tells you how to interact with it. And that part of your brain is much older than your reasoning and it needs to communicate with it. How do you communicate with a symbolic system, with a conceptual system, when you're not symbolic? You need to give it features that are presented in some kind of space, and that space is our body map. It's this invention, this simulacrum of a body that we have in which our feelings are being projected. It's not that when you have anxiety that your gut gets involved because your gut is very good at computing your competence. It's not. Your gut is very good at hurting bacteria in your intestines. That's what. Your gut is very good at hurting bacteria in your intestines. That's what it's doing. So these feelings that you have in your gut actually play out in your brain. And they would also play out if you sever the spinal cord and you're quadriplegic and you don't feel your body anymore. You still have this feeling, which is roughly located here. And the interactions that you get with this feeling are mostly because when you are very anxious and you don't know what to do about this in your environment, as you should, then you might be tempted to do something about it in your body, which you shouldn't, because that's going to interact with the bacteria and your gut regulation, right? So this is the situation that we find ourselves in. We are basically a reasoning computer, a symbolic computer, on top of a computer that gives us feeling, which is on top of a computer that gives us feeling, which is on top of a computer that gives us perception. That's a very good, I would say. I would just add. So I mean, there's a lot of detail, and you can get into definitely a lot of theory about it. And I think Josch is beginning to put much of this into practice. Whether or not we're going to be able to discover that we're in a simulation or not, we're certainly being forced, as evidenced by what you've just said, to think a lot about who we are, how we function, how the brain works. There are different systems with different levels of complexity there. But we're being forced to study that in detail. I'm not the best at quotes, but Descartes talked about studying the world and turning it into an equation. And there's a lot of beauty in that and understanding the detail of that, and that's certainly something that I'm working on now and understanding kind of human-to-human interaction, social systems, how that works and how that becomes convincing and how you do that well, such that interactions with technology don't become mechanized. We don't mechanize the brain, rather we turn the digital brain and make it more in a mirror image of us. I mean, that's, so this Pythagorean turn, I mean, that the world actually is kind of mathematizable, so became for me totally tangible in the movement of the quantified self, which is kind of dead now. But I mean, you might remember that at some point people would have these variable technologies attached to their bodies and measure bodily functions and kind of map themselves into some kind of digital or mathematical representation. And I thought this idea, I mean, to come to this kind of quantum theory of social behavior, I don't know if we will find out that, but that leaves a bit the AI thing. What I would really like to hear from both of you is this idea that we might find artificial intelligence that we try so hard now to mimic human behavior, like in chatbots and other rather boring things, to become something much more interesting, like for example, alien intelligences, aliens that we build ourselves. If you think of Google Alpha, the most noticeable most noticeable AlphaGo, but I mean, there was this paper by Garry Kasparov where he describes how Alpha plays chess. And Alpha was not trained with an optimization algorithm. Alpha was trained as a reinforcement network, so to say, to intelligence is playing chess against each other like billions of times and then come up with a totally original new way of playing chess. So in terms of developing alien intelligences, I mean, I go back to the point for me, it's about building something that's familiar, right? At least on the surface of it. I think the interaction is a critical piece to it, right? So for us, for example, our company, we're developing a digital avatar that really merges the AI brains, we're a deep tech company that does vision-based stuff with the body, right? So we actually have a, this is my background in gaming, and the game character infusing those two things and making it be something that is much more familiar. At the same time, you have the power of AI behind that, right, so you might be interacting with someone who, let's say, is an embodied digital assistant, but it has an infinite memory, and it can customize everything for you and whatnot. And so, we were speaking about this earlier, right? So it's something that's very familiar at the same time with powers, neurological powers, as it were, that are kind of unheard of in humans. So I think us getting used to that is going to be a new step. I think that the biggest enemy that we have as scientists and as thinkers is familiarity, because it deceives us into thinking that we know a thing. The most important progress that we make is usually not when we discover that there are multiple options and one of those options is the right one. The most important thing is when we discover that a certain thing which we thought is unconditionally true is actually not true and there are options. Uncertainty is always the more important discovery than certainty. So a discovery that reduces uncertainty is relatively easy to make, but a discovery that increases uncertainty means that the thing that we thought is given, our null hypothesis covers that already to discover that this null hypothesis was wrong. This is always very exciting. And the way I grew up, I basically settled as a human being into a certain baseline during my childhood. Trees ought to look in a particular way. There are trees which look right, which are the trees of Thuringia, and there are trees which look wrong, which are trees which look different from the trees of Thuringia. And you have to accommodate this unfamiliarity. And now when I look at trees, they all look quite alien to me. There are these weird fractalic growths, like big moss that goes by certain rules to the sun and tries to realize a lot of patterns so the tree doesn't interact with itself in bad ways when storm comes up and the trees don't damage themselves when they bump into each other. And the same is true for people. So as a child, I grew up into looking at people's faces and thinking, this is what people are like. And now I realize, no, they're not. They are all aliens. I'm an alien to myself. What is this thing that I am? Losing this familiarity with what you think is the given thing, that's always the necessary thing that you need to do when you want to understand what's really going on. So when I use mathematics to describe a thing, it's just a way to express code. And everything that exists, we can show it's a very deep and interesting political discussion that maybe we should have another day. Everything that exists is code. There is a particular way in which the universe seems to be, the ground truth, which is the code of the universe. It's prime mover, to speak versus Aristotle. But we cannot discover this, because we are embedded in the whole thing. So the only thing that we can do is make models of how that works. And all these models also have to be based on code because they have been done in languages and now we understand what languages are. That's so great because this is exactly... So one of my most favorite, I would say favorite sources of inspiration, Alain Badiou, in his famous work, Being an Event, works his way through and says, we have incompleteness in axiomatic systems. You might always say, as is the Turing theorem, that the code is never provable or never complete, or you can always make software that breaks other software, so it's never secure. So you might ask yourself, if the world is like that, and I would say quantum physics, and also the general theory of relativity, kind of shows in that direction that the world is kind of codified and mathematisable, but only to a certain extent. That is the end of Badiou's thinking, phrasing that as Lavoisier did. The world might actually be like an incompletely programmed computer game. If you think of computer games in those days, where you would reach the end of the computer game universe. I mean like GTA in those days where you were working on, where you would drive outside LA and suddenly you would see that the horizon was not real, but it was actually pixelated. So it doesn't matter how close you get, you won't see things in more detail. And the world might just be like that. It might just not be... so to say, the prime mover might have been just a bit sloppy and got bored and did not finish it. I think that life is the solution to certain chemical reactions that require control. So the reason why we're not outcompeted on this planetary surface by simple combustion and similar chemical reactions, some reactions require to be smarter than that. You need to add a little bit of energy in a particular way to harvest more energy. And this is why life has an opportunity to flourish. And the amount of control that life can exert to do this is not easily limited. So we put layers and layers of control on top of each other until we get a species like ours. And maybe we are not the top of this. Maybe we are just a sub-program that runs there. Maybe we are just Gaia's solution of getting all this carbon back into the atmosphere. And then we burn ourselves out and Gaia can make more plans. Who knows? But the interesting thing that there's information processing going on to enable this complexity that we have. And in a way, when you look at the world, it's not governed by mathematics. Mathematics describes it only. It's governed by economy, and economy is the art to change bits in the universe in the widest sense. And this also affects many of the things that we're doing. So we wonder, why is our computer technology not secure? And this might have to do with these relations of power. For instance, for the same reason, I suspect, there are no inedible mice. A mouse could evolve to be toxic to birds of prey. Why are mice inedible to birds of prey? And I suspect it's because whenever a mouse develops this kind of adaptation, the birds of prey will hunt that kind of mouse to extinction. Because this mouse is going to compete with other kinds of mice that are totally edible. And the reason why predators have larger brains is not just because it's harder to run after an animal than to run away from an animal. It's usually because you also need to make sure that your food is still there for you tomorrow. And managing the grass is easier than to managing the antelopes. And so every species that is around in a complicated ecosystem will have to make sure that there will be something left to eat in a couple generations from now. And in a way, if you make a completely safe email software that has unbreakable security, then you're not going to have a longer and happier life than an email provider that has breakable security. And that's because there are predators that are interested in your security not being completely unbreakable? I bet that the Bitcoin people will hate that. I forgot the original question now. No, I mean, coming back to the idea of this incompleteness and kind of the world that looks a bit pixelated when you look closely, I mean, that is the game conundrum. I mean, it doesn't spoil the fun of playing a game. I mean, thinking of your characters that are artificially, I mean, it doesn't spoil the fun of playing a game. I mean, thinking of your characters that are artificially, I mean, that they look artificial and probably should. It certainly makes your job easier if they deliberately look artificial. I mean, I can speak to that. So when we were going in and initially designing this character, we were looking at engagement being a primary thing, and had the choice of going with something that is hyper-real versus something that is more cartoony. When you think about the way humans communicate and read each other's emotions, it's vastly more complex the more realistic you go. But we all watch Disney cartoons. We've watched Pixar movies and Disney cartoons for our entire lives, and it's because that medium is an easier way to telegraph emotion ultimately and to have this kind of connection. And so for us, that was an initial choice. Having said that, we are now looking at certain things that have the character in a more aspirational role. So we're looking at fitness, for example, which is like fashion, more aspirational. You want this kind of connection where there's this sort of, there's a relationship where you kind of want to emulate the person that you're interacting with. And in that way, we don't want to be a cartoon. We want to have something that becomes more real. And so the challenge increases in order to have that connection with that character. It really depends on kind of, you know, how, why you're interacting with that technology at that moment. I think that aspiration is not necessarily a wrong thing, right? It's a bad thing for a society to be aspirational. I grew up in Eastern Germany which was a completely aspirational society. Basically, we planned everything for a utopia that never really happened and justified the status quo with this utopia. And in this sense, societies should define themselves by the status quo, not just by their aspirations. But when you talk to a human being, it's even more important who that person wants to be than what they currently are, because this determines their future. And it determines their interactions more than what they are. If you actually want to be a certain thing, and you truly want this, you don't deceive yourself about this and others, and there's a possibility, then you will find a way. So in this sense, the aspiration is very important, right? But it's also important to be truthful about this. By the way, I think that how to negotiate truth has become a more and more important question in AI, right? And I wonder how we can focus more on this thing in this world where we now certainly realize that everything that we get confronted with is fake news, that our societies have been built on fake news. And we are now in a situation where there is rogue fake news where random people can make propaganda on YouTube that gets more viewers than established mainstream media. And we think about curbing the independence, but we don't think about curbing the mainstream media. Should we basically try to build tools that make us discover truth? That is a very... I think that that leads back exactly to your practical work and field of research. I would just, before we come to that, which I find a totally fascinating question also, stay for a moment at this aspiration, because yesterday evening we had a totally amazing and very emotional discussion about diversity and AI. I mean, this is a thing that we will not really go deep into because everyone else is talking about that all the time. But so Chris mentioned that it is, so they use Mechanical Turks to train their AI. Maybe you can elaborate a bit on that and discover that they were lacking diversity and that would not actually work out that well. So the people were just too homogenous that they use as a training set. And you then kind of jumped into and said, well, that was actually kind of the problem in the GDR that while people are on a broad spectrum, in particular in certain intellectual and psychological conditions, having an ideology that would focus on egality solely might totally miss that. We came then to the idea of normality, which is, I mean, of course, at a very dark, and then Francis Galton, who coined the term of the normal distribution, I mean, also the coined the term eugenics, I mean, is really one of the darkest chapters in science that he opened there. And so maybe we can just wrap up. I mean, so what was that with the mechanical turks? And what was that with the Mechanical Turks and what was that with the Spectrum to share that? Sure. So in terms of what we use Mechanical Turk for, Millie, our character, is running with a model that's based on over 3 million videos. And we've sourced those videos initially through Mechanical Turk. And we then built our own layer on top of that to customize it somewhat. But we found with Mechanical Turk that most of the users were either in the US or in India. And there was a natural bias in the data towards people that looked American, however you define that, or Indian. And we didn't want to have any bias in our data. So we built it out so that it actually worked in conjunction with multiple platforms so we could source data from all around the world, people of all ethnicities and types and whatnot. And so there is no inherent bias in the model now having done that. And this is where you say no. Yeah, there's an important question about whether you want your data to be biased or not. For instance, if you follow the discussion at Google, Google has decided that it's not only want to remove biases from the presentation, they also want to introduce biases into their information. So, if you... There was a time when YouTube was giving you recommendations based only on your interest. Now, Google is changing these recommendations to make sure that you get a video suggested to you that Google thinks will lead to a better society. And there's a very big discussion about this because it introduces a bias. So basically, if you are right-wing and you search for right-wing videos, then Google might show you left-wing videos instead. And it's not what you have been looking for. And Google has decided that if you present people with these right-wing videos, you will strengthen these movements and society might come apart, what you have been looking for. And Google has decided that if you present people with these right-wing videos, you will strengthen these movements, and society might come apart, which is a very serious and honest concern that Google has. But it's a way to bias the data. And it leads us possibly away from truth. And it's a very big debate, because people use Google and feel no longer represented when the search results are not what they actually were searching for. I mean, that is an interesting point. I mean, thinking of neural networks. So neural networks have a tendency to fall into what is called local optima and not find truth, so to say, but get stuck somewhere in the middle because it looks already finished. And so I remember, I forgot the guy's name who was at the time head of search at Amazon. It was like 20 years ago. He said, that's exactly what happens with our search algorithm. We only show what we think is the optimal suggestion, what people are looking for, and it hardly ever is. So we introduce what's called jittering, which is we introduce errors into our algorithms to intentionally mislead the algorithm, to intentionally show things that people were not looking for, which is also avoiding getting stuck in what you might think of being right but might actually not want to. I mean, you're talking about adding randomization, ultimately, right? That's one, yeah, one aspect of it. I mean, that may be, you know, 30 years ago, when you went to get your news, you had a natural bias based on who you were, but it was your own personal agency that drove that you were a white collar, upper middle class New Yorker that read the New York Times, right? And now that's obviously all turned on its head. There's an inevitable bias and people, and they'll be accused of sort of West Coast based large tech companies to want to swing things one way or another. And I mean, who ultimately has the power to define that? And so, you know, randomness may be one ultimate solution to kind of balance things out, so you don't get stuck in the filter bubble, but no one else is telling you that this is the other side of that equation. It's an interesting thing that we model the fact that the information that we get is not unbiased. We always do this already, right? We don't believe that we are entitled to news that is completely unbiased. When I grew up in Eastern Germany, we would watch both the West German and the East German news every evening. And our conclusion was not this is the true one, this is the right one, but we would figure out in which way both of them lied, in which way they would constrain reality to try to get basically a third dimension, to figure out based on what lies each side thinks they can get away with, and what group things are available, and what their true incentives are. We would try to figure out what's possibly real. And that's what's possibly real, we don't know what that is, right? But the news constrained it in a particular way. That is actually exactly the point where I would really be interested that you talk a bit about. Your company, as I get that right, hopefully, for example, discovers fakes that are quite elaborate. I mean, like deep fakes, as they are called. So this is, so you are not so much concerned with by proving what is right, but I mean in a really like Vienna circle, Popperian way to at least falsify what's wrong. Part of what our company is currently working on is a project that we call Reality Defender. And it's meant to give people tools to discover when videos and so on are being Defender. And it's meant to give people tools to discover when videos and so on are being faked. And at some point, I also would love if this could do this with text and so on. And, you know, the best journalism right now is mostly still p-hacking. It starts with a hypothesis and then it picks facts selectively to support that hypothesis. And as a scientist, you know this is not permissible. What you have to do is when you don't know a particular thing, you have to quantify your agnosticism. You are not free to pick anything. So what you should be doing always is have all the possible beliefs and shift confidence between these beliefs around according to the evidence. So the strength of your belief always depends on the evidence. If your evidence is a guy having talked to a burning bush on a mountain, it's probably not a very valid experiment. So confidence should be low based on this. And in a similar way, you should basically, whenever you see a consensus opinion in a complicated field, be skeptical, right? Because the consensus-building forces are different forces than those that lead people to truth. When you are an expert in a field, be skeptical, right, because the consensus-building forces are different forces than those that lead people to choose. When you are an expert in a field, you will know that there are very few complicated things about which there is a consensus. So when a complicated thing like nutrition has a consensus at some point, we typically find out 10 years later the consensus was wrong. The consensus is often more wrong than the individual experts. But the individual experts are individually wrong, right? So it's a conundrum that we find ourselves in. I just wanted to point out an interesting dichotomy that you're working on essentially as the ubiquity of AI increases, right, you're working on it from one direction, which is in essentially, you know, we're humanizing it on our direction, which is in essentially, we're humanizing it on our side, right? So we're putting a human face to it, and you're essentially creating the marker that says, no, this is not human, this is very much a machine. So it's kind of coming to an interesting point where you need to both humanize things more, and at the same time clearly define what is, at the end of the day, not human. Yeah, I mean, it's kind of the reverse Turing test. I mean, it's kind of this, I mean, it might be totally boring to think of, I mean, is that a task that a machine can fulfill as well as a human being, but much more poignant, this is where machines are particularly interesting, where they produce glitches. I don't think that the glitches are necessarily the thing that makes us so interesting. It's mostly the ability to do what we think is the right thing to do. And to figure that out, we need to be creative. And creativity, I think, is about bridging gaps in the search space. So when your search space has a clean gradient, you know if you walk in this direction, change your solution's direction, it gets better and better and better until it stops getting better. And this is your local optimum. This is not very creative. This is just the state of the art. And the creativity happens when you need to jump into the unknown, when you need to construct a new search space. And at the moment when things are complicated, this is a problem that machines cannot do very well yet. But this doesn't mean that they cannot do it at all. Very often, we can cover the entire search space of personal strategies to play go and chess better than humans can do this. In this point, the machine is going to get better at being creative than a human being. There's a difference with respect to art as well. I don't think that art and creativity are the same thing. I think that art is very much about seeing. It's about, in a narrow sense, capturing a conscious experience. So there's this thing behind this surface, behind the screen of your mind or your medium, that you try to fixate and look at in the art. And there is this assumption, there is a particular ground truth. And you try to capture it with the tools you have. And this is what art, in a way, is doing. And our machines are not doing this, because our machines don't have built into them the belief that there is a particular ground truth, that the universe is in a particular way. We have these classifiers that say, now you are probably looking at this thing that a human says is a car, and you should avoid it in traffic. But it does not explain what a car really is in its very nature and how you would recognize it. It does not look for this hidden state, the universe itself. And this is, for me, the biggest task, to make something discover a ground truth. Our deep fake detectors that we currently built, they function well because the deepfakes are not very good. Right now, if you take a video that is artificially generated and you look at the blinking frequency and the gaze directions of that thing, you will find inconsistencies, is what humans do. You might find inconsistencies in lighting. You might even find compression artifacts that are different from the rest of the video and so on. So there are many ways in which you can cover these things. But more interesting thing would be to see there is a person that says something that they could not possibly be saying under these circumstances. Yes, that's so good. That's exactly what we have been discussing for a long time. I mean, is there an art that no human being could conceive? Like Reed Hastings, quote, entertaining AIs. I mean, that's really, I mean this question totally serious. This is really what I find fascinating. Well, I mean, you're seeing the emergence of creative AI now, which is producing things that we couldn't necessarily expect. It goes back to the AlphaGo example, right? With reinforcement learning turning into new moves and whatnot that were totally unexpected, that a human would never think of. So that's certainly something that's coming, but as you say, we're a long way from true creativity. Just to go back to your point about noticing how the weirdness of a deepfake and how some of the eye movement and whatnot doesn't work. I think what we look at in our work, if you get that wrong, and I mean, let's assume we're a year away from now where these avatars are more ubiquitous, I'm not sure that a human necessarily notices that off the bat, but I think that there's a real risk, in a subconscious effect of, let's say you interact with three avatars a day in the, on your e-commerce website and in your store and wherever. If you don't get this kind of human interaction right, I think, again, it goes back to this kind of mechanization of the mind problem, right, where you're put off. I mean, social media has changed the way that our brains work fundamentally, has changed our attention spans and whatnot. So for me, it's again about turning it back to being very human, such that we don't have these issues. So I have one last point, and we have scratched it already. It might be slippery territory, but nevertheless, I mean, I would not miss the chance. Thinking of what you said about this conundrum that we have, the individuals or the collective failing, should we believe someone who tells us that he heard or they heard the voice of God out of the burning bush? There is of course a dialectic answer from the Middle Ages, like the concept of mysticism, like Meister Eckhart, that there are these mystical things that we can't share, which is, I think, deeply rooted in German Romanticism. I would be interested to hear about artificial intelligence and mysticism. I mean, how do machines actually dream or how would we envision these conundrums maybe worked out in the Meister Eckhartian way, so to say? The problem is not that we cannot share things. The problem is that it takes many years before we created the language in the mind of the other that enables us to share these ideas. So if I want to share an idea about why mathematics was wrong or why computation was right and why everything is computation, that is basically a discourse that spends many decades at least. And to get to the level where you properly understand it probably takes a few years of discussing things with each other. And if you want to build a society in which you have patterns that make sense, where you have a meaningful distribution of power and regulation and checks and balances and so on, how do you install the social software on people? And the way you do this is you use mythology. You use a story, a story that a five-year-old understands and that scales towards a story that a ten-year-old understands and a 20-year-old and a 30-year-old understands. And this story is only very coarsely anchored or very vaguely anchored in the physical ground truths, but it's one that contains the necessary lectures, right? If you look at the German tales, like Hansel and Gretel, for instance, it's a tale that is difficult to parse right now, because the mythology is one of a different world. It's a world in which the parents starve so much that they can no longer feed their children so that they send them in the forest. And in the forest, they meet a woman that tries to eat them. And it's a story for the children to tell them to deal with the situation and recognize it and to kill her first. And it's a story that is very hard for us to relate to, because it's really not the world that we live in. It's a world in which people that literally want to eat us are very, very rare. We do have something where there are people that actually want to harm us. For instance, if our children are taken by an abuser who wants to rape them and so on, right? There is an echo of that in Hansel and Gretel in that story. And we can use this myth to teach our children about this. Beware of strangers. They might give you candy, but they might want to eat you in a particular way, right? In which, in a way that will harm you in ways that you cannot even imagine. So the myth can be useful, but it's only useful when you don't know the true language. And it's harmful if you tell people that the myth is the truth. And that is the important thing. We have been in a cult for a couple thousand years in Europe that told people, this is the way to discover truth. And if you don't adhere to this way to discover truth, we will burn you at the stake. And I think this has done great harm to our rationality as a culture. And it took a long time for us to recover from this. In some sense, the idea that guys talking to burning bushes learn valid lessons about the physical composition of the universe, that is still the null hypothesis. We still are fighting against this in our world, which is weird, because this guy never had the case. But the reason why this made sense was that for this Hebrew tribe, it was a very important way of structuring the interaction, to organize the military infrastructure, to organize who is a member of the tribe and not. And then the Catholics imported this and built it into something completely else that made the original Hebrew story almost incomprehensible. But to discover in which way the original story was intended, what it actually referred to, requires first that you fix your idea of what can be true and what not, and why a person would be incentivized to say a thing and why another person would be incentivized to say a thing, and why another person would be incentivized to believe it and tell it their children. I would just add, I think, coming at it from another angle, mystery is really a reflection of creativity, ultimately. There is mystery. It's a result of the mind creating something. And the burning bush is a shared example that we have. And I think it ultimately comes down to the approach that you take if you're building an artificial brain. We talked about this this morning, but really, right now, it's essentially pattern matching, and it's very localized, and you're classifying and whatnot. But if you were to build out a broader sense, humans are very conceptual. We conceptualize everything. If you're talking about the Hansel and Gretel story, you're conceptualizing two children, you're conceptualizing a forest, you're conceptualizing a house potentially being eaten. And all of that is built up over a foundation. You talk about the priors, but also the experience of interacting with things through a long period of time, potentially accelerated if you were to build this in a machine. And I think until we build that kind of broad-based form of understanding, a machine will fail to build that kind of broad-based form of understanding, a machine will fail to have the kind of conceptual creativity that leads to mystery, which is such a defining part of the human experience. Very nice. So I think we have still some time for questions or additions from the audience. So feel free to point out things. Or may I borrow one of the mics? Yes, I had a question about, I don't know whether we would call it a paradigm for understanding AI and its development or yeah, a kind of another myth perhaps, but this way of speaking about AI in terms of human development. People will talk about how AI is in its infancy or in its adolescence and this sort of relating it to the human scale of development. I wondered if both of you could say something about that, whether you think that that's applicable and if so, where do you think that AI is? Is that relevant in terms of thinking about intelligence and the difference between intelligence and free will, for example, something in that direction? Very good, thank you. Let me start. I think that at the moment AI is, in its research, experimental statistics, and in its application applied experimental statistics, so automating statistics. And it's very powerful, but it's a tool and it's not a mind. And it will not be a mind before we will be able to learn everything into a unified function, where we will be able to relate everything to everything. In a human being, our infancy starts before we even become an infant with proprioception. So, we form a body map in utero, and then we learn that we can get this body map in principle just by making a co-occurrence statistics. When two nerves fire at the same time, they're probably neighbors, and they're being touched at the same time. So, if you do a lot of statistics, you get a map of the body. And the next thing is the body touches itself. So it learns it's in space. It's basically a 2D surface embedded into a three-dimensional space. And we learn the shape of that body by touching ourselves while we are still in the womb. And when we are born, we get additional modalities, and we start seeing things. And we learn how the things that we see relate to the things that we can touch. And we find ourselves in the perceptual sphere in a scene. And then we move between these perceptual scenes and we learn that they are related into a shared universe. This is the three-dimensional universe that we are in. And everything that we observe is mapped onto a region in the three-dimensional universe. And we don't really go beyond this usually as human beings. This is the kind of universe that we operate in. This is Descartes' Res Extensa. And Res Cogitans is the source that we have about this universe. And so in a sense, our AIs are not even infants yet. They are not even in this stage where they can do this. There are tools that locally extend human rationality. And it will be really interesting once we are able to put everything into a single model. It will be really interesting and potentially scary when that model is motivated and wants something. So when this modeling happens in the service of regulation. I would agree with that in that it is very early and pre-infancy. I think I would ask the question, why do we want to put these, apply these sort of human time skills? What is the value of that? I mean, the progress of AI is probably unstoppable at this point, right? But there are a lot of decisions along the way that need to be made, right, in order to shape it to be what it's going to be, to be something that ultimately works well with us and doesn't overcome us. And so if anything, that's helping us understand, okay, crap, we have a lot to think about, right? Like, when is this going to come? We're probably wrong in our estimations, but being able to plot some rough timescale, I think, helps us in coming to those decisions. And I think we're doing a much better job with AI than we did with social media, to be honest. Oh, yeah. Very good. Thank you. Hey, sorry. I noticed a word you used when you were speaking earlier. You said, usually. Humans are usually in the 3D world. I was curious what examples you have of when we're not mapping that 3D experience. You can learn to see in 4D. That is, it's only interesting if you can make rotations, right? You can always add another dimension. If you add a color dimension to a three-dimensional space, that's not very interesting because you cannot rotate an object into the color space from the place space, the location space, right? But you can construct a four-dimensional space in which you can rotate an object so it retains its shape. And if you are interested in learning this, you can, there's a series of videos called Dimensions done by French artists and mathematicians. Unfortunately, there are many things called dimensions on YouTube, but if you look for it, you can still find it, I think. And it starts with stereographic projections. And you can learn the shapes of four-dimensional polyhedra to understand them by watching this for a few hours. It's a didactic series of videos that tells you step by step how stereographic projection works. And it will take these four dimensional objects and project them spherically into three dimensional objects. And by the way they change, you can actually see how this four dimensional structure works. And we can build rotating objects in up to eight dimensions. There are no more rotations above eight dimensions. And I'm not sure if my brain is able to go anywhere above four, and it's only working for very simple objects. I mean, I don't know if any one of you have seen that there was this amazing, I mean, kind of photographic proof of the shape of the halo around the black hole just recently, like a few months ago. And what that shows you is what the general theory of relativity always said that would be, that this hole in space is actually spherical. And that's exactly, I mean, why is it spherical? I mean, because we live in a kind kind of we have three space dimensions usually and then there is the whole I mean It has to go somewhere. So it goes kind of inside in this curve So that's I would say the first step where we actually see physical objects that are from a higher dimensionality. I mean mapped It gets really bad when the topology changes We are already in a four-dimensional space which which we recognize when we play, for instance, Kerbal Space Program, where you get a very visceral intuition by building rockets that go to the moon. And you have to control them by hand. And you realize when you're in orbit, you actually go straight. It's just the space that is curved. And the curvature of the space is the difference in the density of the space, in a way, right? So we are used to different densities of the space is the difference in the density of the space in a way, right? So we are used to different densities of the space. For instance, normally in 3D, we only have two-dimensional rotations, which has to do with the fact that complex numbers only work in 2D, 4D, and 8D. So in 3D, there are no really complex numbers, which means we cannot define a rotation operator in 3D. So all the rotation that you normally see are when you rotate this glass, it's always in a plane. It's always a two-dimensional rotation around an axis in 2D. You can also rotate this axis in addition, but it's still going to be two-dimensional rotations. But there are some edge cases. For instance, a smoke ring. A smoke ring is a torus that rotates around a circle. And this only works because air is compressible. So on the inside, the air gets compressed. On the outside, it gets dilated. And that's why it can rotate like this. So it's actually four-dimensional. It just uses curvature from the next dimension a little bit and bends our three-dimensional space a little, because the air can be pressed together. In the same way, you can imagine that gravity is such a difference in the density of the space around the planet. But with a black hole, the difference in the density of the space around the planet. But with a black hole, the difference in density becomes so large that you basically punch a hole in the structure of that thing. So this metaphor is no longer working, it gets very confusing for us. The nice thing here is if you didn't get that, it took Hamilton, who came up with this conundrum that you have either two or four dimensional rotations, like 40 years to figure out the math behind it. And he was pretty frustrated about it that then in the meantime, people would come up with the concept of a vector, which could have any dimension, and would be so much more successful in mathematics with that. Yeah, I mean, and equatorians, you mean, it's all this stuff is relatively easy to understand once you realize that mathematics is just a weird way to talk about code. So when you're a programmer, you basically, you understand that a rotation is a way to continuously permute bits. And the big confusion is also the real numbers, right? We have these numbers with infinitely many digits. And during Pythagoras' time, one of his disciples is said to have figured out that you can have numbers that you cannot express as fractions. Basically, Pythagoras thought that all the numbers that exist are integers or fractions. And some people figured out that pi and the square root of 2 are not fractions. And it's said that Pythagoras wanted to drown this disciple. Exactly. He drown this disciple. So it's actually that he did, right? Exactly. He murdered his disciple. I'm not quite sure if that is true or fake news, but the lesson here is that Pythagoras realized the world is not ready for this kind of knowledge. And I think he was correct, because these numbers don't exist. What they are, they are functions. And so pi is not a value. Pi is a function. If you want to know more digits of this function, you plug it into an energy source and have a computer that implements this function. It gives you as many digits as you can afford before your sun or other energy source burns out. But you will never have a thing in our universe that depends on knowing the last digit of pi. And the weird thing is we have physics now that is continuous geometric physics that pretends that we know the last digit of pi. And the weird thing is we have physics now that is continuous geometric physics that pretends that we know the last digit of pi and plug this into the next function. And this physics is wrong. They checked out the code library from mathematics without reading the comments. I'm not a mathematician, so I cannot speak. Although I would say that, I mean, this mathematics is part of that fundamental functional understanding of a broader AI that we don't have yet that would be built, you know, based on understanding space around it and whatnot as a one fundamental part of it. I totally went down a tangent here. Sorry, but I find this stuff so exciting. Again, if you are interested in that, read Brauer and the other intentional nationalists of the 1920s when that came up. The point is just, in physics, usually you have these developments and you have these error correction terms, and you usually drop everything beyond second order, because you can't measure that anyway. Physicists actually never cared about that. They say, well, we don't know pi. I mean, pi, like the first digit of pi or the second might be relevant. The third, no one cares about already. So pi might be kind of an irrational number, but physicists, well, they shrug and say, we can't measure that anyway. The reason why that is important is because there is a discussion in physics whether the universe is geometric or discrete. If the universe is geometric, that is, it happens continuously in a space, then it's required that we know the last digit of pi. And the question is, can we define a system that is able to find out what the last digit of pi is, so basically perform a computation that requires infinitely many steps or not. And if not, we need a different kind of physics. So that is now, I would say, a great, I would say, edge to which we pushed our spaziergang. I would not close without inviting you to share kind of a broad vision. I mean, like, the one thing that you want to shout out to everyone, what's up with AI in the next 20, 50 years? What's your dream of that? It's a broad question. There are so many different areas. I can speak to maybe our area, where the ultimate objective is to have something. So I come from an entertainment background. You always have to think about why you're working on technology. The answer, because it's cool, is a dangerous one. And I've certainly had that in the past. To me, it's ultimately, there are a lot of reasons why we're doing this. For me, it's about delight. And if you imagine all of this around us being technology, this building is technology, the road outside is technology, it's all very static. And I think what we're having now is we're breathing intelligence into our everyday lives through everyday things around us, these digital humans and whatnot. And there's a way to develop them, if we think it through, such that they really work to serve us and work well with us. And digital humans in particular, not being a one to one interaction with another person that we have, but the one in 10,000 interaction that really brightens your day and surprises you and delights you. And so we're really working towards getting to that point where you have these positive interactions with technology in a very intuitive interface. And I think that's kind of around the corner, I would say, shorter than 10 or 20 years. I mean, I think we're going to be there before AR and VR really mature. I suspect my own interaction with AI started when I was a child. and I grew up in a very remote valley and I wanted to have somebody to talk to. So, if there's nobody in your environment that you know that understands what you're interested in and thinks this is interesting stuff because they just think it's weird, it's kind of obvious that you need to build this thing yourself that you can talk to. And later on, when I got into the larger world, I met many more people like me and found them in universities and big cities and so on. And now this is no longer my driving impulse and it's more like understanding our own condition. But this is all embedded into a context of a world in which AI is economically so important that it's probably unstoppable. And we have to deal with the fact that we probably will share our planet with systems that are more intelligent than we are at some point. We don't have these systems yet. And when they will happen is hard to anticipate right now, because we probably need a couple ideas to make it happen beyond the state of the art. It's not even clear if we need these ideas or if you just can just learn the transition function between adjacent braid states. But maybe our meta-learning is already differentiable and can solve the stochastic gradient descent and we just need to do it in the right way. Who knows? But it's possible that we have a need to one or two ideas that we need to put together on top of what we already have in the right way, and we don't know when this will happen. So it could happen tomorrow. It could happen in 10 years, 20 years, 50 years. Difficult to say. I think it's unlikely that it won't happen. And when that happens, the world will change. It will change in ways that are very difficult to predict, maybe impossible to predict for us. Very good. it will change in ways that are very difficult to predict, maybe impossible to predict for us. Very good. I mean, with that, I think we come to an end. Leave everything open and please stay put because the next panel will be totally topical about that. It's about biohacking with great panelists. So everyone stays here. Thank you so much for the attention. I hope we could give you some perspective on the one or the other thing. Thank you so much for the attention. I hope we could give you some perspective on the one or the other thing. Thank you so much for the total inspiration that I already received from the two of you. And yeah, we will be around, looking forward to the rest of the conference. See you. Bye-bye. Thank you, Jörg. That was fun. Thank you. Thank you. Thank you. Thank you.", '29.23029351234436')